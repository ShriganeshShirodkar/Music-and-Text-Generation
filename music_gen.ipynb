{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uc7lszV_cPAv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#from model import build_model, save_weights\n",
    "\n",
    "\n",
    "DATA_DIR = './data'\n",
    "LOG_DIR = './logs'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDslcHXAcgk4"
   },
   "outputs": [],
   "source": [
    "def read_batches(T, vocab_size):\n",
    "    length = T.shape[0]; #129,665\n",
    "    batch_chars = int(length / BATCH_SIZE); # 8,104\n",
    "\n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH): # (0, 8040, 64)\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH)) # 16X64\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, vocab_size)) # 16X64X86\n",
    "        for batch_idx in range(0, BATCH_SIZE): # (0,16)\n",
    "            for i in range(0, SEQ_LENGTH): #(0,64)\n",
    "                X[batch_idx, i] = T[batch_chars * batch_idx + start + i] # \n",
    "                Y[batch_idx, i, T[batch_chars * batch_idx + start + i + 1]] = 1\n",
    "        yield X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXJ2R4j7cyc1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
    "\n",
    "\n",
    "MODEL_DIR = './model'\n",
    "\n",
    "def save_weights(epoch, model,name):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    model.save_weights(os.path.join(MODEL_DIR, 'weights_{}.{}.h5'.format(name,epoch)))\n",
    "\n",
    "def load_weights(epoch, model,name):\n",
    "    model.load_weights(os.path.join(MODEL_DIR, 'weights_{}.{}.h5'.format(name,epoch)))\n",
    "\n",
    "def build_model(batch_size, seq_len, vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(batch_size, seq_len)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences=True, stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(vocab_size))) \n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ns9oKOM5cjVX"
   },
   "outputs": [],
   "source": [
    "def train(name,text, epochs=100, save_freq=10):\n",
    "\n",
    "    # character to index and vice-versa mappings\n",
    "    char_to_idx = { ch: i for (i, ch) in enumerate(sorted(list(set(text)))) }\n",
    "    print(\"Number of unique characters: \" + str(len(char_to_idx))) #86\n",
    "\n",
    "    with open('char_to_idx_{}.json'.format(name), 'w') as f:\n",
    "        json.dump(char_to_idx, f)\n",
    "\n",
    "    idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "    vocab_size = len(char_to_idx)\n",
    "\n",
    "    #model_architecture\n",
    "    model = build_model(BATCH_SIZE, SEQ_LENGTH, vocab_size)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #Train data generation\n",
    "    T = np.asarray([char_to_idx[c] for c in text], dtype=np.int32) #convert complete text into numerical indices\n",
    "\n",
    "    print(\"Length of text:\" + str(T.size)) #129,665\n",
    "\n",
    "    steps_per_epoch = (len(text) / BATCH_SIZE - 1) / SEQ_LENGTH  \n",
    "\n",
    "    #log = TrainLogger('training_log.csv')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "        \n",
    "        losses, accs = [], []\n",
    "\n",
    "        for i, (X, Y) in enumerate(read_batches(T, vocab_size)):\n",
    "            \n",
    "            #print(X);\n",
    "\n",
    "            loss, acc = model.train_on_batch(X, Y)\n",
    "            print('Batch {}: loss = {}, acc = {}'.format(i + 1, loss, acc))\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "\n",
    "        #log.add_entry(np.average(losses), np.average(accs))\n",
    "\n",
    "        if (epoch + 1) % save_freq == 0:\n",
    "            save_weights(epoch + 1, model,name)\n",
    "            print('Saved checkpoint to', 'weights_{}.{}.h5'.format(name,epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFUpvorLz4sZ"
   },
   "outputs": [],
   "source": [
    "def file_name(name):\n",
    "  filename=name\n",
    "  raw_text= open(filename, 'r', encoding='utf-8').read()\n",
    "  #comment the below st for abc music\n",
    "  raw_text= raw_text.lower() \n",
    "  print(len(raw_text))\n",
    "  raw_text=raw_text[0:100000]\n",
    "  return raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yZVbhhEScqvY",
    "outputId": "db6558a5-81dd-41d0-843d-890e8241592a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42533\n",
      "Number of unique characters: 58\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (16, 64, 512)             29696     \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (16, 64, 58)              14906     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (16, 64, 58)              0         \n",
      "=================================================================\n",
      "Total params: 1,882,682\n",
      "Trainable params: 1,882,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Length of text:42533\n",
      "\n",
      "Epoch 1/100\n",
      "Batch 1: loss = 4.0610198974609375, acc = 0.00390625\n",
      "Batch 2: loss = 4.045561790466309, acc = 0.1611328125\n",
      "Batch 3: loss = 4.005928993225098, acc = 0.15625\n",
      "Batch 4: loss = 3.884310007095337, acc = 0.1591796875\n",
      "Batch 5: loss = 3.5737829208374023, acc = 0.1650390625\n",
      "Batch 6: loss = 3.645941734313965, acc = 0.1640625\n",
      "Batch 7: loss = 3.344489574432373, acc = 0.1708984375\n",
      "Batch 8: loss = 3.301954507827759, acc = 0.09375\n",
      "Batch 9: loss = 3.281259536743164, acc = 0.0732421875\n",
      "Batch 10: loss = 3.253796100616455, acc = 0.072265625\n",
      "Batch 11: loss = 3.2939200401306152, acc = 0.0546875\n",
      "Batch 12: loss = 3.2086849212646484, acc = 0.09765625\n",
      "Batch 13: loss = 3.2183163166046143, acc = 0.134765625\n",
      "Batch 14: loss = 3.140692710876465, acc = 0.158203125\n",
      "Batch 15: loss = 3.141977548599243, acc = 0.162109375\n",
      "Batch 16: loss = 3.1627683639526367, acc = 0.1650390625\n",
      "Batch 17: loss = 3.1754305362701416, acc = 0.1611328125\n",
      "Batch 18: loss = 3.1644279956817627, acc = 0.1630859375\n",
      "Batch 19: loss = 3.1445817947387695, acc = 0.162109375\n",
      "Batch 20: loss = 3.117968797683716, acc = 0.162109375\n",
      "Batch 21: loss = 3.1311559677124023, acc = 0.1650390625\n",
      "Batch 22: loss = 3.1076536178588867, acc = 0.154296875\n",
      "Batch 23: loss = 3.1294190883636475, acc = 0.1630859375\n",
      "Batch 24: loss = 3.0898025035858154, acc = 0.15234375\n",
      "Batch 25: loss = 3.1636240482330322, acc = 0.162109375\n",
      "Batch 26: loss = 3.102919578552246, acc = 0.1650390625\n",
      "Batch 27: loss = 3.1526145935058594, acc = 0.1708984375\n",
      "Batch 28: loss = 3.111391544342041, acc = 0.17578125\n",
      "Batch 29: loss = 3.121958017349243, acc = 0.17578125\n",
      "Batch 30: loss = 3.1211626529693604, acc = 0.1669921875\n",
      "Batch 31: loss = 3.1282405853271484, acc = 0.1748046875\n",
      "Batch 32: loss = 3.0774807929992676, acc = 0.1767578125\n",
      "Batch 33: loss = 3.146939516067505, acc = 0.16796875\n",
      "Batch 34: loss = 3.101522207260132, acc = 0.16796875\n",
      "Batch 35: loss = 3.1666693687438965, acc = 0.158203125\n",
      "Batch 36: loss = 3.1378884315490723, acc = 0.1640625\n",
      "Batch 37: loss = 3.1664836406707764, acc = 0.1552734375\n",
      "Batch 38: loss = 3.0908915996551514, acc = 0.1650390625\n",
      "Batch 39: loss = 3.150134563446045, acc = 0.1533203125\n",
      "Batch 40: loss = 3.1302642822265625, acc = 0.15234375\n",
      "Batch 41: loss = 3.2084503173828125, acc = 0.1416015625\n",
      "\n",
      "Epoch 2/100\n",
      "Batch 1: loss = 3.1853842735290527, acc = 0.150390625\n",
      "Batch 2: loss = 3.16697096824646, acc = 0.15625\n",
      "Batch 3: loss = 3.1536099910736084, acc = 0.1494140625\n",
      "Batch 4: loss = 3.1277666091918945, acc = 0.15234375\n",
      "Batch 5: loss = 3.1169533729553223, acc = 0.166015625\n",
      "Batch 6: loss = 3.158066749572754, acc = 0.1591796875\n",
      "Batch 7: loss = 3.0611960887908936, acc = 0.1708984375\n",
      "Batch 8: loss = 3.1167259216308594, acc = 0.17578125\n",
      "Batch 9: loss = 3.1426949501037598, acc = 0.171875\n",
      "Batch 10: loss = 3.128424882888794, acc = 0.1611328125\n",
      "Batch 11: loss = 3.151876211166382, acc = 0.1689453125\n",
      "Batch 12: loss = 3.095982074737549, acc = 0.1630859375\n",
      "Batch 13: loss = 3.127824068069458, acc = 0.1640625\n",
      "Batch 14: loss = 3.0628695487976074, acc = 0.1669921875\n",
      "Batch 15: loss = 3.0802576541900635, acc = 0.1640625\n",
      "Batch 16: loss = 3.133989095687866, acc = 0.1611328125\n",
      "Batch 17: loss = 3.1426849365234375, acc = 0.16015625\n",
      "Batch 18: loss = 3.1228322982788086, acc = 0.1572265625\n",
      "Batch 19: loss = 3.1138243675231934, acc = 0.1572265625\n",
      "Batch 20: loss = 3.046900749206543, acc = 0.1669921875\n",
      "Batch 21: loss = 3.07832407951355, acc = 0.162109375\n",
      "Batch 22: loss = 3.062927722930908, acc = 0.1787109375\n",
      "Batch 23: loss = 3.101853132247925, acc = 0.166015625\n",
      "Batch 24: loss = 3.073178768157959, acc = 0.1728515625\n",
      "Batch 25: loss = 3.1634275913238525, acc = 0.1689453125\n",
      "Batch 26: loss = 3.082634449005127, acc = 0.1669921875\n",
      "Batch 27: loss = 3.1476833820343018, acc = 0.173828125\n",
      "Batch 28: loss = 3.0904135704040527, acc = 0.1787109375\n",
      "Batch 29: loss = 3.098222255706787, acc = 0.177734375\n",
      "Batch 30: loss = 3.1006979942321777, acc = 0.1689453125\n",
      "Batch 31: loss = 3.1025824546813965, acc = 0.17578125\n",
      "Batch 32: loss = 3.05299973487854, acc = 0.1787109375\n",
      "Batch 33: loss = 3.136352300643921, acc = 0.1689453125\n",
      "Batch 34: loss = 3.088670253753662, acc = 0.1689453125\n",
      "Batch 35: loss = 3.15336012840271, acc = 0.15625\n",
      "Batch 36: loss = 3.1292483806610107, acc = 0.1669921875\n",
      "Batch 37: loss = 3.153656482696533, acc = 0.162109375\n",
      "Batch 38: loss = 3.0880656242370605, acc = 0.1796875\n",
      "Batch 39: loss = 3.127866268157959, acc = 0.1630859375\n",
      "Batch 40: loss = 3.1462888717651367, acc = 0.1591796875\n",
      "Batch 41: loss = 3.216387987136841, acc = 0.1494140625\n",
      "\n",
      "Epoch 3/100\n",
      "Batch 1: loss = 3.1719956398010254, acc = 0.1591796875\n",
      "Batch 2: loss = 3.1477742195129395, acc = 0.1611328125\n",
      "Batch 3: loss = 3.143505811691284, acc = 0.1513671875\n",
      "Batch 4: loss = 3.123673915863037, acc = 0.1572265625\n",
      "Batch 5: loss = 3.1119370460510254, acc = 0.1630859375\n",
      "Batch 6: loss = 3.1286561489105225, acc = 0.1630859375\n",
      "Batch 7: loss = 3.065232753753662, acc = 0.1748046875\n",
      "Batch 8: loss = 3.10734224319458, acc = 0.1767578125\n",
      "Batch 9: loss = 3.136234760284424, acc = 0.169921875\n",
      "Batch 10: loss = 3.108523368835449, acc = 0.1630859375\n",
      "Batch 11: loss = 3.142214059829712, acc = 0.16796875\n",
      "Batch 12: loss = 3.092698097229004, acc = 0.1640625\n",
      "Batch 13: loss = 3.1133151054382324, acc = 0.1630859375\n",
      "Batch 14: loss = 3.0583901405334473, acc = 0.1689453125\n",
      "Batch 15: loss = 3.0529165267944336, acc = 0.1630859375\n",
      "Batch 16: loss = 3.1058716773986816, acc = 0.1650390625\n",
      "Batch 17: loss = 3.1319892406463623, acc = 0.16015625\n",
      "Batch 18: loss = 3.107656955718994, acc = 0.166015625\n",
      "Batch 19: loss = 3.095233917236328, acc = 0.162109375\n",
      "Batch 20: loss = 3.058121919631958, acc = 0.1669921875\n",
      "Batch 21: loss = 3.072127342224121, acc = 0.171875\n",
      "Batch 22: loss = 3.0637922286987305, acc = 0.177734375\n",
      "Batch 23: loss = 3.0859780311584473, acc = 0.1689453125\n",
      "Batch 24: loss = 3.057556629180908, acc = 0.17578125\n",
      "Batch 25: loss = 3.151219367980957, acc = 0.16796875\n",
      "Batch 26: loss = 3.0777106285095215, acc = 0.166015625\n",
      "Batch 27: loss = 3.1549177169799805, acc = 0.17578125\n",
      "Batch 28: loss = 3.1007933616638184, acc = 0.1796875\n",
      "Batch 29: loss = 3.0938308238983154, acc = 0.177734375\n",
      "Batch 30: loss = 3.1018528938293457, acc = 0.169921875\n",
      "Batch 31: loss = 3.0971860885620117, acc = 0.17578125\n",
      "Batch 32: loss = 3.0640969276428223, acc = 0.1767578125\n",
      "Batch 33: loss = 3.1290531158447266, acc = 0.16796875\n",
      "Batch 34: loss = 3.0782852172851562, acc = 0.169921875\n",
      "Batch 35: loss = 3.144641637802124, acc = 0.158203125\n",
      "Batch 36: loss = 3.1145663261413574, acc = 0.1650390625\n",
      "Batch 37: loss = 3.140129327774048, acc = 0.16015625\n",
      "Batch 38: loss = 3.0732932090759277, acc = 0.1767578125\n",
      "Batch 39: loss = 3.116093635559082, acc = 0.1669921875\n",
      "Batch 40: loss = 3.362485885620117, acc = 0.158203125\n",
      "Batch 41: loss = 3.3451156616210938, acc = 0.1484375\n",
      "\n",
      "Epoch 4/100\n",
      "Batch 1: loss = 3.1611149311065674, acc = 0.16015625\n",
      "Batch 2: loss = 3.137930393218994, acc = 0.162109375\n",
      "Batch 3: loss = 3.125141143798828, acc = 0.15625\n",
      "Batch 4: loss = 3.0917980670928955, acc = 0.1572265625\n",
      "Batch 5: loss = 3.0939688682556152, acc = 0.1650390625\n",
      "Batch 6: loss = 3.124354124069214, acc = 0.1640625\n",
      "Batch 7: loss = 3.0452494621276855, acc = 0.1728515625\n",
      "Batch 8: loss = 3.09879469871521, acc = 0.17578125\n",
      "Batch 9: loss = 3.10994029045105, acc = 0.171875\n",
      "Batch 10: loss = 3.0873332023620605, acc = 0.1640625\n",
      "Batch 11: loss = 3.114806890487671, acc = 0.1708984375\n",
      "Batch 12: loss = 3.076775074005127, acc = 0.1640625\n",
      "Batch 13: loss = 3.085549831390381, acc = 0.1630859375\n",
      "Batch 14: loss = 3.0373177528381348, acc = 0.1689453125\n",
      "Batch 15: loss = 3.02219820022583, acc = 0.166015625\n",
      "Batch 16: loss = 3.075956344604492, acc = 0.173828125\n",
      "Batch 17: loss = 3.095397710800171, acc = 0.1630859375\n",
      "Batch 18: loss = 3.0678467750549316, acc = 0.16796875\n",
      "Batch 19: loss = 3.055980920791626, acc = 0.169921875\n",
      "Batch 20: loss = 2.992666721343994, acc = 0.1884765625\n",
      "Batch 21: loss = 2.993265151977539, acc = 0.1826171875\n",
      "Batch 22: loss = 2.969484806060791, acc = 0.2021484375\n",
      "Batch 23: loss = 3.009140729904175, acc = 0.1904296875\n",
      "Batch 24: loss = 2.9654064178466797, acc = 0.203125\n",
      "Batch 25: loss = 3.060521125793457, acc = 0.193359375\n",
      "Batch 26: loss = 2.9787373542785645, acc = 0.2041015625\n",
      "Batch 27: loss = 3.020634174346924, acc = 0.205078125\n",
      "Batch 28: loss = 2.953683376312256, acc = 0.22265625\n",
      "Batch 29: loss = 2.975339889526367, acc = 0.216796875\n",
      "Batch 30: loss = 2.9538445472717285, acc = 0.2119140625\n",
      "Batch 31: loss = 2.9466781616210938, acc = 0.2177734375\n",
      "Batch 32: loss = 2.9063706398010254, acc = 0.201171875\n",
      "Batch 33: loss = 2.947558879852295, acc = 0.2158203125\n",
      "Batch 34: loss = 2.9361116886138916, acc = 0.2060546875\n",
      "Batch 35: loss = 2.9985649585723877, acc = 0.205078125\n",
      "Batch 36: loss = 2.955998182296753, acc = 0.2158203125\n",
      "Batch 37: loss = 2.9666919708251953, acc = 0.201171875\n",
      "Batch 38: loss = 2.884507417678833, acc = 0.2236328125\n",
      "Batch 39: loss = 2.934347152709961, acc = 0.2109375\n",
      "Batch 40: loss = 2.947622299194336, acc = 0.220703125\n",
      "Batch 41: loss = 3.036468505859375, acc = 0.2080078125\n",
      "\n",
      "Epoch 5/100\n",
      "Batch 1: loss = 2.9781999588012695, acc = 0.2001953125\n",
      "Batch 2: loss = 2.9438304901123047, acc = 0.20703125\n",
      "Batch 3: loss = 2.9304347038269043, acc = 0.1982421875\n",
      "Batch 4: loss = 2.9079694747924805, acc = 0.2216796875\n",
      "Batch 5: loss = 2.8803787231445312, acc = 0.23046875\n",
      "Batch 6: loss = 2.912307024002075, acc = 0.2314453125\n",
      "Batch 7: loss = 2.844129800796509, acc = 0.2255859375\n",
      "Batch 8: loss = 2.830625534057617, acc = 0.2265625\n",
      "Batch 9: loss = 2.871703624725342, acc = 0.208984375\n",
      "Batch 10: loss = 2.890040397644043, acc = 0.2138671875\n",
      "Batch 11: loss = 2.8717987537384033, acc = 0.21875\n",
      "Batch 12: loss = 2.8096859455108643, acc = 0.2216796875\n",
      "Batch 13: loss = 2.8514628410339355, acc = 0.2314453125\n",
      "Batch 14: loss = 2.843600273132324, acc = 0.205078125\n",
      "Batch 15: loss = 2.813250780105591, acc = 0.21875\n",
      "Batch 16: loss = 2.836975336074829, acc = 0.224609375\n",
      "Batch 17: loss = 2.881199836730957, acc = 0.2236328125\n",
      "Batch 18: loss = 2.8553762435913086, acc = 0.234375\n",
      "Batch 19: loss = 2.855543613433838, acc = 0.2265625\n",
      "Batch 20: loss = 2.791189193725586, acc = 0.2412109375\n",
      "Batch 21: loss = 2.785325527191162, acc = 0.240234375\n",
      "Batch 22: loss = 2.7282590866088867, acc = 0.255859375\n",
      "Batch 23: loss = 2.818657636642456, acc = 0.2314453125\n",
      "Batch 24: loss = 2.75394868850708, acc = 0.2431640625\n",
      "Batch 25: loss = 2.8569602966308594, acc = 0.2392578125\n",
      "Batch 26: loss = 2.7521955966949463, acc = 0.23828125\n",
      "Batch 27: loss = 2.828462600708008, acc = 0.2314453125\n",
      "Batch 28: loss = 2.807483196258545, acc = 0.2470703125\n",
      "Batch 29: loss = 2.7572553157806396, acc = 0.251953125\n",
      "Batch 30: loss = 2.7774791717529297, acc = 0.2236328125\n",
      "Batch 31: loss = 2.763268232345581, acc = 0.2314453125\n",
      "Batch 32: loss = 2.6877329349517822, acc = 0.240234375\n",
      "Batch 33: loss = 2.7662477493286133, acc = 0.23828125\n",
      "Batch 34: loss = 2.757378101348877, acc = 0.2333984375\n",
      "Batch 35: loss = 2.830568313598633, acc = 0.2041015625\n",
      "Batch 36: loss = 2.7701809406280518, acc = 0.2333984375\n",
      "Batch 37: loss = 2.8238658905029297, acc = 0.2265625\n",
      "Batch 38: loss = 2.700875997543335, acc = 0.2587890625\n",
      "Batch 39: loss = 2.781374931335449, acc = 0.2421875\n",
      "Batch 40: loss = 2.800469398498535, acc = 0.224609375\n",
      "Batch 41: loss = 2.9187278747558594, acc = 0.2236328125\n",
      "\n",
      "Epoch 6/100\n",
      "Batch 1: loss = 2.8674278259277344, acc = 0.2158203125\n",
      "Batch 2: loss = 2.7978248596191406, acc = 0.228515625\n",
      "Batch 3: loss = 2.785309314727783, acc = 0.216796875\n",
      "Batch 4: loss = 2.728081703186035, acc = 0.234375\n",
      "Batch 5: loss = 2.719406843185425, acc = 0.2529296875\n",
      "Batch 6: loss = 2.7556443214416504, acc = 0.2412109375\n",
      "Batch 7: loss = 2.6921119689941406, acc = 0.25390625\n",
      "Batch 8: loss = 2.67880916595459, acc = 0.2744140625\n",
      "Batch 9: loss = 2.7015693187713623, acc = 0.2666015625\n",
      "Batch 10: loss = 2.7500643730163574, acc = 0.2333984375\n",
      "Batch 11: loss = 2.7258429527282715, acc = 0.232421875\n",
      "Batch 12: loss = 2.647679328918457, acc = 0.2578125\n",
      "Batch 13: loss = 2.73862886428833, acc = 0.2333984375\n",
      "Batch 14: loss = 2.712005853652954, acc = 0.23046875\n",
      "Batch 15: loss = 2.6505167484283447, acc = 0.255859375\n",
      "Batch 16: loss = 2.69342041015625, acc = 0.2509765625\n",
      "Batch 17: loss = 2.707409143447876, acc = 0.2470703125\n",
      "Batch 18: loss = 2.7296180725097656, acc = 0.2568359375\n",
      "Batch 19: loss = 2.7267496585845947, acc = 0.2470703125\n",
      "Batch 20: loss = 2.672793388366699, acc = 0.2568359375\n",
      "Batch 21: loss = 2.651118755340576, acc = 0.2548828125\n",
      "Batch 22: loss = 2.57071590423584, acc = 0.2763671875\n",
      "Batch 23: loss = 2.681732416152954, acc = 0.2509765625\n",
      "Batch 24: loss = 2.59912109375, acc = 0.2646484375\n",
      "Batch 25: loss = 2.7515296936035156, acc = 0.2568359375\n",
      "Batch 26: loss = 2.5987977981567383, acc = 0.25390625\n",
      "Batch 27: loss = 2.686790943145752, acc = 0.2626953125\n",
      "Batch 28: loss = 2.6880221366882324, acc = 0.25390625\n",
      "Batch 29: loss = 2.6390380859375, acc = 0.2578125\n",
      "Batch 30: loss = 2.64180064201355, acc = 0.2470703125\n",
      "Batch 31: loss = 2.620659351348877, acc = 0.244140625\n",
      "Batch 32: loss = 2.5555429458618164, acc = 0.2666015625\n",
      "Batch 33: loss = 2.6453630924224854, acc = 0.24609375\n",
      "Batch 34: loss = 2.642427444458008, acc = 0.265625\n",
      "Batch 35: loss = 2.697117328643799, acc = 0.234375\n",
      "Batch 36: loss = 2.620476245880127, acc = 0.25\n",
      "Batch 37: loss = 2.69987154006958, acc = 0.2470703125\n",
      "Batch 38: loss = 2.5784735679626465, acc = 0.283203125\n",
      "Batch 39: loss = 2.6371617317199707, acc = 0.23828125\n",
      "Batch 40: loss = 2.672415256500244, acc = 0.2470703125\n",
      "Batch 41: loss = 2.8056702613830566, acc = 0.23046875\n",
      "\n",
      "Epoch 7/100\n",
      "Batch 1: loss = 2.7127845287323, acc = 0.244140625\n",
      "Batch 2: loss = 2.6497321128845215, acc = 0.25390625\n",
      "Batch 3: loss = 2.669384002685547, acc = 0.2353515625\n",
      "Batch 4: loss = 2.6317138671875, acc = 0.2529296875\n",
      "Batch 5: loss = 2.608841896057129, acc = 0.2568359375\n",
      "Batch 6: loss = 2.6556830406188965, acc = 0.2705078125\n",
      "Batch 7: loss = 2.5739173889160156, acc = 0.2685546875\n",
      "Batch 8: loss = 2.533939838409424, acc = 0.2958984375\n",
      "Batch 9: loss = 2.5962367057800293, acc = 0.287109375\n",
      "Batch 10: loss = 2.617136240005493, acc = 0.2802734375\n",
      "Batch 11: loss = 2.5808398723602295, acc = 0.265625\n",
      "Batch 12: loss = 2.5353569984436035, acc = 0.2802734375\n",
      "Batch 13: loss = 2.6266679763793945, acc = 0.23046875\n",
      "Batch 14: loss = 2.592776298522949, acc = 0.259765625\n",
      "Batch 15: loss = 2.5439040660858154, acc = 0.275390625\n",
      "Batch 16: loss = 2.5557188987731934, acc = 0.2705078125\n",
      "Batch 17: loss = 2.576106548309326, acc = 0.2724609375\n",
      "Batch 18: loss = 2.6110219955444336, acc = 0.27734375\n",
      "Batch 19: loss = 2.623135805130005, acc = 0.2744140625\n",
      "Batch 20: loss = 2.5803494453430176, acc = 0.2841796875\n",
      "Batch 21: loss = 2.5260705947875977, acc = 0.275390625\n",
      "Batch 22: loss = 2.4417057037353516, acc = 0.3046875\n",
      "Batch 23: loss = 2.5655980110168457, acc = 0.2763671875\n",
      "Batch 24: loss = 2.5025734901428223, acc = 0.2900390625\n",
      "Batch 25: loss = 2.6157758235931396, acc = 0.279296875\n",
      "Batch 26: loss = 2.474198341369629, acc = 0.2802734375\n",
      "Batch 27: loss = 2.572913646697998, acc = 0.2763671875\n",
      "Batch 28: loss = 2.55950665473938, acc = 0.2890625\n",
      "Batch 29: loss = 2.5318198204040527, acc = 0.2822265625\n",
      "Batch 30: loss = 2.518763542175293, acc = 0.2802734375\n",
      "Batch 31: loss = 2.511056423187256, acc = 0.2724609375\n",
      "Batch 32: loss = 2.431285858154297, acc = 0.296875\n",
      "Batch 33: loss = 2.5384368896484375, acc = 0.291015625\n",
      "Batch 34: loss = 2.5176784992218018, acc = 0.3017578125\n",
      "Batch 35: loss = 2.5731327533721924, acc = 0.2763671875\n",
      "Batch 36: loss = 2.511848211288452, acc = 0.283203125\n",
      "Batch 37: loss = 2.5707013607025146, acc = 0.28515625\n",
      "Batch 38: loss = 2.4563674926757812, acc = 0.3095703125\n",
      "Batch 39: loss = 2.528482437133789, acc = 0.28515625\n",
      "Batch 40: loss = 2.548570394515991, acc = 0.2880859375\n",
      "Batch 41: loss = 2.674196720123291, acc = 0.263671875\n",
      "\n",
      "Epoch 8/100\n",
      "Batch 1: loss = 2.6075923442840576, acc = 0.2919921875\n",
      "Batch 2: loss = 2.529637336730957, acc = 0.2744140625\n",
      "Batch 3: loss = 2.5319314002990723, acc = 0.259765625\n",
      "Batch 4: loss = 2.494403839111328, acc = 0.2900390625\n",
      "Batch 5: loss = 2.480295419692993, acc = 0.3056640625\n",
      "Batch 6: loss = 2.5375096797943115, acc = 0.302734375\n",
      "Batch 7: loss = 2.4479081630706787, acc = 0.296875\n",
      "Batch 8: loss = 2.384188413619995, acc = 0.3212890625\n",
      "Batch 9: loss = 2.452287197113037, acc = 0.3271484375\n",
      "Batch 10: loss = 2.4998626708984375, acc = 0.3134765625\n",
      "Batch 11: loss = 2.476505756378174, acc = 0.30078125\n",
      "Batch 12: loss = 2.3693246841430664, acc = 0.32421875\n",
      "Batch 13: loss = 2.4775004386901855, acc = 0.29296875\n",
      "Batch 14: loss = 2.4408273696899414, acc = 0.2958984375\n",
      "Batch 15: loss = 2.4241437911987305, acc = 0.314453125\n",
      "Batch 16: loss = 2.4136457443237305, acc = 0.3017578125\n",
      "Batch 17: loss = 2.4162991046905518, acc = 0.3056640625\n",
      "Batch 18: loss = 2.453575372695923, acc = 0.3037109375\n",
      "Batch 19: loss = 2.4877371788024902, acc = 0.296875\n",
      "Batch 20: loss = 2.441582679748535, acc = 0.31640625\n",
      "Batch 21: loss = 2.4139628410339355, acc = 0.3134765625\n",
      "Batch 22: loss = 2.2983646392822266, acc = 0.3486328125\n",
      "Batch 23: loss = 2.4210448265075684, acc = 0.33203125\n",
      "Batch 24: loss = 2.3787152767181396, acc = 0.32421875\n",
      "Batch 25: loss = 2.4564833641052246, acc = 0.306640625\n",
      "Batch 26: loss = 2.3463268280029297, acc = 0.3251953125\n",
      "Batch 27: loss = 2.4132070541381836, acc = 0.3251953125\n",
      "Batch 28: loss = 2.4276702404022217, acc = 0.3212890625\n",
      "Batch 29: loss = 2.4062583446502686, acc = 0.3173828125\n",
      "Batch 30: loss = 2.3886871337890625, acc = 0.306640625\n",
      "Batch 31: loss = 2.3584837913513184, acc = 0.30859375\n",
      "Batch 32: loss = 2.286020278930664, acc = 0.341796875\n",
      "Batch 33: loss = 2.404846668243408, acc = 0.328125\n",
      "Batch 34: loss = 2.3977012634277344, acc = 0.328125\n",
      "Batch 35: loss = 2.4577221870422363, acc = 0.3125\n",
      "Batch 36: loss = 2.3624963760375977, acc = 0.3212890625\n",
      "Batch 37: loss = 2.451542854309082, acc = 0.326171875\n",
      "Batch 38: loss = 2.3416826725006104, acc = 0.3349609375\n",
      "Batch 39: loss = 2.3995232582092285, acc = 0.310546875\n",
      "Batch 40: loss = 2.385693073272705, acc = 0.3251953125\n",
      "Batch 41: loss = 2.5016684532165527, acc = 0.3115234375\n",
      "\n",
      "Epoch 9/100\n",
      "Batch 1: loss = 2.5019969940185547, acc = 0.318359375\n",
      "Batch 2: loss = 2.4039478302001953, acc = 0.314453125\n",
      "Batch 3: loss = 2.4153223037719727, acc = 0.3359375\n",
      "Batch 4: loss = 2.3796396255493164, acc = 0.3291015625\n",
      "Batch 5: loss = 2.3768768310546875, acc = 0.3505859375\n",
      "Batch 6: loss = 2.4039487838745117, acc = 0.3291015625\n",
      "Batch 7: loss = 2.3098812103271484, acc = 0.326171875\n",
      "Batch 8: loss = 2.243302822113037, acc = 0.3720703125\n",
      "Batch 9: loss = 2.304500102996826, acc = 0.359375\n",
      "Batch 10: loss = 2.3885838985443115, acc = 0.34375\n",
      "Batch 11: loss = 2.3564343452453613, acc = 0.3212890625\n",
      "Batch 12: loss = 2.2808890342712402, acc = 0.341796875\n",
      "Batch 13: loss = 2.351877212524414, acc = 0.3349609375\n",
      "Batch 14: loss = 2.325502872467041, acc = 0.33203125\n",
      "Batch 15: loss = 2.306839942932129, acc = 0.3505859375\n",
      "Batch 16: loss = 2.307180404663086, acc = 0.328125\n",
      "Batch 17: loss = 2.2735681533813477, acc = 0.3505859375\n",
      "Batch 18: loss = 2.3190178871154785, acc = 0.357421875\n",
      "Batch 19: loss = 2.3936381340026855, acc = 0.3291015625\n",
      "Batch 20: loss = 2.355245590209961, acc = 0.34765625\n",
      "Batch 21: loss = 2.308603286743164, acc = 0.3505859375\n",
      "Batch 22: loss = 2.181081771850586, acc = 0.3935546875\n",
      "Batch 23: loss = 2.304433822631836, acc = 0.369140625\n",
      "Batch 24: loss = 2.278322458267212, acc = 0.34375\n",
      "Batch 25: loss = 2.35941481590271, acc = 0.341796875\n",
      "Batch 26: loss = 2.2038497924804688, acc = 0.365234375\n",
      "Batch 27: loss = 2.2950799465179443, acc = 0.3623046875\n",
      "Batch 28: loss = 2.3129329681396484, acc = 0.3466796875\n",
      "Batch 29: loss = 2.2944393157958984, acc = 0.3583984375\n",
      "Batch 30: loss = 2.2693874835968018, acc = 0.34375\n",
      "Batch 31: loss = 2.212602138519287, acc = 0.373046875\n",
      "Batch 32: loss = 2.1879048347473145, acc = 0.376953125\n",
      "Batch 33: loss = 2.285170078277588, acc = 0.3515625\n",
      "Batch 34: loss = 2.315707206726074, acc = 0.3427734375\n",
      "Batch 35: loss = 2.338103771209717, acc = 0.3466796875\n",
      "Batch 36: loss = 2.24241304397583, acc = 0.3623046875\n",
      "Batch 37: loss = 2.338467597961426, acc = 0.3466796875\n",
      "Batch 38: loss = 2.261446237564087, acc = 0.3408203125\n",
      "Batch 39: loss = 2.263277053833008, acc = 0.345703125\n",
      "Batch 40: loss = 2.2112910747528076, acc = 0.380859375\n",
      "Batch 41: loss = 2.3296546936035156, acc = 0.3720703125\n",
      "\n",
      "Epoch 10/100\n",
      "Batch 1: loss = 2.3836076259613037, acc = 0.353515625\n",
      "Batch 2: loss = 2.2670488357543945, acc = 0.337890625\n",
      "Batch 3: loss = 2.3036298751831055, acc = 0.3515625\n",
      "Batch 4: loss = 2.2815184593200684, acc = 0.3466796875\n",
      "Batch 5: loss = 2.2722105979919434, acc = 0.3623046875\n",
      "Batch 6: loss = 2.287374973297119, acc = 0.3525390625\n",
      "Batch 7: loss = 2.2030227184295654, acc = 0.3623046875\n",
      "Batch 8: loss = 2.1302173137664795, acc = 0.392578125\n",
      "Batch 9: loss = 2.2245306968688965, acc = 0.375\n",
      "Batch 10: loss = 2.2810497283935547, acc = 0.36328125\n",
      "Batch 11: loss = 2.2531027793884277, acc = 0.33984375\n",
      "Batch 12: loss = 2.1859853267669678, acc = 0.373046875\n",
      "Batch 13: loss = 2.225022792816162, acc = 0.3779296875\n",
      "Batch 14: loss = 2.2305192947387695, acc = 0.3623046875\n",
      "Batch 15: loss = 2.2175252437591553, acc = 0.3720703125\n",
      "Batch 16: loss = 2.1930642127990723, acc = 0.345703125\n",
      "Batch 17: loss = 2.1678860187530518, acc = 0.3916015625\n",
      "Batch 18: loss = 2.17536997795105, acc = 0.3955078125\n",
      "Batch 19: loss = 2.2714743614196777, acc = 0.33984375\n",
      "Batch 20: loss = 2.2472829818725586, acc = 0.361328125\n",
      "Batch 21: loss = 2.2461791038513184, acc = 0.357421875\n",
      "Batch 22: loss = 2.1053645610809326, acc = 0.39453125\n",
      "Batch 23: loss = 2.1828083992004395, acc = 0.375\n",
      "Batch 24: loss = 2.1750473976135254, acc = 0.369140625\n",
      "Batch 25: loss = 2.270831823348999, acc = 0.3759765625\n",
      "Batch 26: loss = 2.1074001789093018, acc = 0.3935546875\n",
      "Batch 27: loss = 2.158247470855713, acc = 0.3681640625\n",
      "Batch 28: loss = 2.209585189819336, acc = 0.3828125\n",
      "Batch 29: loss = 2.17061710357666, acc = 0.3916015625\n",
      "Batch 30: loss = 2.14823579788208, acc = 0.38671875\n",
      "Batch 31: loss = 2.1016883850097656, acc = 0.400390625\n",
      "Batch 32: loss = 2.0836329460144043, acc = 0.4091796875\n",
      "Batch 33: loss = 2.1949868202209473, acc = 0.3671875\n",
      "Batch 34: loss = 2.239964485168457, acc = 0.359375\n",
      "Batch 35: loss = 2.2192811965942383, acc = 0.38671875\n",
      "Batch 36: loss = 2.1545419692993164, acc = 0.3818359375\n",
      "Batch 37: loss = 2.2487387657165527, acc = 0.369140625\n",
      "Batch 38: loss = 2.194277763366699, acc = 0.3544921875\n",
      "Batch 39: loss = 2.148850917816162, acc = 0.3740234375\n",
      "Batch 40: loss = 2.086132526397705, acc = 0.4248046875\n",
      "Batch 41: loss = 2.1714632511138916, acc = 0.404296875\n",
      "Saved checkpoint to weights_eminem_input.txt.10.h5\n",
      "\n",
      "Epoch 11/100\n",
      "Batch 1: loss = 2.2682790756225586, acc = 0.36328125\n",
      "Batch 2: loss = 2.1643691062927246, acc = 0.37109375\n",
      "Batch 3: loss = 2.2051260471343994, acc = 0.3671875\n",
      "Batch 4: loss = 2.1682653427124023, acc = 0.3798828125\n",
      "Batch 5: loss = 2.1584763526916504, acc = 0.380859375\n",
      "Batch 6: loss = 2.18637752532959, acc = 0.3876953125\n",
      "Batch 7: loss = 2.102403163909912, acc = 0.3935546875\n",
      "Batch 8: loss = 2.00944185256958, acc = 0.4248046875\n",
      "Batch 9: loss = 2.103148937225342, acc = 0.40625\n",
      "Batch 10: loss = 2.169888496398926, acc = 0.408203125\n",
      "Batch 11: loss = 2.1599223613739014, acc = 0.361328125\n",
      "Batch 12: loss = 2.1053571701049805, acc = 0.3857421875\n",
      "Batch 13: loss = 2.120000123977661, acc = 0.400390625\n",
      "Batch 14: loss = 2.136291742324829, acc = 0.3876953125\n",
      "Batch 15: loss = 2.110887050628662, acc = 0.400390625\n",
      "Batch 16: loss = 2.125655174255371, acc = 0.384765625\n",
      "Batch 17: loss = 2.055802345275879, acc = 0.431640625\n",
      "Batch 18: loss = 2.0759544372558594, acc = 0.421875\n",
      "Batch 19: loss = 2.179668426513672, acc = 0.365234375\n",
      "Batch 20: loss = 2.148177146911621, acc = 0.3984375\n",
      "Batch 21: loss = 2.155691623687744, acc = 0.3896484375\n",
      "Batch 22: loss = 2.029160261154175, acc = 0.408203125\n",
      "Batch 23: loss = 2.094365358352661, acc = 0.4150390625\n",
      "Batch 24: loss = 2.052910804748535, acc = 0.4052734375\n",
      "Batch 25: loss = 2.154571056365967, acc = 0.3896484375\n",
      "Batch 26: loss = 2.012078285217285, acc = 0.416015625\n",
      "Batch 27: loss = 2.058462619781494, acc = 0.4111328125\n",
      "Batch 28: loss = 2.110583782196045, acc = 0.3974609375\n",
      "Batch 29: loss = 2.0732874870300293, acc = 0.412109375\n",
      "Batch 30: loss = 2.032406806945801, acc = 0.4189453125\n",
      "Batch 31: loss = 2.0099072456359863, acc = 0.4267578125\n",
      "Batch 32: loss = 2.006420850753784, acc = 0.421875\n",
      "Batch 33: loss = 2.10551118850708, acc = 0.388671875\n",
      "Batch 34: loss = 2.1641602516174316, acc = 0.380859375\n",
      "Batch 35: loss = 2.1312036514282227, acc = 0.3935546875\n",
      "Batch 36: loss = 2.0677311420440674, acc = 0.404296875\n",
      "Batch 37: loss = 2.158323287963867, acc = 0.3955078125\n",
      "Batch 38: loss = 2.1173362731933594, acc = 0.37890625\n",
      "Batch 39: loss = 2.0850658416748047, acc = 0.3876953125\n",
      "Batch 40: loss = 1.987973690032959, acc = 0.42578125\n",
      "Batch 41: loss = 2.0725512504577637, acc = 0.4189453125\n",
      "\n",
      "Epoch 12/100\n",
      "Batch 1: loss = 2.187321662902832, acc = 0.388671875\n",
      "Batch 2: loss = 2.0672006607055664, acc = 0.390625\n",
      "Batch 3: loss = 2.128675937652588, acc = 0.3994140625\n",
      "Batch 4: loss = 2.050326347351074, acc = 0.41796875\n",
      "Batch 5: loss = 2.072556495666504, acc = 0.4072265625\n",
      "Batch 6: loss = 2.092914581298828, acc = 0.4033203125\n",
      "Batch 7: loss = 2.0037193298339844, acc = 0.4189453125\n",
      "Batch 8: loss = 1.9222438335418701, acc = 0.4619140625\n",
      "Batch 9: loss = 2.040680408477783, acc = 0.421875\n",
      "Batch 10: loss = 2.071640729904175, acc = 0.4208984375\n",
      "Batch 11: loss = 2.119894027709961, acc = 0.3701171875\n",
      "Batch 12: loss = 2.004622459411621, acc = 0.4267578125\n",
      "Batch 13: loss = 2.040496826171875, acc = 0.412109375\n",
      "Batch 14: loss = 2.0869944095611572, acc = 0.3818359375\n",
      "Batch 15: loss = 2.028254508972168, acc = 0.427734375\n",
      "Batch 16: loss = 2.041759967803955, acc = 0.400390625\n",
      "Batch 17: loss = 1.9787219762802124, acc = 0.4423828125\n",
      "Batch 18: loss = 1.9936259984970093, acc = 0.431640625\n",
      "Batch 19: loss = 2.102259874343872, acc = 0.37890625\n",
      "Batch 20: loss = 2.0819385051727295, acc = 0.408203125\n",
      "Batch 21: loss = 2.0895347595214844, acc = 0.3876953125\n",
      "Batch 22: loss = 1.9502133131027222, acc = 0.42578125\n",
      "Batch 23: loss = 2.0199570655822754, acc = 0.4267578125\n",
      "Batch 24: loss = 1.9952030181884766, acc = 0.4140625\n",
      "Batch 25: loss = 2.07552433013916, acc = 0.41015625\n",
      "Batch 26: loss = 1.912498950958252, acc = 0.4560546875\n",
      "Batch 27: loss = 1.9660990238189697, acc = 0.435546875\n",
      "Batch 28: loss = 2.0132229328155518, acc = 0.4150390625\n",
      "Batch 29: loss = 1.984755516052246, acc = 0.4384765625\n",
      "Batch 30: loss = 1.9320368766784668, acc = 0.4384765625\n",
      "Batch 31: loss = 1.9153664112091064, acc = 0.44921875\n",
      "Batch 32: loss = 1.9208735227584839, acc = 0.4443359375\n",
      "Batch 33: loss = 2.043309450149536, acc = 0.4013671875\n",
      "Batch 34: loss = 2.107999324798584, acc = 0.3935546875\n",
      "Batch 35: loss = 2.0533738136291504, acc = 0.421875\n",
      "Batch 36: loss = 1.97785484790802, acc = 0.4296875\n",
      "Batch 37: loss = 2.0880143642425537, acc = 0.412109375\n",
      "Batch 38: loss = 2.0628795623779297, acc = 0.3974609375\n",
      "Batch 39: loss = 2.021821975708008, acc = 0.4228515625\n",
      "Batch 40: loss = 1.930176019668579, acc = 0.447265625\n",
      "Batch 41: loss = 1.9892691373825073, acc = 0.4384765625\n",
      "\n",
      "Epoch 13/100\n",
      "Batch 1: loss = 2.097781181335449, acc = 0.4111328125\n",
      "Batch 2: loss = 1.997706651687622, acc = 0.412109375\n",
      "Batch 3: loss = 2.0493884086608887, acc = 0.41796875\n",
      "Batch 4: loss = 1.9924254417419434, acc = 0.427734375\n",
      "Batch 5: loss = 1.9984805583953857, acc = 0.4296875\n",
      "Batch 6: loss = 1.9996918439865112, acc = 0.4443359375\n",
      "Batch 7: loss = 1.919225811958313, acc = 0.4384765625\n",
      "Batch 8: loss = 1.8456242084503174, acc = 0.46484375\n",
      "Batch 9: loss = 1.9602521657943726, acc = 0.4326171875\n",
      "Batch 10: loss = 2.0094616413116455, acc = 0.4443359375\n",
      "Batch 11: loss = 2.051807403564453, acc = 0.4169921875\n",
      "Batch 12: loss = 1.9789412021636963, acc = 0.4365234375\n",
      "Batch 13: loss = 1.974294662475586, acc = 0.4423828125\n",
      "Batch 14: loss = 1.9978052377700806, acc = 0.4130859375\n",
      "Batch 15: loss = 1.9545539617538452, acc = 0.4404296875\n",
      "Batch 16: loss = 1.9650896787643433, acc = 0.4189453125\n",
      "Batch 17: loss = 1.9323763847351074, acc = 0.447265625\n",
      "Batch 18: loss = 1.9260274171829224, acc = 0.4521484375\n",
      "Batch 19: loss = 2.0271763801574707, acc = 0.404296875\n",
      "Batch 20: loss = 2.0269975662231445, acc = 0.416015625\n",
      "Batch 21: loss = 2.034114360809326, acc = 0.4140625\n",
      "Batch 22: loss = 1.9149198532104492, acc = 0.4287109375\n",
      "Batch 23: loss = 1.9338597059249878, acc = 0.44921875\n",
      "Batch 24: loss = 1.9048261642456055, acc = 0.453125\n",
      "Batch 25: loss = 1.98997962474823, acc = 0.4287109375\n",
      "Batch 26: loss = 1.8496358394622803, acc = 0.4580078125\n",
      "Batch 27: loss = 1.8712232112884521, acc = 0.47265625\n",
      "Batch 28: loss = 1.932135820388794, acc = 0.4404296875\n",
      "Batch 29: loss = 1.9022520780563354, acc = 0.453125\n",
      "Batch 30: loss = 1.8629953861236572, acc = 0.4716796875\n",
      "Batch 31: loss = 1.8616665601730347, acc = 0.466796875\n",
      "Batch 32: loss = 1.843325138092041, acc = 0.455078125\n",
      "Batch 33: loss = 1.9771673679351807, acc = 0.41796875\n",
      "Batch 34: loss = 2.0510218143463135, acc = 0.4189453125\n",
      "Batch 35: loss = 1.9877841472625732, acc = 0.423828125\n",
      "Batch 36: loss = 1.9167190790176392, acc = 0.4453125\n",
      "Batch 37: loss = 1.9972079992294312, acc = 0.4228515625\n",
      "Batch 38: loss = 2.0041422843933105, acc = 0.41796875\n",
      "Batch 39: loss = 1.9398456811904907, acc = 0.4287109375\n",
      "Batch 40: loss = 1.876652717590332, acc = 0.4580078125\n",
      "Batch 41: loss = 1.9378669261932373, acc = 0.451171875\n",
      "\n",
      "Epoch 14/100\n",
      "Batch 1: loss = 2.04841685295105, acc = 0.4267578125\n",
      "Batch 2: loss = 1.912412405014038, acc = 0.447265625\n",
      "Batch 3: loss = 1.9773900508880615, acc = 0.4404296875\n",
      "Batch 4: loss = 1.9149730205535889, acc = 0.447265625\n",
      "Batch 5: loss = 1.9092559814453125, acc = 0.447265625\n",
      "Batch 6: loss = 1.9074296951293945, acc = 0.4599609375\n",
      "Batch 7: loss = 1.852280616760254, acc = 0.4384765625\n",
      "Batch 8: loss = 1.7669520378112793, acc = 0.4833984375\n",
      "Batch 9: loss = 1.8704668283462524, acc = 0.4658203125\n",
      "Batch 10: loss = 1.9338550567626953, acc = 0.44921875\n",
      "Batch 11: loss = 2.0024874210357666, acc = 0.3984375\n",
      "Batch 12: loss = 1.9260730743408203, acc = 0.4404296875\n",
      "Batch 13: loss = 1.9232430458068848, acc = 0.431640625\n",
      "Batch 14: loss = 1.9264442920684814, acc = 0.4345703125\n",
      "Batch 15: loss = 1.892475962638855, acc = 0.4560546875\n",
      "Batch 16: loss = 1.9161980152130127, acc = 0.4228515625\n",
      "Batch 17: loss = 1.8665601015090942, acc = 0.46484375\n",
      "Batch 18: loss = 1.8826658725738525, acc = 0.4501953125\n",
      "Batch 19: loss = 1.9789774417877197, acc = 0.416015625\n",
      "Batch 20: loss = 1.9446289539337158, acc = 0.4326171875\n",
      "Batch 21: loss = 2.00638747215271, acc = 0.4208984375\n",
      "Batch 22: loss = 1.8558855056762695, acc = 0.4482421875\n",
      "Batch 23: loss = 1.8721683025360107, acc = 0.4599609375\n",
      "Batch 24: loss = 1.8681010007858276, acc = 0.4609375\n",
      "Batch 25: loss = 1.9682115316390991, acc = 0.431640625\n",
      "Batch 26: loss = 1.8028578758239746, acc = 0.4609375\n",
      "Batch 27: loss = 1.8099583387374878, acc = 0.486328125\n",
      "Batch 28: loss = 1.8657793998718262, acc = 0.4677734375\n",
      "Batch 29: loss = 1.8485889434814453, acc = 0.47265625\n",
      "Batch 30: loss = 1.7946926355361938, acc = 0.4853515625\n",
      "Batch 31: loss = 1.8079184293746948, acc = 0.4892578125\n",
      "Batch 32: loss = 1.8222813606262207, acc = 0.455078125\n",
      "Batch 33: loss = 1.918678879737854, acc = 0.44140625\n",
      "Batch 34: loss = 2.0263781547546387, acc = 0.408203125\n",
      "Batch 35: loss = 1.9524424076080322, acc = 0.439453125\n",
      "Batch 36: loss = 1.8611109256744385, acc = 0.44921875\n",
      "Batch 37: loss = 1.9556187391281128, acc = 0.4423828125\n",
      "Batch 38: loss = 1.9484269618988037, acc = 0.4306640625\n",
      "Batch 39: loss = 1.8767021894454956, acc = 0.4599609375\n",
      "Batch 40: loss = 1.8077607154846191, acc = 0.482421875\n",
      "Batch 41: loss = 1.8601598739624023, acc = 0.474609375\n",
      "\n",
      "Epoch 15/100\n",
      "Batch 1: loss = 1.974545955657959, acc = 0.4453125\n",
      "Batch 2: loss = 1.8567816019058228, acc = 0.45703125\n",
      "Batch 3: loss = 1.9178613424301147, acc = 0.44921875\n",
      "Batch 4: loss = 1.8693182468414307, acc = 0.4580078125\n",
      "Batch 5: loss = 1.829082727432251, acc = 0.48046875\n",
      "Batch 6: loss = 1.8695828914642334, acc = 0.4775390625\n",
      "Batch 7: loss = 1.764862060546875, acc = 0.490234375\n",
      "Batch 8: loss = 1.678091049194336, acc = 0.521484375\n",
      "Batch 9: loss = 1.8111038208007812, acc = 0.4609375\n",
      "Batch 10: loss = 1.8648838996887207, acc = 0.4599609375\n",
      "Batch 11: loss = 1.942615270614624, acc = 0.421875\n",
      "Batch 12: loss = 1.8464041948318481, acc = 0.4609375\n",
      "Batch 13: loss = 1.8358848094940186, acc = 0.4443359375\n",
      "Batch 14: loss = 1.8475502729415894, acc = 0.455078125\n",
      "Batch 15: loss = 1.8621896505355835, acc = 0.4658203125\n",
      "Batch 16: loss = 1.8726098537445068, acc = 0.447265625\n",
      "Batch 17: loss = 1.8153579235076904, acc = 0.47265625\n",
      "Batch 18: loss = 1.8509427309036255, acc = 0.4736328125\n",
      "Batch 19: loss = 1.932320475578308, acc = 0.4384765625\n",
      "Batch 20: loss = 1.9059607982635498, acc = 0.451171875\n",
      "Batch 21: loss = 1.9216070175170898, acc = 0.435546875\n",
      "Batch 22: loss = 1.8004462718963623, acc = 0.4736328125\n",
      "Batch 23: loss = 1.8286542892456055, acc = 0.474609375\n",
      "Batch 24: loss = 1.8033757209777832, acc = 0.46484375\n",
      "Batch 25: loss = 1.9117586612701416, acc = 0.4462890625\n",
      "Batch 26: loss = 1.7320857048034668, acc = 0.4697265625\n",
      "Batch 27: loss = 1.7304584980010986, acc = 0.51171875\n",
      "Batch 28: loss = 1.8433847427368164, acc = 0.486328125\n",
      "Batch 29: loss = 1.7619596719741821, acc = 0.5029296875\n",
      "Batch 30: loss = 1.752706527709961, acc = 0.4853515625\n",
      "Batch 31: loss = 1.7286298274993896, acc = 0.4931640625\n",
      "Batch 32: loss = 1.7378908395767212, acc = 0.4814453125\n",
      "Batch 33: loss = 1.8750137090682983, acc = 0.451171875\n",
      "Batch 34: loss = 1.9554409980773926, acc = 0.4375\n",
      "Batch 35: loss = 1.8735673427581787, acc = 0.4560546875\n",
      "Batch 36: loss = 1.781632661819458, acc = 0.46875\n",
      "Batch 37: loss = 1.881759762763977, acc = 0.4580078125\n",
      "Batch 38: loss = 1.9177982807159424, acc = 0.4287109375\n",
      "Batch 39: loss = 1.8569433689117432, acc = 0.4638671875\n",
      "Batch 40: loss = 1.7646243572235107, acc = 0.4775390625\n",
      "Batch 41: loss = 1.8172146081924438, acc = 0.4609375\n",
      "\n",
      "Epoch 16/100\n",
      "Batch 1: loss = 1.9171674251556396, acc = 0.466796875\n",
      "Batch 2: loss = 1.7878663539886475, acc = 0.4755859375\n",
      "Batch 3: loss = 1.8484392166137695, acc = 0.4658203125\n",
      "Batch 4: loss = 1.7945786714553833, acc = 0.4765625\n",
      "Batch 5: loss = 1.7314081192016602, acc = 0.5087890625\n",
      "Batch 6: loss = 1.7851189374923706, acc = 0.5\n",
      "Batch 7: loss = 1.716900110244751, acc = 0.494140625\n",
      "Batch 8: loss = 1.6395536661148071, acc = 0.5283203125\n",
      "Batch 9: loss = 1.761866807937622, acc = 0.4814453125\n",
      "Batch 10: loss = 1.7867306470870972, acc = 0.501953125\n",
      "Batch 11: loss = 1.912428617477417, acc = 0.4365234375\n",
      "Batch 12: loss = 1.7964166402816772, acc = 0.4560546875\n",
      "Batch 13: loss = 1.79976487159729, acc = 0.455078125\n",
      "Batch 14: loss = 1.8079698085784912, acc = 0.4697265625\n",
      "Batch 15: loss = 1.780958890914917, acc = 0.482421875\n",
      "Batch 16: loss = 1.8226057291030884, acc = 0.4501953125\n",
      "Batch 17: loss = 1.7758138179779053, acc = 0.4716796875\n",
      "Batch 18: loss = 1.7965666055679321, acc = 0.486328125\n",
      "Batch 19: loss = 1.88130784034729, acc = 0.44140625\n",
      "Batch 20: loss = 1.865910530090332, acc = 0.470703125\n",
      "Batch 21: loss = 1.8707010746002197, acc = 0.458984375\n",
      "Batch 22: loss = 1.757575273513794, acc = 0.4755859375\n",
      "Batch 23: loss = 1.7597830295562744, acc = 0.49609375\n",
      "Batch 24: loss = 1.7686288356781006, acc = 0.4951171875\n",
      "Batch 25: loss = 1.8625580072402954, acc = 0.462890625\n",
      "Batch 26: loss = 1.6807200908660889, acc = 0.501953125\n",
      "Batch 27: loss = 1.664231777191162, acc = 0.50390625\n",
      "Batch 28: loss = 1.745436668395996, acc = 0.5\n",
      "Batch 29: loss = 1.7328212261199951, acc = 0.51171875\n",
      "Batch 30: loss = 1.683095932006836, acc = 0.517578125\n",
      "Batch 31: loss = 1.6741533279418945, acc = 0.52734375\n",
      "Batch 32: loss = 1.689516305923462, acc = 0.5009765625\n",
      "Batch 33: loss = 1.816955327987671, acc = 0.4658203125\n",
      "Batch 34: loss = 1.9181753396987915, acc = 0.4443359375\n",
      "Batch 35: loss = 1.8466355800628662, acc = 0.4638671875\n",
      "Batch 36: loss = 1.747628092765808, acc = 0.474609375\n",
      "Batch 37: loss = 1.8365557193756104, acc = 0.4580078125\n",
      "Batch 38: loss = 1.844066858291626, acc = 0.4599609375\n",
      "Batch 39: loss = 1.7782474756240845, acc = 0.4814453125\n",
      "Batch 40: loss = 1.7139713764190674, acc = 0.498046875\n",
      "Batch 41: loss = 1.766059398651123, acc = 0.4833984375\n",
      "\n",
      "Epoch 17/100\n",
      "Batch 1: loss = 1.8396819829940796, acc = 0.4794921875\n",
      "Batch 2: loss = 1.7477009296417236, acc = 0.515625\n",
      "Batch 3: loss = 1.7815110683441162, acc = 0.5\n",
      "Batch 4: loss = 1.736627221107483, acc = 0.484375\n",
      "Batch 5: loss = 1.6940298080444336, acc = 0.4912109375\n",
      "Batch 6: loss = 1.7090864181518555, acc = 0.5126953125\n",
      "Batch 7: loss = 1.6515083312988281, acc = 0.48828125\n",
      "Batch 8: loss = 1.5777907371520996, acc = 0.548828125\n",
      "Batch 9: loss = 1.6998425722122192, acc = 0.498046875\n",
      "Batch 10: loss = 1.7509021759033203, acc = 0.4921875\n",
      "Batch 11: loss = 1.8609918355941772, acc = 0.447265625\n",
      "Batch 12: loss = 1.7499206066131592, acc = 0.4853515625\n",
      "Batch 13: loss = 1.7352324724197388, acc = 0.48046875\n",
      "Batch 14: loss = 1.7803928852081299, acc = 0.4814453125\n",
      "Batch 15: loss = 1.7551116943359375, acc = 0.498046875\n",
      "Batch 16: loss = 1.7520524263381958, acc = 0.462890625\n",
      "Batch 17: loss = 1.7068495750427246, acc = 0.498046875\n",
      "Batch 18: loss = 1.7400933504104614, acc = 0.484375\n",
      "Batch 19: loss = 1.820612907409668, acc = 0.451171875\n",
      "Batch 20: loss = 1.8121975660324097, acc = 0.4755859375\n",
      "Batch 21: loss = 1.8540358543395996, acc = 0.4404296875\n",
      "Batch 22: loss = 1.6942992210388184, acc = 0.498046875\n",
      "Batch 23: loss = 1.7005527019500732, acc = 0.5224609375\n",
      "Batch 24: loss = 1.7261719703674316, acc = 0.4990234375\n",
      "Batch 25: loss = 1.8375664949417114, acc = 0.47265625\n",
      "Batch 26: loss = 1.61029851436615, acc = 0.5224609375\n",
      "Batch 27: loss = 1.5871500968933105, acc = 0.5341796875\n",
      "Batch 28: loss = 1.6851069927215576, acc = 0.5078125\n",
      "Batch 29: loss = 1.6653344631195068, acc = 0.533203125\n",
      "Batch 30: loss = 1.6592190265655518, acc = 0.521484375\n",
      "Batch 31: loss = 1.6400866508483887, acc = 0.537109375\n",
      "Batch 32: loss = 1.6365892887115479, acc = 0.5078125\n",
      "Batch 33: loss = 1.7807276248931885, acc = 0.4501953125\n",
      "Batch 34: loss = 1.8626391887664795, acc = 0.45703125\n",
      "Batch 35: loss = 1.7963038682937622, acc = 0.4873046875\n",
      "Batch 36: loss = 1.698117971420288, acc = 0.482421875\n",
      "Batch 37: loss = 1.81040358543396, acc = 0.4775390625\n",
      "Batch 38: loss = 1.7874579429626465, acc = 0.46484375\n",
      "Batch 39: loss = 1.735339879989624, acc = 0.4853515625\n",
      "Batch 40: loss = 1.6944409608840942, acc = 0.4990234375\n",
      "Batch 41: loss = 1.7358152866363525, acc = 0.484375\n",
      "\n",
      "Epoch 18/100\n",
      "Batch 1: loss = 1.8000147342681885, acc = 0.4970703125\n",
      "Batch 2: loss = 1.6882466077804565, acc = 0.515625\n",
      "Batch 3: loss = 1.7469040155410767, acc = 0.498046875\n",
      "Batch 4: loss = 1.685945987701416, acc = 0.51171875\n",
      "Batch 5: loss = 1.6348103284835815, acc = 0.51953125\n",
      "Batch 6: loss = 1.6554455757141113, acc = 0.52734375\n",
      "Batch 7: loss = 1.5768654346466064, acc = 0.5498046875\n",
      "Batch 8: loss = 1.5129518508911133, acc = 0.5576171875\n",
      "Batch 9: loss = 1.6607818603515625, acc = 0.5107421875\n",
      "Batch 10: loss = 1.6917459964752197, acc = 0.51953125\n",
      "Batch 11: loss = 1.8351061344146729, acc = 0.4521484375\n",
      "Batch 12: loss = 1.705634593963623, acc = 0.4931640625\n",
      "Batch 13: loss = 1.7013235092163086, acc = 0.4951171875\n",
      "Batch 14: loss = 1.6931774616241455, acc = 0.48828125\n",
      "Batch 15: loss = 1.7155520915985107, acc = 0.501953125\n",
      "Batch 16: loss = 1.691087007522583, acc = 0.4853515625\n",
      "Batch 17: loss = 1.6812849044799805, acc = 0.513671875\n",
      "Batch 18: loss = 1.6938600540161133, acc = 0.5068359375\n",
      "Batch 19: loss = 1.7870383262634277, acc = 0.458984375\n",
      "Batch 20: loss = 1.7463603019714355, acc = 0.5009765625\n",
      "Batch 21: loss = 1.7854551076889038, acc = 0.4716796875\n",
      "Batch 22: loss = 1.6645276546478271, acc = 0.5126953125\n",
      "Batch 23: loss = 1.6834765672683716, acc = 0.5185546875\n",
      "Batch 24: loss = 1.644524335861206, acc = 0.5263671875\n",
      "Batch 25: loss = 1.7464044094085693, acc = 0.5\n",
      "Batch 26: loss = 1.5408445596694946, acc = 0.5322265625\n",
      "Batch 27: loss = 1.5244961977005005, acc = 0.576171875\n",
      "Batch 28: loss = 1.6290934085845947, acc = 0.5283203125\n",
      "Batch 29: loss = 1.617188572883606, acc = 0.5361328125\n",
      "Batch 30: loss = 1.5850633382797241, acc = 0.5361328125\n",
      "Batch 31: loss = 1.56826651096344, acc = 0.548828125\n",
      "Batch 32: loss = 1.6061933040618896, acc = 0.5234375\n",
      "Batch 33: loss = 1.731795072555542, acc = 0.4794921875\n",
      "Batch 34: loss = 1.816699504852295, acc = 0.47265625\n",
      "Batch 35: loss = 1.7600083351135254, acc = 0.48046875\n",
      "Batch 36: loss = 1.6253819465637207, acc = 0.513671875\n",
      "Batch 37: loss = 1.758047342300415, acc = 0.50390625\n",
      "Batch 38: loss = 1.7313668727874756, acc = 0.4892578125\n",
      "Batch 39: loss = 1.6698592901229858, acc = 0.5126953125\n",
      "Batch 40: loss = 1.6292552947998047, acc = 0.5244140625\n",
      "Batch 41: loss = 1.6885836124420166, acc = 0.501953125\n",
      "\n",
      "Epoch 19/100\n",
      "Batch 1: loss = 1.757211685180664, acc = 0.5068359375\n",
      "Batch 2: loss = 1.6432501077651978, acc = 0.5302734375\n",
      "Batch 3: loss = 1.6878490447998047, acc = 0.5224609375\n",
      "Batch 4: loss = 1.6342494487762451, acc = 0.5205078125\n",
      "Batch 5: loss = 1.5694973468780518, acc = 0.5419921875\n",
      "Batch 6: loss = 1.5882530212402344, acc = 0.537109375\n",
      "Batch 7: loss = 1.5595309734344482, acc = 0.5390625\n",
      "Batch 8: loss = 1.4553285837173462, acc = 0.59375\n",
      "Batch 9: loss = 1.5945388078689575, acc = 0.515625\n",
      "Batch 10: loss = 1.6437522172927856, acc = 0.5283203125\n",
      "Batch 11: loss = 1.7579715251922607, acc = 0.474609375\n",
      "Batch 12: loss = 1.6606838703155518, acc = 0.49609375\n",
      "Batch 13: loss = 1.63742995262146, acc = 0.5009765625\n",
      "Batch 14: loss = 1.655517578125, acc = 0.5087890625\n",
      "Batch 15: loss = 1.6216379404067993, acc = 0.5234375\n",
      "Batch 16: loss = 1.6436396837234497, acc = 0.513671875\n",
      "Batch 17: loss = 1.634190559387207, acc = 0.5107421875\n",
      "Batch 18: loss = 1.6315274238586426, acc = 0.5146484375\n",
      "Batch 19: loss = 1.7118279933929443, acc = 0.48046875\n",
      "Batch 20: loss = 1.7272655963897705, acc = 0.4921875\n",
      "Batch 21: loss = 1.7280573844909668, acc = 0.47265625\n",
      "Batch 22: loss = 1.6254174709320068, acc = 0.525390625\n",
      "Batch 23: loss = 1.6332838535308838, acc = 0.5283203125\n",
      "Batch 24: loss = 1.5824236869812012, acc = 0.537109375\n",
      "Batch 25: loss = 1.6851670742034912, acc = 0.51953125\n",
      "Batch 26: loss = 1.4957525730133057, acc = 0.5517578125\n",
      "Batch 27: loss = 1.479366660118103, acc = 0.56640625\n",
      "Batch 28: loss = 1.5737152099609375, acc = 0.52734375\n",
      "Batch 29: loss = 1.5367085933685303, acc = 0.5654296875\n",
      "Batch 30: loss = 1.5275230407714844, acc = 0.564453125\n",
      "Batch 31: loss = 1.5165678262710571, acc = 0.5595703125\n",
      "Batch 32: loss = 1.5423197746276855, acc = 0.537109375\n",
      "Batch 33: loss = 1.687674880027771, acc = 0.494140625\n",
      "Batch 34: loss = 1.7682769298553467, acc = 0.4990234375\n",
      "Batch 35: loss = 1.6723328828811646, acc = 0.5126953125\n",
      "Batch 36: loss = 1.5853583812713623, acc = 0.5283203125\n",
      "Batch 37: loss = 1.6982624530792236, acc = 0.4970703125\n",
      "Batch 38: loss = 1.707122802734375, acc = 0.490234375\n",
      "Batch 39: loss = 1.6711747646331787, acc = 0.517578125\n",
      "Batch 40: loss = 1.5884895324707031, acc = 0.51953125\n",
      "Batch 41: loss = 1.646139144897461, acc = 0.5078125\n",
      "\n",
      "Epoch 20/100\n",
      "Batch 1: loss = 1.6883809566497803, acc = 0.5419921875\n",
      "Batch 2: loss = 1.5701165199279785, acc = 0.53515625\n",
      "Batch 3: loss = 1.6398544311523438, acc = 0.5224609375\n",
      "Batch 4: loss = 1.5803980827331543, acc = 0.5419921875\n",
      "Batch 5: loss = 1.547773838043213, acc = 0.5576171875\n",
      "Batch 6: loss = 1.539847493171692, acc = 0.5615234375\n",
      "Batch 7: loss = 1.4680440425872803, acc = 0.5751953125\n",
      "Batch 8: loss = 1.4209471940994263, acc = 0.5927734375\n",
      "Batch 9: loss = 1.556289553642273, acc = 0.5361328125\n",
      "Batch 10: loss = 1.579685926437378, acc = 0.546875\n",
      "Batch 11: loss = 1.7439618110656738, acc = 0.466796875\n",
      "Batch 12: loss = 1.631995439529419, acc = 0.51953125\n",
      "Batch 13: loss = 1.5924955606460571, acc = 0.5322265625\n",
      "Batch 14: loss = 1.609107494354248, acc = 0.513671875\n",
      "Batch 15: loss = 1.5752118825912476, acc = 0.544921875\n",
      "Batch 16: loss = 1.616265058517456, acc = 0.5126953125\n",
      "Batch 17: loss = 1.5809706449508667, acc = 0.53515625\n",
      "Batch 18: loss = 1.577631950378418, acc = 0.54296875\n",
      "Batch 19: loss = 1.6922203302383423, acc = 0.486328125\n",
      "Batch 20: loss = 1.6481894254684448, acc = 0.5078125\n",
      "Batch 21: loss = 1.6994786262512207, acc = 0.4873046875\n",
      "Batch 22: loss = 1.5727041959762573, acc = 0.5166015625\n",
      "Batch 23: loss = 1.5327327251434326, acc = 0.5498046875\n",
      "Batch 24: loss = 1.5544723272323608, acc = 0.5439453125\n",
      "Batch 25: loss = 1.6625030040740967, acc = 0.5166015625\n",
      "Batch 26: loss = 1.426405429840088, acc = 0.5830078125\n",
      "Batch 27: loss = 1.4457018375396729, acc = 0.5791015625\n",
      "Batch 28: loss = 1.5294053554534912, acc = 0.544921875\n",
      "Batch 29: loss = 1.5218390226364136, acc = 0.5703125\n",
      "Batch 30: loss = 1.468590497970581, acc = 0.5810546875\n",
      "Batch 31: loss = 1.4851845502853394, acc = 0.57421875\n",
      "Batch 32: loss = 1.5130414962768555, acc = 0.5517578125\n",
      "Batch 33: loss = 1.6626774072647095, acc = 0.5\n",
      "Batch 34: loss = 1.7434524297714233, acc = 0.486328125\n",
      "Batch 35: loss = 1.635509729385376, acc = 0.513671875\n",
      "Batch 36: loss = 1.5450854301452637, acc = 0.5302734375\n",
      "Batch 37: loss = 1.633779764175415, acc = 0.5009765625\n",
      "Batch 38: loss = 1.6549129486083984, acc = 0.5126953125\n",
      "Batch 39: loss = 1.6414275169372559, acc = 0.515625\n",
      "Batch 40: loss = 1.575272560119629, acc = 0.53125\n",
      "Batch 41: loss = 1.6003010272979736, acc = 0.521484375\n",
      "Saved checkpoint to weights_eminem_input.txt.20.h5\n",
      "\n",
      "Epoch 21/100\n",
      "Batch 1: loss = 1.6353516578674316, acc = 0.541015625\n",
      "Batch 2: loss = 1.548691749572754, acc = 0.5537109375\n",
      "Batch 3: loss = 1.6009584665298462, acc = 0.5380859375\n",
      "Batch 4: loss = 1.534894347190857, acc = 0.546875\n",
      "Batch 5: loss = 1.4762296676635742, acc = 0.5654296875\n",
      "Batch 6: loss = 1.5105382204055786, acc = 0.5869140625\n",
      "Batch 7: loss = 1.4597657918930054, acc = 0.5771484375\n",
      "Batch 8: loss = 1.393816590309143, acc = 0.603515625\n",
      "Batch 9: loss = 1.5114517211914062, acc = 0.544921875\n",
      "Batch 10: loss = 1.542067289352417, acc = 0.560546875\n",
      "Batch 11: loss = 1.679539680480957, acc = 0.48828125\n",
      "Batch 12: loss = 1.5690141916275024, acc = 0.5234375\n",
      "Batch 13: loss = 1.586179494857788, acc = 0.5244140625\n",
      "Batch 14: loss = 1.5777454376220703, acc = 0.5224609375\n",
      "Batch 15: loss = 1.5394322872161865, acc = 0.5498046875\n",
      "Batch 16: loss = 1.57607102394104, acc = 0.529296875\n",
      "Batch 17: loss = 1.5812277793884277, acc = 0.533203125\n",
      "Batch 18: loss = 1.592248797416687, acc = 0.5341796875\n",
      "Batch 19: loss = 1.671066164970398, acc = 0.5009765625\n",
      "Batch 20: loss = 1.6163311004638672, acc = 0.5322265625\n",
      "Batch 21: loss = 1.6650798320770264, acc = 0.5146484375\n",
      "Batch 22: loss = 1.538818120956421, acc = 0.5361328125\n",
      "Batch 23: loss = 1.5467934608459473, acc = 0.564453125\n",
      "Batch 24: loss = 1.5306832790374756, acc = 0.5546875\n",
      "Batch 25: loss = 1.620624303817749, acc = 0.52734375\n",
      "Batch 26: loss = 1.4381802082061768, acc = 0.576171875\n",
      "Batch 27: loss = 1.3887518644332886, acc = 0.5927734375\n",
      "Batch 28: loss = 1.4799537658691406, acc = 0.55859375\n",
      "Batch 29: loss = 1.4623750448226929, acc = 0.5732421875\n",
      "Batch 30: loss = 1.4340747594833374, acc = 0.5791015625\n",
      "Batch 31: loss = 1.461321473121643, acc = 0.578125\n",
      "Batch 32: loss = 1.4575324058532715, acc = 0.5634765625\n",
      "Batch 33: loss = 1.6479077339172363, acc = 0.5\n",
      "Batch 34: loss = 1.6703823804855347, acc = 0.4990234375\n",
      "Batch 35: loss = 1.6108520030975342, acc = 0.5283203125\n",
      "Batch 36: loss = 1.4910874366760254, acc = 0.5517578125\n",
      "Batch 37: loss = 1.6131579875946045, acc = 0.5185546875\n",
      "Batch 38: loss = 1.6240900754928589, acc = 0.515625\n",
      "Batch 39: loss = 1.6000092029571533, acc = 0.5341796875\n",
      "Batch 40: loss = 1.5185413360595703, acc = 0.5498046875\n",
      "Batch 41: loss = 1.5705804824829102, acc = 0.53515625\n",
      "\n",
      "Epoch 22/100\n",
      "Batch 1: loss = 1.601102352142334, acc = 0.5458984375\n",
      "Batch 2: loss = 1.4706602096557617, acc = 0.5927734375\n",
      "Batch 3: loss = 1.555783748626709, acc = 0.556640625\n",
      "Batch 4: loss = 1.4924719333648682, acc = 0.5634765625\n",
      "Batch 5: loss = 1.443556547164917, acc = 0.5693359375\n",
      "Batch 6: loss = 1.4291898012161255, acc = 0.591796875\n",
      "Batch 7: loss = 1.4077684879302979, acc = 0.5908203125\n",
      "Batch 8: loss = 1.3430492877960205, acc = 0.611328125\n",
      "Batch 9: loss = 1.4594873189926147, acc = 0.5732421875\n",
      "Batch 10: loss = 1.4978909492492676, acc = 0.5751953125\n",
      "Batch 11: loss = 1.646122694015503, acc = 0.4912109375\n",
      "Batch 12: loss = 1.5424106121063232, acc = 0.5341796875\n",
      "Batch 13: loss = 1.5213452577590942, acc = 0.5517578125\n",
      "Batch 14: loss = 1.5143253803253174, acc = 0.55859375\n",
      "Batch 15: loss = 1.5209962129592896, acc = 0.5576171875\n",
      "Batch 16: loss = 1.5336164236068726, acc = 0.541015625\n",
      "Batch 17: loss = 1.5169726610183716, acc = 0.5546875\n",
      "Batch 18: loss = 1.5208759307861328, acc = 0.5595703125\n",
      "Batch 19: loss = 1.6353191137313843, acc = 0.5048828125\n",
      "Batch 20: loss = 1.5811576843261719, acc = 0.54296875\n",
      "Batch 21: loss = 1.6212877035140991, acc = 0.509765625\n",
      "Batch 22: loss = 1.5060768127441406, acc = 0.5556640625\n",
      "Batch 23: loss = 1.4907739162445068, acc = 0.5634765625\n",
      "Batch 24: loss = 1.480879306793213, acc = 0.5654296875\n",
      "Batch 25: loss = 1.5870823860168457, acc = 0.5380859375\n",
      "Batch 26: loss = 1.3853187561035156, acc = 0.6015625\n",
      "Batch 27: loss = 1.3333854675292969, acc = 0.6025390625\n",
      "Batch 28: loss = 1.4682633876800537, acc = 0.57421875\n",
      "Batch 29: loss = 1.4095942974090576, acc = 0.5947265625\n",
      "Batch 30: loss = 1.40542471408844, acc = 0.5966796875\n",
      "Batch 31: loss = 1.4116723537445068, acc = 0.5947265625\n",
      "Batch 32: loss = 1.4413191080093384, acc = 0.5849609375\n",
      "Batch 33: loss = 1.584420919418335, acc = 0.529296875\n",
      "Batch 34: loss = 1.6534345149993896, acc = 0.513671875\n",
      "Batch 35: loss = 1.5755236148834229, acc = 0.5400390625\n",
      "Batch 36: loss = 1.4464168548583984, acc = 0.564453125\n",
      "Batch 37: loss = 1.5764187574386597, acc = 0.53125\n",
      "Batch 38: loss = 1.5847851037979126, acc = 0.5537109375\n",
      "Batch 39: loss = 1.5365382432937622, acc = 0.5439453125\n",
      "Batch 40: loss = 1.4868309497833252, acc = 0.55859375\n",
      "Batch 41: loss = 1.5653457641601562, acc = 0.533203125\n",
      "\n",
      "Epoch 23/100\n",
      "Batch 1: loss = 1.5965138673782349, acc = 0.54296875\n",
      "Batch 2: loss = 1.439239740371704, acc = 0.5859375\n",
      "Batch 3: loss = 1.4742095470428467, acc = 0.5869140625\n",
      "Batch 4: loss = 1.436055064201355, acc = 0.578125\n",
      "Batch 5: loss = 1.3963849544525146, acc = 0.595703125\n",
      "Batch 6: loss = 1.3925641775131226, acc = 0.6142578125\n",
      "Batch 7: loss = 1.3617653846740723, acc = 0.59765625\n",
      "Batch 8: loss = 1.3267953395843506, acc = 0.625\n",
      "Batch 9: loss = 1.4475877285003662, acc = 0.5712890625\n",
      "Batch 10: loss = 1.482213020324707, acc = 0.5791015625\n",
      "Batch 11: loss = 1.633401870727539, acc = 0.4921875\n",
      "Batch 12: loss = 1.491218090057373, acc = 0.544921875\n",
      "Batch 13: loss = 1.4665443897247314, acc = 0.5546875\n",
      "Batch 14: loss = 1.4713115692138672, acc = 0.5517578125\n",
      "Batch 15: loss = 1.4732556343078613, acc = 0.5771484375\n",
      "Batch 16: loss = 1.474473237991333, acc = 0.57421875\n",
      "Batch 17: loss = 1.4943020343780518, acc = 0.572265625\n",
      "Batch 18: loss = 1.5041903257369995, acc = 0.5595703125\n",
      "Batch 19: loss = 1.6112940311431885, acc = 0.5107421875\n",
      "Batch 20: loss = 1.5638973712921143, acc = 0.544921875\n",
      "Batch 21: loss = 1.6073565483093262, acc = 0.5185546875\n",
      "Batch 22: loss = 1.490177035331726, acc = 0.560546875\n",
      "Batch 23: loss = 1.4644620418548584, acc = 0.5771484375\n",
      "Batch 24: loss = 1.4236270189285278, acc = 0.5830078125\n",
      "Batch 25: loss = 1.5186901092529297, acc = 0.5576171875\n",
      "Batch 26: loss = 1.355210781097412, acc = 0.59375\n",
      "Batch 27: loss = 1.3048369884490967, acc = 0.6318359375\n",
      "Batch 28: loss = 1.4377241134643555, acc = 0.58203125\n",
      "Batch 29: loss = 1.3823938369750977, acc = 0.6083984375\n",
      "Batch 30: loss = 1.3722304105758667, acc = 0.599609375\n",
      "Batch 31: loss = 1.3991365432739258, acc = 0.595703125\n",
      "Batch 32: loss = 1.4075229167938232, acc = 0.5703125\n",
      "Batch 33: loss = 1.5131884813308716, acc = 0.5458984375\n",
      "Batch 34: loss = 1.6061968803405762, acc = 0.517578125\n",
      "Batch 35: loss = 1.5284922122955322, acc = 0.54296875\n",
      "Batch 36: loss = 1.3873094320297241, acc = 0.5888671875\n",
      "Batch 37: loss = 1.5356698036193848, acc = 0.546875\n",
      "Batch 38: loss = 1.5346845388412476, acc = 0.541015625\n",
      "Batch 39: loss = 1.4979171752929688, acc = 0.560546875\n",
      "Batch 40: loss = 1.435283899307251, acc = 0.578125\n",
      "Batch 41: loss = 1.5492186546325684, acc = 0.5263671875\n",
      "\n",
      "Epoch 24/100\n",
      "Batch 1: loss = 1.5424553155899048, acc = 0.55859375\n",
      "Batch 2: loss = 1.412731647491455, acc = 0.583984375\n",
      "Batch 3: loss = 1.460336446762085, acc = 0.572265625\n",
      "Batch 4: loss = 1.4298605918884277, acc = 0.5771484375\n",
      "Batch 5: loss = 1.328413963317871, acc = 0.6103515625\n",
      "Batch 6: loss = 1.3279473781585693, acc = 0.6318359375\n",
      "Batch 7: loss = 1.3691916465759277, acc = 0.5927734375\n",
      "Batch 8: loss = 1.2784892320632935, acc = 0.6328125\n",
      "Batch 9: loss = 1.4281294345855713, acc = 0.57421875\n",
      "Batch 10: loss = 1.4327805042266846, acc = 0.5771484375\n",
      "Batch 11: loss = 1.5949771404266357, acc = 0.5087890625\n",
      "Batch 12: loss = 1.4802932739257812, acc = 0.5517578125\n",
      "Batch 13: loss = 1.4425865411758423, acc = 0.5634765625\n",
      "Batch 14: loss = 1.4566032886505127, acc = 0.5595703125\n",
      "Batch 15: loss = 1.4313955307006836, acc = 0.603515625\n",
      "Batch 16: loss = 1.4654779434204102, acc = 0.55859375\n",
      "Batch 17: loss = 1.4467954635620117, acc = 0.576171875\n",
      "Batch 18: loss = 1.467392921447754, acc = 0.5693359375\n",
      "Batch 19: loss = 1.5589599609375, acc = 0.5419921875\n",
      "Batch 20: loss = 1.5171279907226562, acc = 0.53515625\n",
      "Batch 21: loss = 1.5473204851150513, acc = 0.5322265625\n",
      "Batch 22: loss = 1.4671428203582764, acc = 0.5458984375\n",
      "Batch 23: loss = 1.4689511060714722, acc = 0.576171875\n",
      "Batch 24: loss = 1.4270657300949097, acc = 0.5849609375\n",
      "Batch 25: loss = 1.4955623149871826, acc = 0.57421875\n",
      "Batch 26: loss = 1.2852928638458252, acc = 0.619140625\n",
      "Batch 27: loss = 1.2412354946136475, acc = 0.638671875\n",
      "Batch 28: loss = 1.3877038955688477, acc = 0.5966796875\n",
      "Batch 29: loss = 1.3508095741271973, acc = 0.6220703125\n",
      "Batch 30: loss = 1.3437438011169434, acc = 0.619140625\n",
      "Batch 31: loss = 1.3757480382919312, acc = 0.6015625\n",
      "Batch 32: loss = 1.3761436939239502, acc = 0.5908203125\n",
      "Batch 33: loss = 1.4956098794937134, acc = 0.5546875\n",
      "Batch 34: loss = 1.5930442810058594, acc = 0.537109375\n",
      "Batch 35: loss = 1.4788681268692017, acc = 0.5673828125\n",
      "Batch 36: loss = 1.3687560558319092, acc = 0.6015625\n",
      "Batch 37: loss = 1.473435640335083, acc = 0.55859375\n",
      "Batch 38: loss = 1.509383201599121, acc = 0.541015625\n",
      "Batch 39: loss = 1.4662737846374512, acc = 0.5625\n",
      "Batch 40: loss = 1.4097769260406494, acc = 0.5712890625\n",
      "Batch 41: loss = 1.4959526062011719, acc = 0.54296875\n",
      "\n",
      "Epoch 25/100\n",
      "Batch 1: loss = 1.4875229597091675, acc = 0.5751953125\n",
      "Batch 2: loss = 1.379881501197815, acc = 0.58984375\n",
      "Batch 3: loss = 1.4316174983978271, acc = 0.5751953125\n",
      "Batch 4: loss = 1.3989520072937012, acc = 0.5888671875\n",
      "Batch 5: loss = 1.3411476612091064, acc = 0.6142578125\n",
      "Batch 6: loss = 1.3096706867218018, acc = 0.6240234375\n",
      "Batch 7: loss = 1.293811321258545, acc = 0.6328125\n",
      "Batch 8: loss = 1.219539999961853, acc = 0.6533203125\n",
      "Batch 9: loss = 1.3687942028045654, acc = 0.599609375\n",
      "Batch 10: loss = 1.384141206741333, acc = 0.5908203125\n",
      "Batch 11: loss = 1.5446434020996094, acc = 0.5263671875\n",
      "Batch 12: loss = 1.4368083477020264, acc = 0.5546875\n",
      "Batch 13: loss = 1.4333910942077637, acc = 0.587890625\n",
      "Batch 14: loss = 1.4035910367965698, acc = 0.5869140625\n",
      "Batch 15: loss = 1.4063506126403809, acc = 0.603515625\n",
      "Batch 16: loss = 1.4211455583572388, acc = 0.578125\n",
      "Batch 17: loss = 1.4209060668945312, acc = 0.5703125\n",
      "Batch 18: loss = 1.4336615800857544, acc = 0.57421875\n",
      "Batch 19: loss = 1.5292097330093384, acc = 0.5400390625\n",
      "Batch 20: loss = 1.5276806354522705, acc = 0.5654296875\n",
      "Batch 21: loss = 1.5114948749542236, acc = 0.5341796875\n",
      "Batch 22: loss = 1.39873206615448, acc = 0.5810546875\n",
      "Batch 23: loss = 1.4019689559936523, acc = 0.5888671875\n",
      "Batch 24: loss = 1.3590710163116455, acc = 0.609375\n",
      "Batch 25: loss = 1.4483683109283447, acc = 0.58203125\n",
      "Batch 26: loss = 1.2431204319000244, acc = 0.6318359375\n",
      "Batch 27: loss = 1.2126405239105225, acc = 0.634765625\n",
      "Batch 28: loss = 1.3096413612365723, acc = 0.61328125\n",
      "Batch 29: loss = 1.3007838726043701, acc = 0.6328125\n",
      "Batch 30: loss = 1.2944293022155762, acc = 0.625\n",
      "Batch 31: loss = 1.328332781791687, acc = 0.6103515625\n",
      "Batch 32: loss = 1.296579122543335, acc = 0.619140625\n",
      "Batch 33: loss = 1.479854941368103, acc = 0.564453125\n",
      "Batch 34: loss = 1.5468616485595703, acc = 0.54296875\n",
      "Batch 35: loss = 1.4194986820220947, acc = 0.576171875\n",
      "Batch 36: loss = 1.3137130737304688, acc = 0.60546875\n",
      "Batch 37: loss = 1.4428870677947998, acc = 0.576171875\n",
      "Batch 38: loss = 1.437811017036438, acc = 0.5712890625\n",
      "Batch 39: loss = 1.427186369895935, acc = 0.5673828125\n",
      "Batch 40: loss = 1.3713932037353516, acc = 0.5888671875\n",
      "Batch 41: loss = 1.4301772117614746, acc = 0.5693359375\n",
      "\n",
      "Epoch 26/100\n",
      "Batch 1: loss = 1.4274039268493652, acc = 0.6005859375\n",
      "Batch 2: loss = 1.3186784982681274, acc = 0.6181640625\n",
      "Batch 3: loss = 1.3459454774856567, acc = 0.6103515625\n",
      "Batch 4: loss = 1.335562825202942, acc = 0.609375\n",
      "Batch 5: loss = 1.277940034866333, acc = 0.625\n",
      "Batch 6: loss = 1.266840934753418, acc = 0.6435546875\n",
      "Batch 7: loss = 1.2602242231369019, acc = 0.630859375\n",
      "Batch 8: loss = 1.2228251695632935, acc = 0.6416015625\n",
      "Batch 9: loss = 1.3142516613006592, acc = 0.611328125\n",
      "Batch 10: loss = 1.3307011127471924, acc = 0.6259765625\n",
      "Batch 11: loss = 1.5322339534759521, acc = 0.5498046875\n",
      "Batch 12: loss = 1.4150995016098022, acc = 0.5673828125\n",
      "Batch 13: loss = 1.4066216945648193, acc = 0.58203125\n",
      "Batch 14: loss = 1.3607125282287598, acc = 0.6142578125\n",
      "Batch 15: loss = 1.3414608240127563, acc = 0.61328125\n",
      "Batch 16: loss = 1.3298097848892212, acc = 0.6005859375\n",
      "Batch 17: loss = 1.361532211303711, acc = 0.5859375\n",
      "Batch 18: loss = 1.3636665344238281, acc = 0.6044921875\n",
      "Batch 19: loss = 1.469684362411499, acc = 0.5537109375\n",
      "Batch 20: loss = 1.4314579963684082, acc = 0.578125\n",
      "Batch 21: loss = 1.4732182025909424, acc = 0.54296875\n",
      "Batch 22: loss = 1.3656296730041504, acc = 0.5869140625\n",
      "Batch 23: loss = 1.358381748199463, acc = 0.60546875\n",
      "Batch 24: loss = 1.322381854057312, acc = 0.6123046875\n",
      "Batch 25: loss = 1.4079184532165527, acc = 0.59375\n",
      "Batch 26: loss = 1.2063477039337158, acc = 0.65234375\n",
      "Batch 27: loss = 1.1558480262756348, acc = 0.6640625\n",
      "Batch 28: loss = 1.287904143333435, acc = 0.630859375\n",
      "Batch 29: loss = 1.254932165145874, acc = 0.6484375\n",
      "Batch 30: loss = 1.235426902770996, acc = 0.6328125\n",
      "Batch 31: loss = 1.2678380012512207, acc = 0.62890625\n",
      "Batch 32: loss = 1.2599306106567383, acc = 0.6298828125\n",
      "Batch 33: loss = 1.4409441947937012, acc = 0.580078125\n",
      "Batch 34: loss = 1.5040454864501953, acc = 0.5517578125\n",
      "Batch 35: loss = 1.4350762367248535, acc = 0.5908203125\n",
      "Batch 36: loss = 1.2737312316894531, acc = 0.6142578125\n",
      "Batch 37: loss = 1.394684076309204, acc = 0.58203125\n",
      "Batch 38: loss = 1.3940098285675049, acc = 0.572265625\n",
      "Batch 39: loss = 1.3654093742370605, acc = 0.6103515625\n",
      "Batch 40: loss = 1.3525261878967285, acc = 0.576171875\n",
      "Batch 41: loss = 1.3789491653442383, acc = 0.5673828125\n",
      "\n",
      "Epoch 27/100\n",
      "Batch 1: loss = 1.3634059429168701, acc = 0.611328125\n",
      "Batch 2: loss = 1.2772291898727417, acc = 0.6298828125\n",
      "Batch 3: loss = 1.2929290533065796, acc = 0.623046875\n",
      "Batch 4: loss = 1.2490365505218506, acc = 0.6552734375\n",
      "Batch 5: loss = 1.2161403894424438, acc = 0.6416015625\n",
      "Batch 6: loss = 1.2044554948806763, acc = 0.677734375\n",
      "Batch 7: loss = 1.2208353281021118, acc = 0.642578125\n",
      "Batch 8: loss = 1.17962646484375, acc = 0.6572265625\n",
      "Batch 9: loss = 1.279916524887085, acc = 0.6376953125\n",
      "Batch 10: loss = 1.3227781057357788, acc = 0.6005859375\n",
      "Batch 11: loss = 1.4894731044769287, acc = 0.54296875\n",
      "Batch 12: loss = 1.3333706855773926, acc = 0.5849609375\n",
      "Batch 13: loss = 1.3471193313598633, acc = 0.595703125\n",
      "Batch 14: loss = 1.301732063293457, acc = 0.6044921875\n",
      "Batch 15: loss = 1.3511812686920166, acc = 0.6181640625\n",
      "Batch 16: loss = 1.3193275928497314, acc = 0.591796875\n",
      "Batch 17: loss = 1.3418796062469482, acc = 0.6025390625\n",
      "Batch 18: loss = 1.3441641330718994, acc = 0.6044921875\n",
      "Batch 19: loss = 1.4429031610488892, acc = 0.5634765625\n",
      "Batch 20: loss = 1.457682728767395, acc = 0.5576171875\n",
      "Batch 21: loss = 1.420745849609375, acc = 0.572265625\n",
      "Batch 22: loss = 1.38149094581604, acc = 0.5771484375\n",
      "Batch 23: loss = 1.3566291332244873, acc = 0.6015625\n",
      "Batch 24: loss = 1.3048474788665771, acc = 0.6162109375\n",
      "Batch 25: loss = 1.3718087673187256, acc = 0.5791015625\n",
      "Batch 26: loss = 1.168397307395935, acc = 0.646484375\n",
      "Batch 27: loss = 1.1393603086471558, acc = 0.6630859375\n",
      "Batch 28: loss = 1.2750627994537354, acc = 0.6259765625\n",
      "Batch 29: loss = 1.2425024509429932, acc = 0.6494140625\n",
      "Batch 30: loss = 1.2042832374572754, acc = 0.6513671875\n",
      "Batch 31: loss = 1.2503466606140137, acc = 0.642578125\n",
      "Batch 32: loss = 1.2488408088684082, acc = 0.6416015625\n",
      "Batch 33: loss = 1.3867541551589966, acc = 0.5771484375\n",
      "Batch 34: loss = 1.4683735370635986, acc = 0.5625\n",
      "Batch 35: loss = 1.4119694232940674, acc = 0.5810546875\n",
      "Batch 36: loss = 1.2427161931991577, acc = 0.6376953125\n",
      "Batch 37: loss = 1.3596140146255493, acc = 0.591796875\n",
      "Batch 38: loss = 1.3345158100128174, acc = 0.5830078125\n",
      "Batch 39: loss = 1.348401427268982, acc = 0.5908203125\n",
      "Batch 40: loss = 1.2984358072280884, acc = 0.5966796875\n",
      "Batch 41: loss = 1.3669414520263672, acc = 0.5830078125\n",
      "\n",
      "Epoch 28/100\n",
      "Batch 1: loss = 1.3636661767959595, acc = 0.62109375\n",
      "Batch 2: loss = 1.2226698398590088, acc = 0.6513671875\n",
      "Batch 3: loss = 1.2565624713897705, acc = 0.6259765625\n",
      "Batch 4: loss = 1.2669576406478882, acc = 0.642578125\n",
      "Batch 5: loss = 1.182316541671753, acc = 0.6552734375\n",
      "Batch 6: loss = 1.1852504014968872, acc = 0.671875\n",
      "Batch 7: loss = 1.1912639141082764, acc = 0.6513671875\n",
      "Batch 8: loss = 1.1697736978530884, acc = 0.6669921875\n",
      "Batch 9: loss = 1.2561748027801514, acc = 0.630859375\n",
      "Batch 10: loss = 1.2878162860870361, acc = 0.615234375\n",
      "Batch 11: loss = 1.4472242593765259, acc = 0.572265625\n",
      "Batch 12: loss = 1.323777198791504, acc = 0.5966796875\n",
      "Batch 13: loss = 1.3158438205718994, acc = 0.6044921875\n",
      "Batch 14: loss = 1.2628474235534668, acc = 0.6220703125\n",
      "Batch 15: loss = 1.2983019351959229, acc = 0.6259765625\n",
      "Batch 16: loss = 1.2907428741455078, acc = 0.6044921875\n",
      "Batch 17: loss = 1.321973443031311, acc = 0.6044921875\n",
      "Batch 18: loss = 1.3456939458847046, acc = 0.595703125\n",
      "Batch 19: loss = 1.3988924026489258, acc = 0.5625\n",
      "Batch 20: loss = 1.3837281465530396, acc = 0.5849609375\n",
      "Batch 21: loss = 1.3869028091430664, acc = 0.564453125\n",
      "Batch 22: loss = 1.3115530014038086, acc = 0.6123046875\n",
      "Batch 23: loss = 1.295398473739624, acc = 0.619140625\n",
      "Batch 24: loss = 1.2608652114868164, acc = 0.6201171875\n",
      "Batch 25: loss = 1.3154528141021729, acc = 0.619140625\n",
      "Batch 26: loss = 1.1468416452407837, acc = 0.66796875\n",
      "Batch 27: loss = 1.1281707286834717, acc = 0.671875\n",
      "Batch 28: loss = 1.2212705612182617, acc = 0.6357421875\n",
      "Batch 29: loss = 1.2421810626983643, acc = 0.634765625\n",
      "Batch 30: loss = 1.2137794494628906, acc = 0.64453125\n",
      "Batch 31: loss = 1.267099142074585, acc = 0.6181640625\n",
      "Batch 32: loss = 1.2053035497665405, acc = 0.640625\n",
      "Batch 33: loss = 1.3243093490600586, acc = 0.59765625\n",
      "Batch 34: loss = 1.4137883186340332, acc = 0.5703125\n",
      "Batch 35: loss = 1.3233877420425415, acc = 0.5859375\n",
      "Batch 36: loss = 1.2046401500701904, acc = 0.640625\n",
      "Batch 37: loss = 1.334519863128662, acc = 0.6181640625\n",
      "Batch 38: loss = 1.3172495365142822, acc = 0.6015625\n",
      "Batch 39: loss = 1.3434423208236694, acc = 0.6025390625\n",
      "Batch 40: loss = 1.2645790576934814, acc = 0.609375\n",
      "Batch 41: loss = 1.3220760822296143, acc = 0.5908203125\n",
      "\n",
      "Epoch 29/100\n",
      "Batch 1: loss = 1.3195738792419434, acc = 0.625\n",
      "Batch 2: loss = 1.2115254402160645, acc = 0.646484375\n",
      "Batch 3: loss = 1.206972360610962, acc = 0.6552734375\n",
      "Batch 4: loss = 1.215551733970642, acc = 0.65234375\n",
      "Batch 5: loss = 1.1579655408859253, acc = 0.6630859375\n",
      "Batch 6: loss = 1.1388022899627686, acc = 0.689453125\n",
      "Batch 7: loss = 1.1480271816253662, acc = 0.6669921875\n",
      "Batch 8: loss = 1.1453083753585815, acc = 0.68359375\n",
      "Batch 9: loss = 1.2113069295883179, acc = 0.6572265625\n",
      "Batch 10: loss = 1.2557270526885986, acc = 0.6220703125\n",
      "Batch 11: loss = 1.4454967975616455, acc = 0.564453125\n",
      "Batch 12: loss = 1.3042819499969482, acc = 0.6005859375\n",
      "Batch 13: loss = 1.3049049377441406, acc = 0.609375\n",
      "Batch 14: loss = 1.2524523735046387, acc = 0.6220703125\n",
      "Batch 15: loss = 1.2043434381484985, acc = 0.6533203125\n",
      "Batch 16: loss = 1.2402591705322266, acc = 0.6279296875\n",
      "Batch 17: loss = 1.288151741027832, acc = 0.619140625\n",
      "Batch 18: loss = 1.2756017446517944, acc = 0.6318359375\n",
      "Batch 19: loss = 1.4134273529052734, acc = 0.5732421875\n",
      "Batch 20: loss = 1.3739118576049805, acc = 0.5947265625\n",
      "Batch 21: loss = 1.3611892461776733, acc = 0.5771484375\n",
      "Batch 22: loss = 1.2940490245819092, acc = 0.6064453125\n",
      "Batch 23: loss = 1.24740469455719, acc = 0.6435546875\n",
      "Batch 24: loss = 1.2128996849060059, acc = 0.6435546875\n",
      "Batch 25: loss = 1.260762333869934, acc = 0.6201171875\n",
      "Batch 26: loss = 1.1044795513153076, acc = 0.677734375\n",
      "Batch 27: loss = 1.0883828401565552, acc = 0.6904296875\n",
      "Batch 28: loss = 1.1833982467651367, acc = 0.6552734375\n",
      "Batch 29: loss = 1.18873929977417, acc = 0.6484375\n",
      "Batch 30: loss = 1.1653563976287842, acc = 0.6474609375\n",
      "Batch 31: loss = 1.2272353172302246, acc = 0.65625\n",
      "Batch 32: loss = 1.1809331178665161, acc = 0.6474609375\n",
      "Batch 33: loss = 1.3504644632339478, acc = 0.591796875\n",
      "Batch 34: loss = 1.4070346355438232, acc = 0.580078125\n",
      "Batch 35: loss = 1.2999260425567627, acc = 0.60546875\n",
      "Batch 36: loss = 1.1731082201004028, acc = 0.6474609375\n",
      "Batch 37: loss = 1.3030097484588623, acc = 0.6357421875\n",
      "Batch 38: loss = 1.2995514869689941, acc = 0.6025390625\n",
      "Batch 39: loss = 1.2757333517074585, acc = 0.6220703125\n",
      "Batch 40: loss = 1.2594032287597656, acc = 0.6279296875\n",
      "Batch 41: loss = 1.311568260192871, acc = 0.599609375\n",
      "\n",
      "Epoch 30/100\n",
      "Batch 1: loss = 1.2653353214263916, acc = 0.640625\n",
      "Batch 2: loss = 1.1741790771484375, acc = 0.669921875\n",
      "Batch 3: loss = 1.2040244340896606, acc = 0.640625\n",
      "Batch 4: loss = 1.187166690826416, acc = 0.671875\n",
      "Batch 5: loss = 1.125481367111206, acc = 0.6611328125\n",
      "Batch 6: loss = 1.1082103252410889, acc = 0.681640625\n",
      "Batch 7: loss = 1.0707324743270874, acc = 0.6806640625\n",
      "Batch 8: loss = 1.096956729888916, acc = 0.6748046875\n",
      "Batch 9: loss = 1.1343344449996948, acc = 0.669921875\n",
      "Batch 10: loss = 1.1970890760421753, acc = 0.650390625\n",
      "Batch 11: loss = 1.3736567497253418, acc = 0.5966796875\n",
      "Batch 12: loss = 1.2632877826690674, acc = 0.6142578125\n",
      "Batch 13: loss = 1.2643882036209106, acc = 0.6240234375\n",
      "Batch 14: loss = 1.199636697769165, acc = 0.6328125\n",
      "Batch 15: loss = 1.210277795791626, acc = 0.6484375\n",
      "Batch 16: loss = 1.2187864780426025, acc = 0.630859375\n",
      "Batch 17: loss = 1.250896692276001, acc = 0.626953125\n",
      "Batch 18: loss = 1.2313380241394043, acc = 0.623046875\n",
      "Batch 19: loss = 1.3439956903457642, acc = 0.5751953125\n",
      "Batch 20: loss = 1.2970046997070312, acc = 0.60546875\n",
      "Batch 21: loss = 1.3250030279159546, acc = 0.5888671875\n",
      "Batch 22: loss = 1.2583622932434082, acc = 0.626953125\n",
      "Batch 23: loss = 1.2647972106933594, acc = 0.6279296875\n",
      "Batch 24: loss = 1.174079418182373, acc = 0.6533203125\n",
      "Batch 25: loss = 1.2060152292251587, acc = 0.6396484375\n",
      "Batch 26: loss = 1.052642822265625, acc = 0.6923828125\n",
      "Batch 27: loss = 1.0204169750213623, acc = 0.7109375\n",
      "Batch 28: loss = 1.1809594631195068, acc = 0.6591796875\n",
      "Batch 29: loss = 1.150932788848877, acc = 0.666015625\n",
      "Batch 30: loss = 1.1340571641921997, acc = 0.6630859375\n",
      "Batch 31: loss = 1.161332368850708, acc = 0.65625\n",
      "Batch 32: loss = 1.1361653804779053, acc = 0.662109375\n",
      "Batch 33: loss = 1.2903752326965332, acc = 0.611328125\n",
      "Batch 34: loss = 1.3550678491592407, acc = 0.58984375\n",
      "Batch 35: loss = 1.2674555778503418, acc = 0.6103515625\n",
      "Batch 36: loss = 1.147169589996338, acc = 0.6689453125\n",
      "Batch 37: loss = 1.2832815647125244, acc = 0.6259765625\n",
      "Batch 38: loss = 1.2308554649353027, acc = 0.6318359375\n",
      "Batch 39: loss = 1.2330873012542725, acc = 0.6396484375\n",
      "Batch 40: loss = 1.2259600162506104, acc = 0.6279296875\n",
      "Batch 41: loss = 1.2563719749450684, acc = 0.6201171875\n",
      "Saved checkpoint to weights_eminem_input.txt.30.h5\n",
      "\n",
      "Epoch 31/100\n",
      "Batch 1: loss = 1.244945764541626, acc = 0.638671875\n",
      "Batch 2: loss = 1.122459888458252, acc = 0.671875\n",
      "Batch 3: loss = 1.1541545391082764, acc = 0.6630859375\n",
      "Batch 4: loss = 1.117988109588623, acc = 0.681640625\n",
      "Batch 5: loss = 1.0643525123596191, acc = 0.69140625\n",
      "Batch 6: loss = 1.0662516355514526, acc = 0.703125\n",
      "Batch 7: loss = 1.084273099899292, acc = 0.6904296875\n",
      "Batch 8: loss = 1.0659503936767578, acc = 0.6923828125\n",
      "Batch 9: loss = 1.1558113098144531, acc = 0.64453125\n",
      "Batch 10: loss = 1.1573810577392578, acc = 0.6474609375\n",
      "Batch 11: loss = 1.346229076385498, acc = 0.59375\n",
      "Batch 12: loss = 1.2274160385131836, acc = 0.626953125\n",
      "Batch 13: loss = 1.2431472539901733, acc = 0.63671875\n",
      "Batch 14: loss = 1.2034469842910767, acc = 0.6474609375\n",
      "Batch 15: loss = 1.1456081867218018, acc = 0.67578125\n",
      "Batch 16: loss = 1.161966323852539, acc = 0.6572265625\n",
      "Batch 17: loss = 1.21830415725708, acc = 0.640625\n",
      "Batch 18: loss = 1.2060232162475586, acc = 0.6328125\n",
      "Batch 19: loss = 1.2904170751571655, acc = 0.6005859375\n",
      "Batch 20: loss = 1.2584514617919922, acc = 0.6181640625\n",
      "Batch 21: loss = 1.289000391960144, acc = 0.6103515625\n",
      "Batch 22: loss = 1.2115356922149658, acc = 0.63671875\n",
      "Batch 23: loss = 1.1752326488494873, acc = 0.642578125\n",
      "Batch 24: loss = 1.1175806522369385, acc = 0.662109375\n",
      "Batch 25: loss = 1.1869382858276367, acc = 0.6572265625\n",
      "Batch 26: loss = 1.0401731729507446, acc = 0.6904296875\n",
      "Batch 27: loss = 0.9941917061805725, acc = 0.7109375\n",
      "Batch 28: loss = 1.1019232273101807, acc = 0.681640625\n",
      "Batch 29: loss = 1.0976978540420532, acc = 0.6865234375\n",
      "Batch 30: loss = 1.086759328842163, acc = 0.681640625\n",
      "Batch 31: loss = 1.1213064193725586, acc = 0.67578125\n",
      "Batch 32: loss = 1.0753521919250488, acc = 0.6845703125\n",
      "Batch 33: loss = 1.2740318775177002, acc = 0.623046875\n",
      "Batch 34: loss = 1.3099331855773926, acc = 0.6123046875\n",
      "Batch 35: loss = 1.2317965030670166, acc = 0.638671875\n",
      "Batch 36: loss = 1.078287959098816, acc = 0.6875\n",
      "Batch 37: loss = 1.1871116161346436, acc = 0.6513671875\n",
      "Batch 38: loss = 1.2249832153320312, acc = 0.6259765625\n",
      "Batch 39: loss = 1.2199782133102417, acc = 0.623046875\n",
      "Batch 40: loss = 1.2118148803710938, acc = 0.6162109375\n",
      "Batch 41: loss = 1.2601789236068726, acc = 0.59375\n",
      "\n",
      "Epoch 32/100\n",
      "Batch 1: loss = 1.2026889324188232, acc = 0.6474609375\n",
      "Batch 2: loss = 1.0656383037567139, acc = 0.67578125\n",
      "Batch 3: loss = 1.1132161617279053, acc = 0.6728515625\n",
      "Batch 4: loss = 1.0837571620941162, acc = 0.6826171875\n",
      "Batch 5: loss = 1.0386489629745483, acc = 0.7060546875\n",
      "Batch 6: loss = 0.9943839907646179, acc = 0.7265625\n",
      "Batch 7: loss = 1.0445425510406494, acc = 0.6962890625\n",
      "Batch 8: loss = 1.035735845565796, acc = 0.701171875\n",
      "Batch 9: loss = 1.1458830833435059, acc = 0.673828125\n",
      "Batch 10: loss = 1.1250147819519043, acc = 0.673828125\n",
      "Batch 11: loss = 1.297708511352539, acc = 0.599609375\n",
      "Batch 12: loss = 1.1889452934265137, acc = 0.630859375\n",
      "Batch 13: loss = 1.1988309621810913, acc = 0.626953125\n",
      "Batch 14: loss = 1.107348918914795, acc = 0.67578125\n",
      "Batch 15: loss = 1.1307501792907715, acc = 0.6728515625\n",
      "Batch 16: loss = 1.1184313297271729, acc = 0.6591796875\n",
      "Batch 17: loss = 1.157930850982666, acc = 0.654296875\n",
      "Batch 18: loss = 1.1715465784072876, acc = 0.6474609375\n",
      "Batch 19: loss = 1.264098048210144, acc = 0.6083984375\n",
      "Batch 20: loss = 1.2316392660140991, acc = 0.642578125\n",
      "Batch 21: loss = 1.2787959575653076, acc = 0.61328125\n",
      "Batch 22: loss = 1.1714835166931152, acc = 0.63671875\n",
      "Batch 23: loss = 1.1773892641067505, acc = 0.646484375\n",
      "Batch 24: loss = 1.0790252685546875, acc = 0.68359375\n",
      "Batch 25: loss = 1.1382592916488647, acc = 0.66015625\n",
      "Batch 26: loss = 0.9827878475189209, acc = 0.716796875\n",
      "Batch 27: loss = 0.9199143648147583, acc = 0.7275390625\n",
      "Batch 28: loss = 1.06703519821167, acc = 0.6904296875\n",
      "Batch 29: loss = 1.0666171312332153, acc = 0.69140625\n",
      "Batch 30: loss = 1.051469087600708, acc = 0.6943359375\n",
      "Batch 31: loss = 1.104686975479126, acc = 0.685546875\n",
      "Batch 32: loss = 1.085161805152893, acc = 0.6806640625\n",
      "Batch 33: loss = 1.2268118858337402, acc = 0.623046875\n",
      "Batch 34: loss = 1.252601981163025, acc = 0.6162109375\n",
      "Batch 35: loss = 1.1750433444976807, acc = 0.662109375\n",
      "Batch 36: loss = 1.0932934284210205, acc = 0.66796875\n",
      "Batch 37: loss = 1.1803064346313477, acc = 0.650390625\n",
      "Batch 38: loss = 1.173048973083496, acc = 0.6337890625\n",
      "Batch 39: loss = 1.191143274307251, acc = 0.6396484375\n",
      "Batch 40: loss = 1.144120693206787, acc = 0.6494140625\n",
      "Batch 41: loss = 1.231663465499878, acc = 0.626953125\n",
      "\n",
      "Epoch 33/100\n",
      "Batch 1: loss = 1.2063044309616089, acc = 0.6513671875\n",
      "Batch 2: loss = 1.1038835048675537, acc = 0.6748046875\n",
      "Batch 3: loss = 1.0935916900634766, acc = 0.677734375\n",
      "Batch 4: loss = 1.0481061935424805, acc = 0.6806640625\n",
      "Batch 5: loss = 0.9798977971076965, acc = 0.7041015625\n",
      "Batch 6: loss = 1.007035255432129, acc = 0.7197265625\n",
      "Batch 7: loss = 1.0358293056488037, acc = 0.6865234375\n",
      "Batch 8: loss = 0.9905976057052612, acc = 0.7236328125\n",
      "Batch 9: loss = 1.1100318431854248, acc = 0.681640625\n",
      "Batch 10: loss = 1.0886207818984985, acc = 0.66796875\n",
      "Batch 11: loss = 1.2657607793807983, acc = 0.6064453125\n",
      "Batch 12: loss = 1.1611058712005615, acc = 0.6455078125\n",
      "Batch 13: loss = 1.1775538921356201, acc = 0.630859375\n",
      "Batch 14: loss = 1.0871319770812988, acc = 0.6748046875\n",
      "Batch 15: loss = 1.0931031703948975, acc = 0.6826171875\n",
      "Batch 16: loss = 1.1302913427352905, acc = 0.65234375\n",
      "Batch 17: loss = 1.1500089168548584, acc = 0.650390625\n",
      "Batch 18: loss = 1.1503238677978516, acc = 0.640625\n",
      "Batch 19: loss = 1.224053144454956, acc = 0.6279296875\n",
      "Batch 20: loss = 1.2028745412826538, acc = 0.6298828125\n",
      "Batch 21: loss = 1.2343716621398926, acc = 0.6201171875\n",
      "Batch 22: loss = 1.1614978313446045, acc = 0.6318359375\n",
      "Batch 23: loss = 1.1216003894805908, acc = 0.6669921875\n",
      "Batch 24: loss = 1.0971930027008057, acc = 0.6591796875\n",
      "Batch 25: loss = 1.1342535018920898, acc = 0.6533203125\n",
      "Batch 26: loss = 0.9750775098800659, acc = 0.70703125\n",
      "Batch 27: loss = 0.9190145134925842, acc = 0.71875\n",
      "Batch 28: loss = 1.0325617790222168, acc = 0.7060546875\n",
      "Batch 29: loss = 1.0380525588989258, acc = 0.703125\n",
      "Batch 30: loss = 1.0227856636047363, acc = 0.6982421875\n",
      "Batch 31: loss = 1.062971591949463, acc = 0.69140625\n",
      "Batch 32: loss = 1.022334098815918, acc = 0.7099609375\n",
      "Batch 33: loss = 1.1725537776947021, acc = 0.6318359375\n",
      "Batch 34: loss = 1.2504351139068604, acc = 0.626953125\n",
      "Batch 35: loss = 1.1619271039962769, acc = 0.6748046875\n",
      "Batch 36: loss = 1.0335052013397217, acc = 0.6982421875\n",
      "Batch 37: loss = 1.1267776489257812, acc = 0.6748046875\n",
      "Batch 38: loss = 1.1236824989318848, acc = 0.66796875\n",
      "Batch 39: loss = 1.178309679031372, acc = 0.6484375\n",
      "Batch 40: loss = 1.12807035446167, acc = 0.666015625\n",
      "Batch 41: loss = 1.1552057266235352, acc = 0.6328125\n",
      "\n",
      "Epoch 34/100\n",
      "Batch 1: loss = 1.1236604452133179, acc = 0.671875\n",
      "Batch 2: loss = 1.0346400737762451, acc = 0.7001953125\n",
      "Batch 3: loss = 1.0360260009765625, acc = 0.7041015625\n",
      "Batch 4: loss = 1.002570390701294, acc = 0.7177734375\n",
      "Batch 5: loss = 0.938795804977417, acc = 0.7333984375\n",
      "Batch 6: loss = 0.9258382320404053, acc = 0.744140625\n",
      "Batch 7: loss = 0.952386736869812, acc = 0.7275390625\n",
      "Batch 8: loss = 0.9725762605667114, acc = 0.73046875\n",
      "Batch 9: loss = 1.0208027362823486, acc = 0.697265625\n",
      "Batch 10: loss = 1.0601813793182373, acc = 0.673828125\n",
      "Batch 11: loss = 1.2541375160217285, acc = 0.6044921875\n",
      "Batch 12: loss = 1.1282141208648682, acc = 0.654296875\n",
      "Batch 13: loss = 1.110305666923523, acc = 0.673828125\n",
      "Batch 14: loss = 1.0271066427230835, acc = 0.68359375\n",
      "Batch 15: loss = 1.0621280670166016, acc = 0.68359375\n",
      "Batch 16: loss = 1.052105188369751, acc = 0.6708984375\n",
      "Batch 17: loss = 1.0999277830123901, acc = 0.6669921875\n",
      "Batch 18: loss = 1.1491427421569824, acc = 0.6611328125\n",
      "Batch 19: loss = 1.210265874862671, acc = 0.6318359375\n",
      "Batch 20: loss = 1.1683655977249146, acc = 0.6279296875\n",
      "Batch 21: loss = 1.206587791442871, acc = 0.6240234375\n",
      "Batch 22: loss = 1.1675121784210205, acc = 0.6513671875\n",
      "Batch 23: loss = 1.1179909706115723, acc = 0.6640625\n",
      "Batch 24: loss = 1.0855885744094849, acc = 0.6796875\n",
      "Batch 25: loss = 1.1045591831207275, acc = 0.6728515625\n",
      "Batch 26: loss = 0.9463820457458496, acc = 0.724609375\n",
      "Batch 27: loss = 0.8928920030593872, acc = 0.734375\n",
      "Batch 28: loss = 1.0570194721221924, acc = 0.6904296875\n",
      "Batch 29: loss = 1.0390608310699463, acc = 0.69140625\n",
      "Batch 30: loss = 0.9691624641418457, acc = 0.7080078125\n",
      "Batch 31: loss = 1.0407978296279907, acc = 0.6884765625\n",
      "Batch 32: loss = 1.0251483917236328, acc = 0.6923828125\n",
      "Batch 33: loss = 1.1483570337295532, acc = 0.65625\n",
      "Batch 34: loss = 1.233616590499878, acc = 0.625\n",
      "Batch 35: loss = 1.1342157125473022, acc = 0.66015625\n",
      "Batch 36: loss = 1.017681360244751, acc = 0.6826171875\n",
      "Batch 37: loss = 1.126328945159912, acc = 0.654296875\n",
      "Batch 38: loss = 1.1095033884048462, acc = 0.6748046875\n",
      "Batch 39: loss = 1.1317071914672852, acc = 0.654296875\n",
      "Batch 40: loss = 1.072237491607666, acc = 0.66796875\n",
      "Batch 41: loss = 1.1643978357315063, acc = 0.6416015625\n",
      "\n",
      "Epoch 35/100\n",
      "Batch 1: loss = 1.1130452156066895, acc = 0.6796875\n",
      "Batch 2: loss = 0.9934903383255005, acc = 0.70703125\n",
      "Batch 3: loss = 0.9941108226776123, acc = 0.70703125\n",
      "Batch 4: loss = 1.0188989639282227, acc = 0.703125\n",
      "Batch 5: loss = 0.9456332325935364, acc = 0.7177734375\n",
      "Batch 6: loss = 0.9376339316368103, acc = 0.73828125\n",
      "Batch 7: loss = 0.9365613460540771, acc = 0.7275390625\n",
      "Batch 8: loss = 0.9433234930038452, acc = 0.7119140625\n",
      "Batch 9: loss = 1.0095142126083374, acc = 0.6962890625\n",
      "Batch 10: loss = 1.0534632205963135, acc = 0.6748046875\n",
      "Batch 11: loss = 1.184230089187622, acc = 0.6357421875\n",
      "Batch 12: loss = 1.084338903427124, acc = 0.6572265625\n",
      "Batch 13: loss = 1.1040550470352173, acc = 0.6689453125\n",
      "Batch 14: loss = 1.0198800563812256, acc = 0.671875\n",
      "Batch 15: loss = 1.056466817855835, acc = 0.685546875\n",
      "Batch 16: loss = 1.0161781311035156, acc = 0.6845703125\n",
      "Batch 17: loss = 1.0605303049087524, acc = 0.6728515625\n",
      "Batch 18: loss = 1.111708164215088, acc = 0.666015625\n",
      "Batch 19: loss = 1.1625123023986816, acc = 0.6455078125\n",
      "Batch 20: loss = 1.1750236749649048, acc = 0.6435546875\n",
      "Batch 21: loss = 1.1802704334259033, acc = 0.6328125\n",
      "Batch 22: loss = 1.0886082649230957, acc = 0.671875\n",
      "Batch 23: loss = 1.0887424945831299, acc = 0.6845703125\n",
      "Batch 24: loss = 0.9915042519569397, acc = 0.712890625\n",
      "Batch 25: loss = 1.046818733215332, acc = 0.6923828125\n",
      "Batch 26: loss = 0.9471949338912964, acc = 0.7294921875\n",
      "Batch 27: loss = 0.8795106410980225, acc = 0.7509765625\n",
      "Batch 28: loss = 1.0152357816696167, acc = 0.69921875\n",
      "Batch 29: loss = 0.9919028282165527, acc = 0.71484375\n",
      "Batch 30: loss = 0.9416128396987915, acc = 0.7216796875\n",
      "Batch 31: loss = 1.0317175388336182, acc = 0.6923828125\n",
      "Batch 32: loss = 0.9935376644134521, acc = 0.705078125\n",
      "Batch 33: loss = 1.1173136234283447, acc = 0.654296875\n",
      "Batch 34: loss = 1.1836082935333252, acc = 0.650390625\n",
      "Batch 35: loss = 1.0813419818878174, acc = 0.66796875\n",
      "Batch 36: loss = 0.9606735706329346, acc = 0.724609375\n",
      "Batch 37: loss = 1.1143579483032227, acc = 0.677734375\n",
      "Batch 38: loss = 1.0418167114257812, acc = 0.6884765625\n",
      "Batch 39: loss = 1.0918223857879639, acc = 0.662109375\n",
      "Batch 40: loss = 1.0650265216827393, acc = 0.6611328125\n",
      "Batch 41: loss = 1.0883067846298218, acc = 0.6630859375\n",
      "\n",
      "Epoch 36/100\n",
      "Batch 1: loss = 1.0674524307250977, acc = 0.6875\n",
      "Batch 2: loss = 0.9621885418891907, acc = 0.7109375\n",
      "Batch 3: loss = 0.9657403230667114, acc = 0.7119140625\n",
      "Batch 4: loss = 0.9604818820953369, acc = 0.7158203125\n",
      "Batch 5: loss = 0.8825744390487671, acc = 0.7470703125\n",
      "Batch 6: loss = 0.9361233711242676, acc = 0.734375\n",
      "Batch 7: loss = 0.9380052089691162, acc = 0.720703125\n",
      "Batch 8: loss = 0.913072943687439, acc = 0.7431640625\n",
      "Batch 9: loss = 1.0164246559143066, acc = 0.708984375\n",
      "Batch 10: loss = 0.9987796545028687, acc = 0.705078125\n",
      "Batch 11: loss = 1.1762053966522217, acc = 0.6298828125\n",
      "Batch 12: loss = 1.0822060108184814, acc = 0.66015625\n",
      "Batch 13: loss = 1.0340468883514404, acc = 0.6875\n",
      "Batch 14: loss = 0.9861727356910706, acc = 0.708984375\n",
      "Batch 15: loss = 0.9715527296066284, acc = 0.7197265625\n",
      "Batch 16: loss = 1.009364366531372, acc = 0.689453125\n",
      "Batch 17: loss = 1.0958590507507324, acc = 0.6650390625\n",
      "Batch 18: loss = 1.0656715631484985, acc = 0.66796875\n",
      "Batch 19: loss = 1.145146131515503, acc = 0.6396484375\n",
      "Batch 20: loss = 1.1458936929702759, acc = 0.65625\n",
      "Batch 21: loss = 1.124082326889038, acc = 0.650390625\n",
      "Batch 22: loss = 1.0456035137176514, acc = 0.6884765625\n",
      "Batch 23: loss = 1.0214481353759766, acc = 0.7041015625\n",
      "Batch 24: loss = 1.002061128616333, acc = 0.71484375\n",
      "Batch 25: loss = 1.0039467811584473, acc = 0.697265625\n",
      "Batch 26: loss = 0.8839660882949829, acc = 0.7373046875\n",
      "Batch 27: loss = 0.7962231636047363, acc = 0.7705078125\n",
      "Batch 28: loss = 0.941490888595581, acc = 0.7236328125\n",
      "Batch 29: loss = 0.9542676210403442, acc = 0.71484375\n",
      "Batch 30: loss = 0.9328349828720093, acc = 0.7138671875\n",
      "Batch 31: loss = 1.0045114755630493, acc = 0.708984375\n",
      "Batch 32: loss = 0.9677566289901733, acc = 0.7177734375\n",
      "Batch 33: loss = 1.097785234451294, acc = 0.66015625\n",
      "Batch 34: loss = 1.1368565559387207, acc = 0.6591796875\n",
      "Batch 35: loss = 1.0644532442092896, acc = 0.6884765625\n",
      "Batch 36: loss = 0.9658048748970032, acc = 0.7119140625\n",
      "Batch 37: loss = 1.0606355667114258, acc = 0.69140625\n",
      "Batch 38: loss = 1.040203332901001, acc = 0.685546875\n",
      "Batch 39: loss = 1.0648967027664185, acc = 0.693359375\n",
      "Batch 40: loss = 1.0604503154754639, acc = 0.6708984375\n",
      "Batch 41: loss = 1.100903034210205, acc = 0.6552734375\n",
      "\n",
      "Epoch 37/100\n",
      "Batch 1: loss = 1.002623200416565, acc = 0.716796875\n",
      "Batch 2: loss = 0.9096575379371643, acc = 0.7421875\n",
      "Batch 3: loss = 0.9624588489532471, acc = 0.71484375\n",
      "Batch 4: loss = 0.9218074083328247, acc = 0.7509765625\n",
      "Batch 5: loss = 0.8718518018722534, acc = 0.732421875\n",
      "Batch 6: loss = 0.885729968547821, acc = 0.7421875\n",
      "Batch 7: loss = 0.9027212858200073, acc = 0.7314453125\n",
      "Batch 8: loss = 0.8902068138122559, acc = 0.73828125\n",
      "Batch 9: loss = 0.9460353851318359, acc = 0.72265625\n",
      "Batch 10: loss = 0.9994670748710632, acc = 0.697265625\n",
      "Batch 11: loss = 1.152907371520996, acc = 0.638671875\n",
      "Batch 12: loss = 1.0095608234405518, acc = 0.6904296875\n",
      "Batch 13: loss = 1.055314540863037, acc = 0.6884765625\n",
      "Batch 14: loss = 0.9778067469596863, acc = 0.7021484375\n",
      "Batch 15: loss = 0.9471859931945801, acc = 0.7265625\n",
      "Batch 16: loss = 0.9807667136192322, acc = 0.69921875\n",
      "Batch 17: loss = 1.0154964923858643, acc = 0.7001953125\n",
      "Batch 18: loss = 1.034064531326294, acc = 0.6943359375\n",
      "Batch 19: loss = 1.0910063982009888, acc = 0.666015625\n",
      "Batch 20: loss = 1.064767837524414, acc = 0.6806640625\n",
      "Batch 21: loss = 1.1113059520721436, acc = 0.6640625\n",
      "Batch 22: loss = 0.9904406070709229, acc = 0.7177734375\n",
      "Batch 23: loss = 1.0247118473052979, acc = 0.6875\n",
      "Batch 24: loss = 0.9702035188674927, acc = 0.7021484375\n",
      "Batch 25: loss = 0.9796676635742188, acc = 0.6953125\n",
      "Batch 26: loss = 0.9049810171127319, acc = 0.7373046875\n",
      "Batch 27: loss = 0.8095606565475464, acc = 0.75390625\n",
      "Batch 28: loss = 0.9246121644973755, acc = 0.7294921875\n",
      "Batch 29: loss = 0.943310558795929, acc = 0.7236328125\n",
      "Batch 30: loss = 0.9335911870002747, acc = 0.7177734375\n",
      "Batch 31: loss = 0.9997677206993103, acc = 0.7021484375\n",
      "Batch 32: loss = 0.9349546432495117, acc = 0.7099609375\n",
      "Batch 33: loss = 1.0591892004013062, acc = 0.6845703125\n",
      "Batch 34: loss = 1.102733850479126, acc = 0.6650390625\n",
      "Batch 35: loss = 1.0346181392669678, acc = 0.6826171875\n",
      "Batch 36: loss = 0.9240797758102417, acc = 0.7255859375\n",
      "Batch 37: loss = 1.0277040004730225, acc = 0.701171875\n",
      "Batch 38: loss = 0.9907041192054749, acc = 0.6962890625\n",
      "Batch 39: loss = 1.0449674129486084, acc = 0.6845703125\n",
      "Batch 40: loss = 1.056364893913269, acc = 0.673828125\n",
      "Batch 41: loss = 1.0805957317352295, acc = 0.6748046875\n",
      "\n",
      "Epoch 38/100\n",
      "Batch 1: loss = 0.9945620894432068, acc = 0.7138671875\n",
      "Batch 2: loss = 0.8945412635803223, acc = 0.7490234375\n",
      "Batch 3: loss = 0.8827786445617676, acc = 0.734375\n",
      "Batch 4: loss = 0.9009522199630737, acc = 0.759765625\n",
      "Batch 5: loss = 0.8182546496391296, acc = 0.751953125\n",
      "Batch 6: loss = 0.8321143388748169, acc = 0.755859375\n",
      "Batch 7: loss = 0.913262665271759, acc = 0.7119140625\n",
      "Batch 8: loss = 0.8846925497055054, acc = 0.75\n",
      "Batch 9: loss = 0.9165041446685791, acc = 0.7255859375\n",
      "Batch 10: loss = 0.9546448588371277, acc = 0.7177734375\n",
      "Batch 11: loss = 1.1069109439849854, acc = 0.650390625\n",
      "Batch 12: loss = 1.008681297302246, acc = 0.693359375\n",
      "Batch 13: loss = 1.026308298110962, acc = 0.6943359375\n",
      "Batch 14: loss = 0.9485394358634949, acc = 0.7265625\n",
      "Batch 15: loss = 0.9744226932525635, acc = 0.712890625\n",
      "Batch 16: loss = 0.9618209004402161, acc = 0.7158203125\n",
      "Batch 17: loss = 0.9938234686851501, acc = 0.6982421875\n",
      "Batch 18: loss = 1.0385054349899292, acc = 0.6796875\n",
      "Batch 19: loss = 1.1030833721160889, acc = 0.66015625\n",
      "Batch 20: loss = 1.134716272354126, acc = 0.669921875\n",
      "Batch 21: loss = 1.1008890867233276, acc = 0.642578125\n",
      "Batch 22: loss = 1.0026676654815674, acc = 0.69921875\n",
      "Batch 23: loss = 1.0168943405151367, acc = 0.685546875\n",
      "Batch 24: loss = 0.9335039854049683, acc = 0.71875\n",
      "Batch 25: loss = 1.004247784614563, acc = 0.689453125\n",
      "Batch 26: loss = 0.8195270895957947, acc = 0.7568359375\n",
      "Batch 27: loss = 0.76133793592453, acc = 0.7822265625\n",
      "Batch 28: loss = 0.903702437877655, acc = 0.7509765625\n",
      "Batch 29: loss = 0.9410689473152161, acc = 0.7275390625\n",
      "Batch 30: loss = 0.8774454593658447, acc = 0.7431640625\n",
      "Batch 31: loss = 0.9635521173477173, acc = 0.7060546875\n",
      "Batch 32: loss = 0.9257485866546631, acc = 0.71484375\n",
      "Batch 33: loss = 1.0444536209106445, acc = 0.6875\n",
      "Batch 34: loss = 1.093461275100708, acc = 0.669921875\n",
      "Batch 35: loss = 1.0115967988967896, acc = 0.693359375\n",
      "Batch 36: loss = 0.8728460073471069, acc = 0.7451171875\n",
      "Batch 37: loss = 0.9975039958953857, acc = 0.7041015625\n",
      "Batch 38: loss = 0.9479618072509766, acc = 0.7080078125\n",
      "Batch 39: loss = 1.0152629613876343, acc = 0.6884765625\n",
      "Batch 40: loss = 0.983041524887085, acc = 0.6875\n",
      "Batch 41: loss = 1.038322925567627, acc = 0.681640625\n",
      "\n",
      "Epoch 39/100\n",
      "Batch 1: loss = 1.027430772781372, acc = 0.708984375\n",
      "Batch 2: loss = 0.9146385192871094, acc = 0.740234375\n",
      "Batch 3: loss = 0.893221914768219, acc = 0.755859375\n",
      "Batch 4: loss = 0.8709387183189392, acc = 0.75390625\n",
      "Batch 5: loss = 0.8388247489929199, acc = 0.7451171875\n",
      "Batch 6: loss = 0.8177951574325562, acc = 0.75\n",
      "Batch 7: loss = 0.8533652424812317, acc = 0.7294921875\n",
      "Batch 8: loss = 0.8835203647613525, acc = 0.7333984375\n",
      "Batch 9: loss = 0.9337012767791748, acc = 0.71484375\n",
      "Batch 10: loss = 0.9089353084564209, acc = 0.71875\n",
      "Batch 11: loss = 1.1001105308532715, acc = 0.6640625\n",
      "Batch 12: loss = 0.9863867163658142, acc = 0.7060546875\n",
      "Batch 13: loss = 0.9901105761528015, acc = 0.6953125\n",
      "Batch 14: loss = 0.9234009981155396, acc = 0.720703125\n",
      "Batch 15: loss = 0.9268630146980286, acc = 0.7216796875\n",
      "Batch 16: loss = 0.9411922097206116, acc = 0.724609375\n",
      "Batch 17: loss = 0.9789342284202576, acc = 0.6962890625\n",
      "Batch 18: loss = 1.0254552364349365, acc = 0.6767578125\n",
      "Batch 19: loss = 1.0614104270935059, acc = 0.6787109375\n",
      "Batch 20: loss = 1.0693860054016113, acc = 0.6650390625\n",
      "Batch 21: loss = 1.0208805799484253, acc = 0.6923828125\n",
      "Batch 22: loss = 0.9679867625236511, acc = 0.7138671875\n",
      "Batch 23: loss = 1.0211271047592163, acc = 0.689453125\n",
      "Batch 24: loss = 0.9141450524330139, acc = 0.7392578125\n",
      "Batch 25: loss = 0.9085835218429565, acc = 0.7314453125\n",
      "Batch 26: loss = 0.8095444440841675, acc = 0.763671875\n",
      "Batch 27: loss = 0.7627303004264832, acc = 0.78515625\n",
      "Batch 28: loss = 0.8521425724029541, acc = 0.74609375\n",
      "Batch 29: loss = 0.9238014817237854, acc = 0.7353515625\n",
      "Batch 30: loss = 0.8498209118843079, acc = 0.7392578125\n",
      "Batch 31: loss = 0.908097505569458, acc = 0.73828125\n",
      "Batch 32: loss = 0.8808732032775879, acc = 0.740234375\n",
      "Batch 33: loss = 0.9584392309188843, acc = 0.7099609375\n",
      "Batch 34: loss = 1.0564603805541992, acc = 0.693359375\n",
      "Batch 35: loss = 0.9932753443717957, acc = 0.701171875\n",
      "Batch 36: loss = 0.8676468729972839, acc = 0.728515625\n",
      "Batch 37: loss = 0.9843970537185669, acc = 0.7109375\n",
      "Batch 38: loss = 0.9292341470718384, acc = 0.7216796875\n",
      "Batch 39: loss = 0.9862023591995239, acc = 0.7041015625\n",
      "Batch 40: loss = 0.9962295293807983, acc = 0.6982421875\n",
      "Batch 41: loss = 1.0052685737609863, acc = 0.6845703125\n",
      "\n",
      "Epoch 40/100\n",
      "Batch 1: loss = 0.9749787449836731, acc = 0.7255859375\n",
      "Batch 2: loss = 0.8757571578025818, acc = 0.7451171875\n",
      "Batch 3: loss = 0.8751475811004639, acc = 0.7451171875\n",
      "Batch 4: loss = 0.8592842221260071, acc = 0.7509765625\n",
      "Batch 5: loss = 0.8033920526504517, acc = 0.76953125\n",
      "Batch 6: loss = 0.7960419654846191, acc = 0.7626953125\n",
      "Batch 7: loss = 0.8225274085998535, acc = 0.767578125\n",
      "Batch 8: loss = 0.8032664060592651, acc = 0.7626953125\n",
      "Batch 9: loss = 0.8403184413909912, acc = 0.755859375\n",
      "Batch 10: loss = 0.9235559105873108, acc = 0.734375\n",
      "Batch 11: loss = 1.082462191581726, acc = 0.68359375\n",
      "Batch 12: loss = 0.9904910326004028, acc = 0.6962890625\n",
      "Batch 13: loss = 0.9793111085891724, acc = 0.697265625\n",
      "Batch 14: loss = 0.8848757147789001, acc = 0.73046875\n",
      "Batch 15: loss = 0.9219014644622803, acc = 0.7333984375\n",
      "Batch 16: loss = 0.9145090579986572, acc = 0.7099609375\n",
      "Batch 17: loss = 0.9512268304824829, acc = 0.7021484375\n",
      "Batch 18: loss = 0.9487627148628235, acc = 0.71875\n",
      "Batch 19: loss = 0.9692925214767456, acc = 0.7060546875\n",
      "Batch 20: loss = 1.005593180656433, acc = 0.6796875\n",
      "Batch 21: loss = 1.011178731918335, acc = 0.6796875\n",
      "Batch 22: loss = 0.9547582864761353, acc = 0.7138671875\n",
      "Batch 23: loss = 0.9396550059318542, acc = 0.72265625\n",
      "Batch 24: loss = 0.9163200855255127, acc = 0.734375\n",
      "Batch 25: loss = 0.9048073887825012, acc = 0.7314453125\n",
      "Batch 26: loss = 0.7898163795471191, acc = 0.7568359375\n",
      "Batch 27: loss = 0.7388260960578918, acc = 0.7783203125\n",
      "Batch 28: loss = 0.8122010231018066, acc = 0.7548828125\n",
      "Batch 29: loss = 0.8949980139732361, acc = 0.7373046875\n",
      "Batch 30: loss = 0.840806782245636, acc = 0.732421875\n",
      "Batch 31: loss = 0.8652757406234741, acc = 0.7412109375\n",
      "Batch 32: loss = 0.8404866456985474, acc = 0.7607421875\n",
      "Batch 33: loss = 0.9906880259513855, acc = 0.6884765625\n",
      "Batch 34: loss = 1.0344371795654297, acc = 0.689453125\n",
      "Batch 35: loss = 0.9663857221603394, acc = 0.703125\n",
      "Batch 36: loss = 0.8389601707458496, acc = 0.7470703125\n",
      "Batch 37: loss = 0.9177711009979248, acc = 0.73828125\n",
      "Batch 38: loss = 0.9713600873947144, acc = 0.7041015625\n",
      "Batch 39: loss = 0.9404711127281189, acc = 0.732421875\n",
      "Batch 40: loss = 0.9366011619567871, acc = 0.7255859375\n",
      "Batch 41: loss = 0.9846546649932861, acc = 0.69921875\n",
      "Saved checkpoint to weights_eminem_input.txt.40.h5\n",
      "\n",
      "Epoch 41/100\n",
      "Batch 1: loss = 0.9361700415611267, acc = 0.7138671875\n",
      "Batch 2: loss = 0.8265145421028137, acc = 0.7587890625\n",
      "Batch 3: loss = 0.8318073749542236, acc = 0.7568359375\n",
      "Batch 4: loss = 0.8551225066184998, acc = 0.7626953125\n",
      "Batch 5: loss = 0.7722357511520386, acc = 0.7666015625\n",
      "Batch 6: loss = 0.8172296285629272, acc = 0.7666015625\n",
      "Batch 7: loss = 0.8186677098274231, acc = 0.7470703125\n",
      "Batch 8: loss = 0.8193310499191284, acc = 0.75390625\n",
      "Batch 9: loss = 0.8652417659759521, acc = 0.7470703125\n",
      "Batch 10: loss = 0.8511781692504883, acc = 0.7392578125\n",
      "Batch 11: loss = 1.0318669080734253, acc = 0.6611328125\n",
      "Batch 12: loss = 0.9292163252830505, acc = 0.7138671875\n",
      "Batch 13: loss = 0.9370067119598389, acc = 0.712890625\n",
      "Batch 14: loss = 0.8858352303504944, acc = 0.732421875\n",
      "Batch 15: loss = 0.8798990249633789, acc = 0.74609375\n",
      "Batch 16: loss = 0.8988628387451172, acc = 0.7255859375\n",
      "Batch 17: loss = 0.9436583518981934, acc = 0.7138671875\n",
      "Batch 18: loss = 0.9695439338684082, acc = 0.7060546875\n",
      "Batch 19: loss = 0.9682981371879578, acc = 0.6953125\n",
      "Batch 20: loss = 0.9821805953979492, acc = 0.7001953125\n",
      "Batch 21: loss = 1.0038080215454102, acc = 0.693359375\n",
      "Batch 22: loss = 0.9538068771362305, acc = 0.70703125\n",
      "Batch 23: loss = 0.9308326244354248, acc = 0.724609375\n",
      "Batch 24: loss = 0.8859124183654785, acc = 0.7314453125\n",
      "Batch 25: loss = 0.8902281522750854, acc = 0.7255859375\n",
      "Batch 26: loss = 0.760959267616272, acc = 0.7705078125\n",
      "Batch 27: loss = 0.7088879346847534, acc = 0.7939453125\n",
      "Batch 28: loss = 0.8300126791000366, acc = 0.75\n",
      "Batch 29: loss = 0.8359354734420776, acc = 0.744140625\n",
      "Batch 30: loss = 0.8522133827209473, acc = 0.73046875\n",
      "Batch 31: loss = 0.8194107413291931, acc = 0.7568359375\n",
      "Batch 32: loss = 0.8183879852294922, acc = 0.759765625\n",
      "Batch 33: loss = 0.9408918619155884, acc = 0.7197265625\n",
      "Batch 34: loss = 1.0068073272705078, acc = 0.697265625\n",
      "Batch 35: loss = 0.9323418140411377, acc = 0.7265625\n",
      "Batch 36: loss = 0.8291955590248108, acc = 0.7490234375\n",
      "Batch 37: loss = 0.9040504693984985, acc = 0.7373046875\n",
      "Batch 38: loss = 0.8688088655471802, acc = 0.7392578125\n",
      "Batch 39: loss = 0.9201152324676514, acc = 0.71484375\n",
      "Batch 40: loss = 0.8853424787521362, acc = 0.7275390625\n",
      "Batch 41: loss = 0.9707459807395935, acc = 0.7041015625\n",
      "\n",
      "Epoch 42/100\n",
      "Batch 1: loss = 0.8676614761352539, acc = 0.7373046875\n",
      "Batch 2: loss = 0.811144232749939, acc = 0.75390625\n",
      "Batch 3: loss = 0.8385698795318604, acc = 0.744140625\n",
      "Batch 4: loss = 0.8208729028701782, acc = 0.767578125\n",
      "Batch 5: loss = 0.7395696640014648, acc = 0.78515625\n",
      "Batch 6: loss = 0.7861548662185669, acc = 0.7646484375\n",
      "Batch 7: loss = 0.8088504076004028, acc = 0.755859375\n",
      "Batch 8: loss = 0.7634007930755615, acc = 0.7626953125\n",
      "Batch 9: loss = 0.8315534591674805, acc = 0.7734375\n",
      "Batch 10: loss = 0.8634157776832581, acc = 0.740234375\n",
      "Batch 11: loss = 0.9882993102073669, acc = 0.6982421875\n",
      "Batch 12: loss = 0.9161431789398193, acc = 0.703125\n",
      "Batch 13: loss = 0.8910356163978577, acc = 0.732421875\n",
      "Batch 14: loss = 0.8377544283866882, acc = 0.7548828125\n",
      "Batch 15: loss = 0.8448269963264465, acc = 0.76171875\n",
      "Batch 16: loss = 0.8693018555641174, acc = 0.734375\n",
      "Batch 17: loss = 0.8809148073196411, acc = 0.7470703125\n",
      "Batch 18: loss = 0.9175293445587158, acc = 0.724609375\n",
      "Batch 19: loss = 0.9414768218994141, acc = 0.7275390625\n",
      "Batch 20: loss = 0.9426435232162476, acc = 0.720703125\n",
      "Batch 21: loss = 0.9478706121444702, acc = 0.705078125\n",
      "Batch 22: loss = 0.8800511360168457, acc = 0.724609375\n",
      "Batch 23: loss = 0.8672927021980286, acc = 0.7470703125\n",
      "Batch 24: loss = 0.8445290327072144, acc = 0.7529296875\n",
      "Batch 25: loss = 0.8895740509033203, acc = 0.7333984375\n",
      "Batch 26: loss = 0.7791678309440613, acc = 0.763671875\n",
      "Batch 27: loss = 0.708112359046936, acc = 0.7861328125\n",
      "Batch 28: loss = 0.7651193141937256, acc = 0.775390625\n",
      "Batch 29: loss = 0.8177199363708496, acc = 0.7626953125\n",
      "Batch 30: loss = 0.8103771805763245, acc = 0.74609375\n",
      "Batch 31: loss = 0.8379036784172058, acc = 0.7451171875\n",
      "Batch 32: loss = 0.7894564867019653, acc = 0.76171875\n",
      "Batch 33: loss = 0.8967225551605225, acc = 0.732421875\n",
      "Batch 34: loss = 0.9793170690536499, acc = 0.6904296875\n",
      "Batch 35: loss = 0.9216381311416626, acc = 0.70703125\n",
      "Batch 36: loss = 0.7413070201873779, acc = 0.76953125\n",
      "Batch 37: loss = 0.9237438440322876, acc = 0.7265625\n",
      "Batch 38: loss = 0.8739758729934692, acc = 0.73828125\n",
      "Batch 39: loss = 0.8804486393928528, acc = 0.7275390625\n",
      "Batch 40: loss = 0.8750829696655273, acc = 0.7294921875\n",
      "Batch 41: loss = 0.9078738689422607, acc = 0.71875\n",
      "\n",
      "Epoch 43/100\n",
      "Batch 1: loss = 0.8238813281059265, acc = 0.7685546875\n",
      "Batch 2: loss = 0.7671411037445068, acc = 0.7763671875\n",
      "Batch 3: loss = 0.7614123821258545, acc = 0.7763671875\n",
      "Batch 4: loss = 0.7587230205535889, acc = 0.779296875\n",
      "Batch 5: loss = 0.7176940441131592, acc = 0.791015625\n",
      "Batch 6: loss = 0.736011803150177, acc = 0.775390625\n",
      "Batch 7: loss = 0.7948609590530396, acc = 0.7587890625\n",
      "Batch 8: loss = 0.7779920101165771, acc = 0.7734375\n",
      "Batch 9: loss = 0.8107587099075317, acc = 0.767578125\n",
      "Batch 10: loss = 0.8099645972251892, acc = 0.75390625\n",
      "Batch 11: loss = 0.9371353387832642, acc = 0.6923828125\n",
      "Batch 12: loss = 0.8909364938735962, acc = 0.7294921875\n",
      "Batch 13: loss = 0.8712095022201538, acc = 0.720703125\n",
      "Batch 14: loss = 0.7984210252761841, acc = 0.76171875\n",
      "Batch 15: loss = 0.8385615348815918, acc = 0.7421875\n",
      "Batch 16: loss = 0.8160644173622131, acc = 0.76171875\n",
      "Batch 17: loss = 0.8668770790100098, acc = 0.7431640625\n",
      "Batch 18: loss = 0.9116706848144531, acc = 0.728515625\n",
      "Batch 19: loss = 0.9280931353569031, acc = 0.720703125\n",
      "Batch 20: loss = 0.9238013625144958, acc = 0.732421875\n",
      "Batch 21: loss = 0.9367616176605225, acc = 0.7119140625\n",
      "Batch 22: loss = 0.8559360504150391, acc = 0.734375\n",
      "Batch 23: loss = 0.8749769926071167, acc = 0.734375\n",
      "Batch 24: loss = 0.8193202018737793, acc = 0.76171875\n",
      "Batch 25: loss = 0.8176875114440918, acc = 0.755859375\n",
      "Batch 26: loss = 0.7378954887390137, acc = 0.77734375\n",
      "Batch 27: loss = 0.6993633508682251, acc = 0.802734375\n",
      "Batch 28: loss = 0.8008899688720703, acc = 0.7470703125\n",
      "Batch 29: loss = 0.8034390807151794, acc = 0.755859375\n",
      "Batch 30: loss = 0.7542521953582764, acc = 0.7685546875\n",
      "Batch 31: loss = 0.7579208612442017, acc = 0.7783203125\n",
      "Batch 32: loss = 0.7754155397415161, acc = 0.7568359375\n",
      "Batch 33: loss = 0.9019829034805298, acc = 0.7060546875\n",
      "Batch 34: loss = 0.9683730006217957, acc = 0.705078125\n",
      "Batch 35: loss = 0.8649531602859497, acc = 0.7373046875\n",
      "Batch 36: loss = 0.7696847915649414, acc = 0.7685546875\n",
      "Batch 37: loss = 0.8380643129348755, acc = 0.7490234375\n",
      "Batch 38: loss = 0.8338058590888977, acc = 0.7529296875\n",
      "Batch 39: loss = 0.8950549364089966, acc = 0.71484375\n",
      "Batch 40: loss = 0.8775707483291626, acc = 0.7275390625\n",
      "Batch 41: loss = 0.8698543310165405, acc = 0.734375\n",
      "\n",
      "Epoch 44/100\n",
      "Batch 1: loss = 0.8156971335411072, acc = 0.759765625\n",
      "Batch 2: loss = 0.730449378490448, acc = 0.78125\n",
      "Batch 3: loss = 0.7623052597045898, acc = 0.763671875\n",
      "Batch 4: loss = 0.7602024078369141, acc = 0.7763671875\n",
      "Batch 5: loss = 0.6593538522720337, acc = 0.80859375\n",
      "Batch 6: loss = 0.7161571383476257, acc = 0.7900390625\n",
      "Batch 7: loss = 0.7483477592468262, acc = 0.765625\n",
      "Batch 8: loss = 0.7356564998626709, acc = 0.7724609375\n",
      "Batch 9: loss = 0.7752615809440613, acc = 0.7705078125\n",
      "Batch 10: loss = 0.8124364018440247, acc = 0.767578125\n",
      "Batch 11: loss = 0.9244371056556702, acc = 0.70703125\n",
      "Batch 12: loss = 0.8650221824645996, acc = 0.712890625\n",
      "Batch 13: loss = 0.8400566577911377, acc = 0.748046875\n",
      "Batch 14: loss = 0.784168004989624, acc = 0.765625\n",
      "Batch 15: loss = 0.7548578977584839, acc = 0.771484375\n",
      "Batch 16: loss = 0.7939164638519287, acc = 0.751953125\n",
      "Batch 17: loss = 0.7872530221939087, acc = 0.759765625\n",
      "Batch 18: loss = 0.8723558187484741, acc = 0.724609375\n",
      "Batch 19: loss = 0.871727466583252, acc = 0.73046875\n",
      "Batch 20: loss = 0.9441713094711304, acc = 0.71484375\n",
      "Batch 21: loss = 0.9085918664932251, acc = 0.71875\n",
      "Batch 22: loss = 0.8365232944488525, acc = 0.7529296875\n",
      "Batch 23: loss = 0.85378098487854, acc = 0.72265625\n",
      "Batch 24: loss = 0.7974399328231812, acc = 0.755859375\n",
      "Batch 25: loss = 0.7606048583984375, acc = 0.767578125\n",
      "Batch 26: loss = 0.7373954057693481, acc = 0.7802734375\n",
      "Batch 27: loss = 0.6417475342750549, acc = 0.8037109375\n",
      "Batch 28: loss = 0.7333266735076904, acc = 0.783203125\n",
      "Batch 29: loss = 0.7625887989997864, acc = 0.767578125\n",
      "Batch 30: loss = 0.7529012560844421, acc = 0.76953125\n",
      "Batch 31: loss = 0.7683414220809937, acc = 0.7705078125\n",
      "Batch 32: loss = 0.7581748962402344, acc = 0.7783203125\n",
      "Batch 33: loss = 0.8722882270812988, acc = 0.7294921875\n",
      "Batch 34: loss = 0.9661234021186829, acc = 0.7001953125\n",
      "Batch 35: loss = 0.8549254536628723, acc = 0.748046875\n",
      "Batch 36: loss = 0.7121462821960449, acc = 0.783203125\n",
      "Batch 37: loss = 0.7940517663955688, acc = 0.765625\n",
      "Batch 38: loss = 0.8451166152954102, acc = 0.7265625\n",
      "Batch 39: loss = 0.8412649631500244, acc = 0.75390625\n",
      "Batch 40: loss = 0.8553676009178162, acc = 0.73828125\n",
      "Batch 41: loss = 0.8240442872047424, acc = 0.75\n",
      "\n",
      "Epoch 45/100\n",
      "Batch 1: loss = 0.8496419787406921, acc = 0.75390625\n",
      "Batch 2: loss = 0.7190478444099426, acc = 0.7861328125\n",
      "Batch 3: loss = 0.7284109592437744, acc = 0.787109375\n",
      "Batch 4: loss = 0.7504138946533203, acc = 0.78125\n",
      "Batch 5: loss = 0.6509238481521606, acc = 0.8017578125\n",
      "Batch 6: loss = 0.6763337254524231, acc = 0.8017578125\n",
      "Batch 7: loss = 0.7379839420318604, acc = 0.7724609375\n",
      "Batch 8: loss = 0.6971766948699951, acc = 0.7880859375\n",
      "Batch 9: loss = 0.771381139755249, acc = 0.779296875\n",
      "Batch 10: loss = 0.7910243272781372, acc = 0.76953125\n",
      "Batch 11: loss = 0.8730616569519043, acc = 0.72265625\n",
      "Batch 12: loss = 0.8023474216461182, acc = 0.759765625\n",
      "Batch 13: loss = 0.795000433921814, acc = 0.755859375\n",
      "Batch 14: loss = 0.7511764764785767, acc = 0.77734375\n",
      "Batch 15: loss = 0.7642339468002319, acc = 0.771484375\n",
      "Batch 16: loss = 0.7768732309341431, acc = 0.7578125\n",
      "Batch 17: loss = 0.8178275227546692, acc = 0.755859375\n",
      "Batch 18: loss = 0.8189890384674072, acc = 0.7373046875\n",
      "Batch 19: loss = 0.8676361441612244, acc = 0.7470703125\n",
      "Batch 20: loss = 0.8545076251029968, acc = 0.748046875\n",
      "Batch 21: loss = 0.865752100944519, acc = 0.7314453125\n",
      "Batch 22: loss = 0.8266255855560303, acc = 0.7353515625\n",
      "Batch 23: loss = 0.7994036674499512, acc = 0.7509765625\n",
      "Batch 24: loss = 0.8127163648605347, acc = 0.7587890625\n",
      "Batch 25: loss = 0.7755260467529297, acc = 0.7607421875\n",
      "Batch 26: loss = 0.6851534843444824, acc = 0.7958984375\n",
      "Batch 27: loss = 0.6049519777297974, acc = 0.8212890625\n",
      "Batch 28: loss = 0.7221198081970215, acc = 0.783203125\n",
      "Batch 29: loss = 0.7061787843704224, acc = 0.779296875\n",
      "Batch 30: loss = 0.6625393629074097, acc = 0.796875\n",
      "Batch 31: loss = 0.7545759677886963, acc = 0.7724609375\n",
      "Batch 32: loss = 0.7189120054244995, acc = 0.78125\n",
      "Batch 33: loss = 0.8395142555236816, acc = 0.7373046875\n",
      "Batch 34: loss = 0.8715642690658569, acc = 0.732421875\n",
      "Batch 35: loss = 0.8205888271331787, acc = 0.7490234375\n",
      "Batch 36: loss = 0.6974477171897888, acc = 0.794921875\n",
      "Batch 37: loss = 0.8043367862701416, acc = 0.759765625\n",
      "Batch 38: loss = 0.7973532676696777, acc = 0.7548828125\n",
      "Batch 39: loss = 0.8111248016357422, acc = 0.75\n",
      "Batch 40: loss = 0.8232130408287048, acc = 0.74609375\n",
      "Batch 41: loss = 0.8243796229362488, acc = 0.7412109375\n",
      "\n",
      "Epoch 46/100\n",
      "Batch 1: loss = 0.770627498626709, acc = 0.7763671875\n",
      "Batch 2: loss = 0.6796166300773621, acc = 0.8095703125\n",
      "Batch 3: loss = 0.6980050206184387, acc = 0.80078125\n",
      "Batch 4: loss = 0.7013784646987915, acc = 0.8046875\n",
      "Batch 5: loss = 0.6493507027626038, acc = 0.8056640625\n",
      "Batch 6: loss = 0.6571958065032959, acc = 0.796875\n",
      "Batch 7: loss = 0.689048171043396, acc = 0.79296875\n",
      "Batch 8: loss = 0.6716351509094238, acc = 0.8056640625\n",
      "Batch 9: loss = 0.7470703721046448, acc = 0.7685546875\n",
      "Batch 10: loss = 0.7287372946739197, acc = 0.783203125\n",
      "Batch 11: loss = 0.8553401231765747, acc = 0.732421875\n",
      "Batch 12: loss = 0.7779223918914795, acc = 0.7646484375\n",
      "Batch 13: loss = 0.7884186506271362, acc = 0.765625\n",
      "Batch 14: loss = 0.7329509854316711, acc = 0.76953125\n",
      "Batch 15: loss = 0.7163251638412476, acc = 0.77734375\n",
      "Batch 16: loss = 0.7057608366012573, acc = 0.7890625\n",
      "Batch 17: loss = 0.7669327855110168, acc = 0.763671875\n",
      "Batch 18: loss = 0.8043215274810791, acc = 0.7548828125\n",
      "Batch 19: loss = 0.8245741128921509, acc = 0.74609375\n",
      "Batch 20: loss = 0.8302868604660034, acc = 0.7490234375\n",
      "Batch 21: loss = 0.8416827917098999, acc = 0.748046875\n",
      "Batch 22: loss = 0.7599925994873047, acc = 0.7802734375\n",
      "Batch 23: loss = 0.7578781843185425, acc = 0.7734375\n",
      "Batch 24: loss = 0.7416126728057861, acc = 0.76953125\n",
      "Batch 25: loss = 0.7027910947799683, acc = 0.7841796875\n",
      "Batch 26: loss = 0.6341938376426697, acc = 0.80859375\n",
      "Batch 27: loss = 0.5864373445510864, acc = 0.8271484375\n",
      "Batch 28: loss = 0.7020314335823059, acc = 0.798828125\n",
      "Batch 29: loss = 0.7075245976448059, acc = 0.783203125\n",
      "Batch 30: loss = 0.6921570897102356, acc = 0.7919921875\n",
      "Batch 31: loss = 0.7567172050476074, acc = 0.76953125\n",
      "Batch 32: loss = 0.6574840545654297, acc = 0.7998046875\n",
      "Batch 33: loss = 0.8346806764602661, acc = 0.748046875\n",
      "Batch 34: loss = 0.8586335182189941, acc = 0.7421875\n",
      "Batch 35: loss = 0.8214136958122253, acc = 0.7412109375\n",
      "Batch 36: loss = 0.6581445932388306, acc = 0.796875\n",
      "Batch 37: loss = 0.7308357954025269, acc = 0.7734375\n",
      "Batch 38: loss = 0.7386138439178467, acc = 0.7705078125\n",
      "Batch 39: loss = 0.7803629636764526, acc = 0.767578125\n",
      "Batch 40: loss = 0.7595310211181641, acc = 0.763671875\n",
      "Batch 41: loss = 0.7968263626098633, acc = 0.73828125\n",
      "\n",
      "Epoch 47/100\n",
      "Batch 1: loss = 0.7500634789466858, acc = 0.7900390625\n",
      "Batch 2: loss = 0.6270197629928589, acc = 0.8173828125\n",
      "Batch 3: loss = 0.6659196615219116, acc = 0.8037109375\n",
      "Batch 4: loss = 0.6796941757202148, acc = 0.8134765625\n",
      "Batch 5: loss = 0.6146425604820251, acc = 0.8056640625\n",
      "Batch 6: loss = 0.6450331807136536, acc = 0.80859375\n",
      "Batch 7: loss = 0.6829144358634949, acc = 0.77734375\n",
      "Batch 8: loss = 0.6295685768127441, acc = 0.80859375\n",
      "Batch 9: loss = 0.7134824991226196, acc = 0.77734375\n",
      "Batch 10: loss = 0.7528889775276184, acc = 0.7724609375\n",
      "Batch 11: loss = 0.8252637982368469, acc = 0.7451171875\n",
      "Batch 12: loss = 0.7666608691215515, acc = 0.7548828125\n",
      "Batch 13: loss = 0.7660613059997559, acc = 0.763671875\n",
      "Batch 14: loss = 0.7002968192100525, acc = 0.7724609375\n",
      "Batch 15: loss = 0.6826859712600708, acc = 0.78515625\n",
      "Batch 16: loss = 0.7145476937294006, acc = 0.779296875\n",
      "Batch 17: loss = 0.7095749974250793, acc = 0.787109375\n",
      "Batch 18: loss = 0.7673202157020569, acc = 0.7646484375\n",
      "Batch 19: loss = 0.768933117389679, acc = 0.76171875\n",
      "Batch 20: loss = 0.7993032932281494, acc = 0.75390625\n",
      "Batch 21: loss = 0.865496039390564, acc = 0.7216796875\n",
      "Batch 22: loss = 0.7474204301834106, acc = 0.775390625\n",
      "Batch 23: loss = 0.723526120185852, acc = 0.779296875\n",
      "Batch 24: loss = 0.6965994238853455, acc = 0.7880859375\n",
      "Batch 25: loss = 0.7035733461380005, acc = 0.78515625\n",
      "Batch 26: loss = 0.5913848280906677, acc = 0.82421875\n",
      "Batch 27: loss = 0.5742713212966919, acc = 0.83984375\n",
      "Batch 28: loss = 0.6182359457015991, acc = 0.822265625\n",
      "Batch 29: loss = 0.6314169764518738, acc = 0.8046875\n",
      "Batch 30: loss = 0.6470205187797546, acc = 0.80859375\n",
      "Batch 31: loss = 0.6807196140289307, acc = 0.7958984375\n",
      "Batch 32: loss = 0.695562481880188, acc = 0.791015625\n",
      "Batch 33: loss = 0.7762191295623779, acc = 0.7470703125\n",
      "Batch 34: loss = 0.848969578742981, acc = 0.73828125\n",
      "Batch 35: loss = 0.7588692903518677, acc = 0.763671875\n",
      "Batch 36: loss = 0.6173401474952698, acc = 0.8173828125\n",
      "Batch 37: loss = 0.7358667254447937, acc = 0.7822265625\n",
      "Batch 38: loss = 0.6939636468887329, acc = 0.7802734375\n",
      "Batch 39: loss = 0.751827597618103, acc = 0.7734375\n",
      "Batch 40: loss = 0.7406899333000183, acc = 0.7763671875\n",
      "Batch 41: loss = 0.7602539658546448, acc = 0.76171875\n",
      "\n",
      "Epoch 48/100\n",
      "Batch 1: loss = 0.701449990272522, acc = 0.798828125\n",
      "Batch 2: loss = 0.584175169467926, acc = 0.83203125\n",
      "Batch 3: loss = 0.6282501816749573, acc = 0.8154296875\n",
      "Batch 4: loss = 0.6550066471099854, acc = 0.8046875\n",
      "Batch 5: loss = 0.5682584047317505, acc = 0.833984375\n",
      "Batch 6: loss = 0.6407214403152466, acc = 0.8125\n",
      "Batch 7: loss = 0.6399042010307312, acc = 0.8154296875\n",
      "Batch 8: loss = 0.6234000325202942, acc = 0.80859375\n",
      "Batch 9: loss = 0.6806875467300415, acc = 0.798828125\n",
      "Batch 10: loss = 0.7098777294158936, acc = 0.7763671875\n",
      "Batch 11: loss = 0.7609819173812866, acc = 0.7763671875\n",
      "Batch 12: loss = 0.7631707787513733, acc = 0.7568359375\n",
      "Batch 13: loss = 0.7169526815414429, acc = 0.7744140625\n",
      "Batch 14: loss = 0.6688693761825562, acc = 0.802734375\n",
      "Batch 15: loss = 0.6819425225257874, acc = 0.796875\n",
      "Batch 16: loss = 0.6783391833305359, acc = 0.79296875\n",
      "Batch 17: loss = 0.7320854067802429, acc = 0.767578125\n",
      "Batch 18: loss = 0.7292016744613647, acc = 0.7890625\n",
      "Batch 19: loss = 0.7535788416862488, acc = 0.7744140625\n",
      "Batch 20: loss = 0.7387939691543579, acc = 0.7705078125\n",
      "Batch 21: loss = 0.8270071148872375, acc = 0.740234375\n",
      "Batch 22: loss = 0.7532473802566528, acc = 0.763671875\n",
      "Batch 23: loss = 0.727148175239563, acc = 0.7705078125\n",
      "Batch 24: loss = 0.6673375368118286, acc = 0.8037109375\n",
      "Batch 25: loss = 0.6824259161949158, acc = 0.7880859375\n",
      "Batch 26: loss = 0.5895324945449829, acc = 0.82421875\n",
      "Batch 27: loss = 0.538245439529419, acc = 0.833984375\n",
      "Batch 28: loss = 0.6243348717689514, acc = 0.80859375\n",
      "Batch 29: loss = 0.6643583178520203, acc = 0.7958984375\n",
      "Batch 30: loss = 0.6166437268257141, acc = 0.80859375\n",
      "Batch 31: loss = 0.6732801198959351, acc = 0.7978515625\n",
      "Batch 32: loss = 0.6484152674674988, acc = 0.7939453125\n",
      "Batch 33: loss = 0.752558708190918, acc = 0.765625\n",
      "Batch 34: loss = 0.8076796531677246, acc = 0.755859375\n",
      "Batch 35: loss = 0.6869878172874451, acc = 0.791015625\n",
      "Batch 36: loss = 0.5952771306037903, acc = 0.8212890625\n",
      "Batch 37: loss = 0.7424851655960083, acc = 0.775390625\n",
      "Batch 38: loss = 0.6741076707839966, acc = 0.78515625\n",
      "Batch 39: loss = 0.7311664819717407, acc = 0.7705078125\n",
      "Batch 40: loss = 0.6916638612747192, acc = 0.787109375\n",
      "Batch 41: loss = 0.7437486052513123, acc = 0.7626953125\n",
      "\n",
      "Epoch 49/100\n",
      "Batch 1: loss = 0.697128415107727, acc = 0.7939453125\n",
      "Batch 2: loss = 0.6059157848358154, acc = 0.8212890625\n",
      "Batch 3: loss = 0.5782631039619446, acc = 0.8291015625\n",
      "Batch 4: loss = 0.6125816106796265, acc = 0.8212890625\n",
      "Batch 5: loss = 0.5552041530609131, acc = 0.8466796875\n",
      "Batch 6: loss = 0.6115174293518066, acc = 0.8154296875\n",
      "Batch 7: loss = 0.5906167030334473, acc = 0.814453125\n",
      "Batch 8: loss = 0.5724063515663147, acc = 0.8349609375\n",
      "Batch 9: loss = 0.6476225256919861, acc = 0.8125\n",
      "Batch 10: loss = 0.6668655872344971, acc = 0.802734375\n",
      "Batch 11: loss = 0.770366907119751, acc = 0.7529296875\n",
      "Batch 12: loss = 0.6692235469818115, acc = 0.7802734375\n",
      "Batch 13: loss = 0.6939935684204102, acc = 0.783203125\n",
      "Batch 14: loss = 0.6169053912162781, acc = 0.8115234375\n",
      "Batch 15: loss = 0.6228706240653992, acc = 0.8154296875\n",
      "Batch 16: loss = 0.6581472158432007, acc = 0.798828125\n",
      "Batch 17: loss = 0.6917131543159485, acc = 0.7890625\n",
      "Batch 18: loss = 0.7220792770385742, acc = 0.765625\n",
      "Batch 19: loss = 0.7194570302963257, acc = 0.7744140625\n",
      "Batch 20: loss = 0.7552295923233032, acc = 0.775390625\n",
      "Batch 21: loss = 0.73029625415802, acc = 0.767578125\n",
      "Batch 22: loss = 0.7092235088348389, acc = 0.7861328125\n",
      "Batch 23: loss = 0.6769261360168457, acc = 0.794921875\n",
      "Batch 24: loss = 0.6561855673789978, acc = 0.80078125\n",
      "Batch 25: loss = 0.6635191440582275, acc = 0.794921875\n",
      "Batch 26: loss = 0.585342526435852, acc = 0.8271484375\n",
      "Batch 27: loss = 0.5761733055114746, acc = 0.830078125\n",
      "Batch 28: loss = 0.6322144269943237, acc = 0.8046875\n",
      "Batch 29: loss = 0.6306338310241699, acc = 0.7998046875\n",
      "Batch 30: loss = 0.5974477529525757, acc = 0.8017578125\n",
      "Batch 31: loss = 0.6833821535110474, acc = 0.79296875\n",
      "Batch 32: loss = 0.6253904700279236, acc = 0.7998046875\n",
      "Batch 33: loss = 0.6981566548347473, acc = 0.7744140625\n",
      "Batch 34: loss = 0.7340025901794434, acc = 0.7861328125\n",
      "Batch 35: loss = 0.7049514055252075, acc = 0.7998046875\n",
      "Batch 36: loss = 0.5931342840194702, acc = 0.828125\n",
      "Batch 37: loss = 0.6642264127731323, acc = 0.8017578125\n",
      "Batch 38: loss = 0.6903238296508789, acc = 0.7802734375\n",
      "Batch 39: loss = 0.7027935981750488, acc = 0.76953125\n",
      "Batch 40: loss = 0.6700881123542786, acc = 0.7822265625\n",
      "Batch 41: loss = 0.7183852791786194, acc = 0.79296875\n",
      "\n",
      "Epoch 50/100\n",
      "Batch 1: loss = 0.6644061207771301, acc = 0.806640625\n",
      "Batch 2: loss = 0.5826942324638367, acc = 0.81640625\n",
      "Batch 3: loss = 0.5663845539093018, acc = 0.837890625\n",
      "Batch 4: loss = 0.5968209505081177, acc = 0.8203125\n",
      "Batch 5: loss = 0.5424787998199463, acc = 0.83203125\n",
      "Batch 6: loss = 0.5716620683670044, acc = 0.826171875\n",
      "Batch 7: loss = 0.5931183695793152, acc = 0.818359375\n",
      "Batch 8: loss = 0.5811681747436523, acc = 0.8232421875\n",
      "Batch 9: loss = 0.6161835789680481, acc = 0.818359375\n",
      "Batch 10: loss = 0.6244057416915894, acc = 0.8037109375\n",
      "Batch 11: loss = 0.7395350933074951, acc = 0.7705078125\n",
      "Batch 12: loss = 0.6836245059967041, acc = 0.775390625\n",
      "Batch 13: loss = 0.7069960832595825, acc = 0.7900390625\n",
      "Batch 14: loss = 0.6490470170974731, acc = 0.79296875\n",
      "Batch 15: loss = 0.6257094740867615, acc = 0.81640625\n",
      "Batch 16: loss = 0.5980018377304077, acc = 0.8173828125\n",
      "Batch 17: loss = 0.6391925811767578, acc = 0.80078125\n",
      "Batch 18: loss = 0.7141435146331787, acc = 0.7626953125\n",
      "Batch 19: loss = 0.7127909660339355, acc = 0.7734375\n",
      "Batch 20: loss = 0.7352139949798584, acc = 0.767578125\n",
      "Batch 21: loss = 0.7565499544143677, acc = 0.765625\n",
      "Batch 22: loss = 0.6781158447265625, acc = 0.79296875\n",
      "Batch 23: loss = 0.6710913181304932, acc = 0.779296875\n",
      "Batch 24: loss = 0.6546921730041504, acc = 0.8017578125\n",
      "Batch 25: loss = 0.6404271125793457, acc = 0.7998046875\n",
      "Batch 26: loss = 0.5632216930389404, acc = 0.8359375\n",
      "Batch 27: loss = 0.5009483098983765, acc = 0.8525390625\n",
      "Batch 28: loss = 0.5961889028549194, acc = 0.8271484375\n",
      "Batch 29: loss = 0.6205689907073975, acc = 0.796875\n",
      "Batch 30: loss = 0.5824519395828247, acc = 0.8330078125\n",
      "Batch 31: loss = 0.625873327255249, acc = 0.8115234375\n",
      "Batch 32: loss = 0.5665103197097778, acc = 0.837890625\n",
      "Batch 33: loss = 0.6755909323692322, acc = 0.79296875\n",
      "Batch 34: loss = 0.7547650933265686, acc = 0.7548828125\n",
      "Batch 35: loss = 0.6557601094245911, acc = 0.7939453125\n",
      "Batch 36: loss = 0.5685157775878906, acc = 0.830078125\n",
      "Batch 37: loss = 0.6781361103057861, acc = 0.7900390625\n",
      "Batch 38: loss = 0.6065798401832581, acc = 0.8193359375\n",
      "Batch 39: loss = 0.6561043858528137, acc = 0.791015625\n",
      "Batch 40: loss = 0.6875914335250854, acc = 0.787109375\n",
      "Batch 41: loss = 0.6809329986572266, acc = 0.7861328125\n",
      "Saved checkpoint to weights_eminem_input.txt.50.h5\n",
      "\n",
      "Epoch 51/100\n",
      "Batch 1: loss = 0.6339386701583862, acc = 0.8115234375\n",
      "Batch 2: loss = 0.5894806385040283, acc = 0.830078125\n",
      "Batch 3: loss = 0.575699508190155, acc = 0.8291015625\n",
      "Batch 4: loss = 0.5948590636253357, acc = 0.822265625\n",
      "Batch 5: loss = 0.5395305156707764, acc = 0.8388671875\n",
      "Batch 6: loss = 0.553457498550415, acc = 0.8349609375\n",
      "Batch 7: loss = 0.5821260213851929, acc = 0.8251953125\n",
      "Batch 8: loss = 0.5814856290817261, acc = 0.83203125\n",
      "Batch 9: loss = 0.5773164629936218, acc = 0.822265625\n",
      "Batch 10: loss = 0.6484339833259583, acc = 0.8046875\n",
      "Batch 11: loss = 0.7028418779373169, acc = 0.783203125\n",
      "Batch 12: loss = 0.6457207798957825, acc = 0.814453125\n",
      "Batch 13: loss = 0.6591873168945312, acc = 0.7919921875\n",
      "Batch 14: loss = 0.6029617786407471, acc = 0.8291015625\n",
      "Batch 15: loss = 0.6338472366333008, acc = 0.822265625\n",
      "Batch 16: loss = 0.6476967334747314, acc = 0.802734375\n",
      "Batch 17: loss = 0.6096988916397095, acc = 0.8125\n",
      "Batch 18: loss = 0.6707539558410645, acc = 0.7890625\n",
      "Batch 19: loss = 0.7155483961105347, acc = 0.77734375\n",
      "Batch 20: loss = 0.7171065807342529, acc = 0.7763671875\n",
      "Batch 21: loss = 0.7508174180984497, acc = 0.75\n",
      "Batch 22: loss = 0.6903015971183777, acc = 0.7861328125\n",
      "Batch 23: loss = 0.6627049446105957, acc = 0.79296875\n",
      "Batch 24: loss = 0.6434338092803955, acc = 0.794921875\n",
      "Batch 25: loss = 0.6160396337509155, acc = 0.8017578125\n",
      "Batch 26: loss = 0.5636324286460876, acc = 0.8193359375\n",
      "Batch 27: loss = 0.5131271481513977, acc = 0.8583984375\n",
      "Batch 28: loss = 0.5831343531608582, acc = 0.8310546875\n",
      "Batch 29: loss = 0.6050546169281006, acc = 0.810546875\n",
      "Batch 30: loss = 0.5888619422912598, acc = 0.82421875\n",
      "Batch 31: loss = 0.626103401184082, acc = 0.8134765625\n",
      "Batch 32: loss = 0.5849273800849915, acc = 0.82421875\n",
      "Batch 33: loss = 0.659374475479126, acc = 0.779296875\n",
      "Batch 34: loss = 0.7211660146713257, acc = 0.7763671875\n",
      "Batch 35: loss = 0.6708229780197144, acc = 0.8076171875\n",
      "Batch 36: loss = 0.563697338104248, acc = 0.8251953125\n",
      "Batch 37: loss = 0.6419632434844971, acc = 0.8056640625\n",
      "Batch 38: loss = 0.6388065814971924, acc = 0.80078125\n",
      "Batch 39: loss = 0.6684759259223938, acc = 0.791015625\n",
      "Batch 40: loss = 0.6451932191848755, acc = 0.7919921875\n",
      "Batch 41: loss = 0.6961999535560608, acc = 0.7841796875\n",
      "\n",
      "Epoch 52/100\n",
      "Batch 1: loss = 0.6258344054222107, acc = 0.826171875\n",
      "Batch 2: loss = 0.5324146747589111, acc = 0.8427734375\n",
      "Batch 3: loss = 0.5506070852279663, acc = 0.8427734375\n",
      "Batch 4: loss = 0.5948020815849304, acc = 0.8251953125\n",
      "Batch 5: loss = 0.5403885245323181, acc = 0.8427734375\n",
      "Batch 6: loss = 0.5394494533538818, acc = 0.8388671875\n",
      "Batch 7: loss = 0.599652886390686, acc = 0.81640625\n",
      "Batch 8: loss = 0.5722053050994873, acc = 0.830078125\n",
      "Batch 9: loss = 0.5948621034622192, acc = 0.8212890625\n",
      "Batch 10: loss = 0.5764800310134888, acc = 0.8203125\n",
      "Batch 11: loss = 0.6558784246444702, acc = 0.791015625\n",
      "Batch 12: loss = 0.6451818346977234, acc = 0.7919921875\n",
      "Batch 13: loss = 0.6652171015739441, acc = 0.8134765625\n",
      "Batch 14: loss = 0.5968148708343506, acc = 0.8173828125\n",
      "Batch 15: loss = 0.5659706592559814, acc = 0.828125\n",
      "Batch 16: loss = 0.6561682224273682, acc = 0.7861328125\n",
      "Batch 17: loss = 0.6607107520103455, acc = 0.7861328125\n",
      "Batch 18: loss = 0.6849039196968079, acc = 0.77734375\n",
      "Batch 19: loss = 0.6516789197921753, acc = 0.7958984375\n",
      "Batch 20: loss = 0.6913598775863647, acc = 0.7783203125\n",
      "Batch 21: loss = 0.6966958045959473, acc = 0.7705078125\n",
      "Batch 22: loss = 0.6358797550201416, acc = 0.8037109375\n",
      "Batch 23: loss = 0.6366782784461975, acc = 0.80078125\n",
      "Batch 24: loss = 0.5916867852210999, acc = 0.8095703125\n",
      "Batch 25: loss = 0.5993757247924805, acc = 0.8212890625\n",
      "Batch 26: loss = 0.5630708336830139, acc = 0.8271484375\n",
      "Batch 27: loss = 0.5140918493270874, acc = 0.857421875\n",
      "Batch 28: loss = 0.5621491074562073, acc = 0.8203125\n",
      "Batch 29: loss = 0.6386216878890991, acc = 0.80078125\n",
      "Batch 30: loss = 0.5608544945716858, acc = 0.830078125\n",
      "Batch 31: loss = 0.6220356225967407, acc = 0.8076171875\n",
      "Batch 32: loss = 0.5679595470428467, acc = 0.8291015625\n",
      "Batch 33: loss = 0.6211826801300049, acc = 0.8046875\n",
      "Batch 34: loss = 0.7219654321670532, acc = 0.783203125\n",
      "Batch 35: loss = 0.6316044926643372, acc = 0.8037109375\n",
      "Batch 36: loss = 0.5624734163284302, acc = 0.8359375\n",
      "Batch 37: loss = 0.6054351329803467, acc = 0.8115234375\n",
      "Batch 38: loss = 0.6223979592323303, acc = 0.80859375\n",
      "Batch 39: loss = 0.6288179755210876, acc = 0.8017578125\n",
      "Batch 40: loss = 0.6903189420700073, acc = 0.7802734375\n",
      "Batch 41: loss = 0.6856428384780884, acc = 0.7666015625\n",
      "\n",
      "Epoch 53/100\n",
      "Batch 1: loss = 0.5920739769935608, acc = 0.8251953125\n",
      "Batch 2: loss = 0.5574188232421875, acc = 0.8330078125\n",
      "Batch 3: loss = 0.5780127048492432, acc = 0.8134765625\n",
      "Batch 4: loss = 0.5419845581054688, acc = 0.845703125\n",
      "Batch 5: loss = 0.4988628327846527, acc = 0.85546875\n",
      "Batch 6: loss = 0.5251761674880981, acc = 0.837890625\n",
      "Batch 7: loss = 0.6002298593521118, acc = 0.8203125\n",
      "Batch 8: loss = 0.5836314558982849, acc = 0.8193359375\n",
      "Batch 9: loss = 0.6060826778411865, acc = 0.8291015625\n",
      "Batch 10: loss = 0.6094878315925598, acc = 0.7998046875\n",
      "Batch 11: loss = 0.692962646484375, acc = 0.78515625\n",
      "Batch 12: loss = 0.5692176222801208, acc = 0.8134765625\n",
      "Batch 13: loss = 0.5967059135437012, acc = 0.8134765625\n",
      "Batch 14: loss = 0.5799866318702698, acc = 0.8251953125\n",
      "Batch 15: loss = 0.5812290906906128, acc = 0.833984375\n",
      "Batch 16: loss = 0.5925144553184509, acc = 0.8095703125\n",
      "Batch 17: loss = 0.6315096020698547, acc = 0.810546875\n",
      "Batch 18: loss = 0.665595531463623, acc = 0.775390625\n",
      "Batch 19: loss = 0.6846837401390076, acc = 0.787109375\n",
      "Batch 20: loss = 0.7088019847869873, acc = 0.7744140625\n",
      "Batch 21: loss = 0.7325782775878906, acc = 0.7646484375\n",
      "Batch 22: loss = 0.6461462378501892, acc = 0.7900390625\n",
      "Batch 23: loss = 0.638853907585144, acc = 0.796875\n",
      "Batch 24: loss = 0.5674499273300171, acc = 0.814453125\n",
      "Batch 25: loss = 0.5902019739151001, acc = 0.822265625\n",
      "Batch 26: loss = 0.5129823684692383, acc = 0.8408203125\n",
      "Batch 27: loss = 0.47164130210876465, acc = 0.85546875\n",
      "Batch 28: loss = 0.562448263168335, acc = 0.8271484375\n",
      "Batch 29: loss = 0.5822976231575012, acc = 0.8212890625\n",
      "Batch 30: loss = 0.5832127928733826, acc = 0.8193359375\n",
      "Batch 31: loss = 0.6105413436889648, acc = 0.8037109375\n",
      "Batch 32: loss = 0.5564005374908447, acc = 0.826171875\n",
      "Batch 33: loss = 0.6460961699485779, acc = 0.796875\n",
      "Batch 34: loss = 0.6804282665252686, acc = 0.7919921875\n",
      "Batch 35: loss = 0.6462609767913818, acc = 0.8046875\n",
      "Batch 36: loss = 0.5378745794296265, acc = 0.845703125\n",
      "Batch 37: loss = 0.6145140528678894, acc = 0.8115234375\n",
      "Batch 38: loss = 0.5964463949203491, acc = 0.814453125\n",
      "Batch 39: loss = 0.6526657342910767, acc = 0.78515625\n",
      "Batch 40: loss = 0.6504409909248352, acc = 0.796875\n",
      "Batch 41: loss = 0.6833333373069763, acc = 0.7822265625\n",
      "\n",
      "Epoch 54/100\n",
      "Batch 1: loss = 0.635198712348938, acc = 0.814453125\n",
      "Batch 2: loss = 0.5496640801429749, acc = 0.8349609375\n",
      "Batch 3: loss = 0.5458081960678101, acc = 0.8310546875\n",
      "Batch 4: loss = 0.5800155997276306, acc = 0.818359375\n",
      "Batch 5: loss = 0.49616190791130066, acc = 0.8525390625\n",
      "Batch 6: loss = 0.5275161266326904, acc = 0.84765625\n",
      "Batch 7: loss = 0.5043487548828125, acc = 0.8388671875\n",
      "Batch 8: loss = 0.5358903408050537, acc = 0.8349609375\n",
      "Batch 9: loss = 0.5664621591567993, acc = 0.8251953125\n",
      "Batch 10: loss = 0.6034939289093018, acc = 0.8173828125\n",
      "Batch 11: loss = 0.6673253774642944, acc = 0.779296875\n",
      "Batch 12: loss = 0.6425445079803467, acc = 0.7900390625\n",
      "Batch 13: loss = 0.5806053280830383, acc = 0.8173828125\n",
      "Batch 14: loss = 0.5530047416687012, acc = 0.8427734375\n",
      "Batch 15: loss = 0.5388844609260559, acc = 0.8408203125\n",
      "Batch 16: loss = 0.5350706577301025, acc = 0.84375\n",
      "Batch 17: loss = 0.6027206182479858, acc = 0.8203125\n",
      "Batch 18: loss = 0.6321218609809875, acc = 0.8017578125\n",
      "Batch 19: loss = 0.6367788314819336, acc = 0.8017578125\n",
      "Batch 20: loss = 0.6972689032554626, acc = 0.7841796875\n",
      "Batch 21: loss = 0.6916969418525696, acc = 0.7666015625\n",
      "Batch 22: loss = 0.6772034764289856, acc = 0.798828125\n",
      "Batch 23: loss = 0.6275234222412109, acc = 0.8095703125\n",
      "Batch 24: loss = 0.6526753902435303, acc = 0.7958984375\n",
      "Batch 25: loss = 0.6172848343849182, acc = 0.806640625\n",
      "Batch 26: loss = 0.5247523784637451, acc = 0.8388671875\n",
      "Batch 27: loss = 0.4574078917503357, acc = 0.8603515625\n",
      "Batch 28: loss = 0.5405197143554688, acc = 0.833984375\n",
      "Batch 29: loss = 0.5671300888061523, acc = 0.8369140625\n",
      "Batch 30: loss = 0.5379139184951782, acc = 0.837890625\n",
      "Batch 31: loss = 0.5863741636276245, acc = 0.8251953125\n",
      "Batch 32: loss = 0.5249214768409729, acc = 0.8447265625\n",
      "Batch 33: loss = 0.6555193066596985, acc = 0.7939453125\n",
      "Batch 34: loss = 0.665067195892334, acc = 0.80078125\n",
      "Batch 35: loss = 0.5997041463851929, acc = 0.830078125\n",
      "Batch 36: loss = 0.5503072142601013, acc = 0.830078125\n",
      "Batch 37: loss = 0.5933765172958374, acc = 0.8251953125\n",
      "Batch 38: loss = 0.5586003065109253, acc = 0.8203125\n",
      "Batch 39: loss = 0.6297140717506409, acc = 0.8046875\n",
      "Batch 40: loss = 0.6368892192840576, acc = 0.7802734375\n",
      "Batch 41: loss = 0.6630029678344727, acc = 0.783203125\n",
      "\n",
      "Epoch 55/100\n",
      "Batch 1: loss = 0.6381373405456543, acc = 0.814453125\n",
      "Batch 2: loss = 0.5451309084892273, acc = 0.830078125\n",
      "Batch 3: loss = 0.5267859101295471, acc = 0.84765625\n",
      "Batch 4: loss = 0.5465084910392761, acc = 0.833984375\n",
      "Batch 5: loss = 0.5028170347213745, acc = 0.8515625\n",
      "Batch 6: loss = 0.4574739933013916, acc = 0.853515625\n",
      "Batch 7: loss = 0.5120075941085815, acc = 0.837890625\n",
      "Batch 8: loss = 0.492822527885437, acc = 0.861328125\n",
      "Batch 9: loss = 0.5522581338882446, acc = 0.82421875\n",
      "Batch 10: loss = 0.5256441831588745, acc = 0.8486328125\n",
      "Batch 11: loss = 0.6562286615371704, acc = 0.8017578125\n",
      "Batch 12: loss = 0.6013391613960266, acc = 0.8095703125\n",
      "Batch 13: loss = 0.6131802797317505, acc = 0.8193359375\n",
      "Batch 14: loss = 0.5463067889213562, acc = 0.8291015625\n",
      "Batch 15: loss = 0.5176407098770142, acc = 0.8486328125\n",
      "Batch 16: loss = 0.5337601900100708, acc = 0.830078125\n",
      "Batch 17: loss = 0.5619665384292603, acc = 0.8193359375\n",
      "Batch 18: loss = 0.578118085861206, acc = 0.8271484375\n",
      "Batch 19: loss = 0.6022895574569702, acc = 0.8125\n",
      "Batch 20: loss = 0.6786648631095886, acc = 0.7978515625\n",
      "Batch 21: loss = 0.6229361891746521, acc = 0.810546875\n",
      "Batch 22: loss = 0.6711889505386353, acc = 0.7841796875\n",
      "Batch 23: loss = 0.6599032878875732, acc = 0.802734375\n",
      "Batch 24: loss = 0.5936144590377808, acc = 0.806640625\n",
      "Batch 25: loss = 0.5926251411437988, acc = 0.80859375\n",
      "Batch 26: loss = 0.5112243294715881, acc = 0.849609375\n",
      "Batch 27: loss = 0.46584731340408325, acc = 0.8564453125\n",
      "Batch 28: loss = 0.5047998428344727, acc = 0.8544921875\n",
      "Batch 29: loss = 0.5636659860610962, acc = 0.8291015625\n",
      "Batch 30: loss = 0.5146446228027344, acc = 0.845703125\n",
      "Batch 31: loss = 0.5664398670196533, acc = 0.826171875\n",
      "Batch 32: loss = 0.5078927278518677, acc = 0.85546875\n",
      "Batch 33: loss = 0.6034784913063049, acc = 0.8134765625\n",
      "Batch 34: loss = 0.6891058683395386, acc = 0.802734375\n",
      "Batch 35: loss = 0.6157071590423584, acc = 0.8046875\n",
      "Batch 36: loss = 0.5022670030593872, acc = 0.8544921875\n",
      "Batch 37: loss = 0.5469927787780762, acc = 0.8291015625\n",
      "Batch 38: loss = 0.5494548082351685, acc = 0.8359375\n",
      "Batch 39: loss = 0.5807904005050659, acc = 0.814453125\n",
      "Batch 40: loss = 0.5971930027008057, acc = 0.8115234375\n",
      "Batch 41: loss = 0.5877057313919067, acc = 0.822265625\n",
      "\n",
      "Epoch 56/100\n",
      "Batch 1: loss = 0.5644592642784119, acc = 0.8232421875\n",
      "Batch 2: loss = 0.5075066685676575, acc = 0.841796875\n",
      "Batch 3: loss = 0.4680793285369873, acc = 0.861328125\n",
      "Batch 4: loss = 0.49406492710113525, acc = 0.857421875\n",
      "Batch 5: loss = 0.482269823551178, acc = 0.859375\n",
      "Batch 6: loss = 0.47629719972610474, acc = 0.86328125\n",
      "Batch 7: loss = 0.5175848007202148, acc = 0.8349609375\n",
      "Batch 8: loss = 0.49802204966545105, acc = 0.8408203125\n",
      "Batch 9: loss = 0.5598596334457397, acc = 0.826171875\n",
      "Batch 10: loss = 0.5432078838348389, acc = 0.8447265625\n",
      "Batch 11: loss = 0.6708710789680481, acc = 0.783203125\n",
      "Batch 12: loss = 0.5678818821907043, acc = 0.8232421875\n",
      "Batch 13: loss = 0.6005531549453735, acc = 0.8056640625\n",
      "Batch 14: loss = 0.5357977747917175, acc = 0.83203125\n",
      "Batch 15: loss = 0.5346254110336304, acc = 0.8359375\n",
      "Batch 16: loss = 0.5076271295547485, acc = 0.84375\n",
      "Batch 17: loss = 0.5471169948577881, acc = 0.8330078125\n",
      "Batch 18: loss = 0.5685564279556274, acc = 0.8173828125\n",
      "Batch 19: loss = 0.5787692666053772, acc = 0.828125\n",
      "Batch 20: loss = 0.5830093622207642, acc = 0.8271484375\n",
      "Batch 21: loss = 0.6435689926147461, acc = 0.8017578125\n",
      "Batch 22: loss = 0.5974560976028442, acc = 0.814453125\n",
      "Batch 23: loss = 0.5635592341423035, acc = 0.828125\n",
      "Batch 24: loss = 0.5402483940124512, acc = 0.8310546875\n",
      "Batch 25: loss = 0.5279517769813538, acc = 0.833984375\n",
      "Batch 26: loss = 0.47905975580215454, acc = 0.8603515625\n",
      "Batch 27: loss = 0.4437410533428192, acc = 0.8671875\n",
      "Batch 28: loss = 0.5255868434906006, acc = 0.8466796875\n",
      "Batch 29: loss = 0.5175093412399292, acc = 0.83984375\n",
      "Batch 30: loss = 0.501354992389679, acc = 0.8544921875\n",
      "Batch 31: loss = 0.5444662570953369, acc = 0.8408203125\n",
      "Batch 32: loss = 0.5033812522888184, acc = 0.845703125\n",
      "Batch 33: loss = 0.5882634520530701, acc = 0.810546875\n",
      "Batch 34: loss = 0.643335223197937, acc = 0.802734375\n",
      "Batch 35: loss = 0.5692713260650635, acc = 0.83203125\n",
      "Batch 36: loss = 0.4748263955116272, acc = 0.8603515625\n",
      "Batch 37: loss = 0.5655937194824219, acc = 0.8154296875\n",
      "Batch 38: loss = 0.5573737621307373, acc = 0.83984375\n",
      "Batch 39: loss = 0.5966348648071289, acc = 0.8134765625\n",
      "Batch 40: loss = 0.5678480863571167, acc = 0.8212890625\n",
      "Batch 41: loss = 0.5440726280212402, acc = 0.8310546875\n",
      "\n",
      "Epoch 57/100\n",
      "Batch 1: loss = 0.5664388537406921, acc = 0.83984375\n",
      "Batch 2: loss = 0.4612199664115906, acc = 0.859375\n",
      "Batch 3: loss = 0.5113551616668701, acc = 0.8447265625\n",
      "Batch 4: loss = 0.503085732460022, acc = 0.84375\n",
      "Batch 5: loss = 0.4302155375480652, acc = 0.8798828125\n",
      "Batch 6: loss = 0.488700270652771, acc = 0.8564453125\n",
      "Batch 7: loss = 0.5016772150993347, acc = 0.845703125\n",
      "Batch 8: loss = 0.48305192589759827, acc = 0.86328125\n",
      "Batch 9: loss = 0.5488300323486328, acc = 0.8359375\n",
      "Batch 10: loss = 0.5635018944740295, acc = 0.830078125\n",
      "Batch 11: loss = 0.6211709976196289, acc = 0.802734375\n",
      "Batch 12: loss = 0.5460066795349121, acc = 0.833984375\n",
      "Batch 13: loss = 0.5437453985214233, acc = 0.8271484375\n",
      "Batch 14: loss = 0.4980194568634033, acc = 0.8486328125\n",
      "Batch 15: loss = 0.5101896524429321, acc = 0.859375\n",
      "Batch 16: loss = 0.5608335137367249, acc = 0.822265625\n",
      "Batch 17: loss = 0.5237636566162109, acc = 0.828125\n",
      "Batch 18: loss = 0.5701533555984497, acc = 0.818359375\n",
      "Batch 19: loss = 0.591347336769104, acc = 0.8271484375\n",
      "Batch 20: loss = 0.6087372303009033, acc = 0.8017578125\n",
      "Batch 21: loss = 0.6055263876914978, acc = 0.8134765625\n",
      "Batch 22: loss = 0.5497387647628784, acc = 0.8408203125\n",
      "Batch 23: loss = 0.5349586606025696, acc = 0.83203125\n",
      "Batch 24: loss = 0.5250537395477295, acc = 0.8330078125\n",
      "Batch 25: loss = 0.5114052295684814, acc = 0.8505859375\n",
      "Batch 26: loss = 0.4626696705818176, acc = 0.859375\n",
      "Batch 27: loss = 0.42440786957740784, acc = 0.8681640625\n",
      "Batch 28: loss = 0.5014413595199585, acc = 0.859375\n",
      "Batch 29: loss = 0.5405418872833252, acc = 0.8310546875\n",
      "Batch 30: loss = 0.5516678094863892, acc = 0.8271484375\n",
      "Batch 31: loss = 0.5218170881271362, acc = 0.8427734375\n",
      "Batch 32: loss = 0.5462446212768555, acc = 0.83203125\n",
      "Batch 33: loss = 0.5878833532333374, acc = 0.81640625\n",
      "Batch 34: loss = 0.5782302021980286, acc = 0.826171875\n",
      "Batch 35: loss = 0.533269464969635, acc = 0.841796875\n",
      "Batch 36: loss = 0.4482334852218628, acc = 0.8505859375\n",
      "Batch 37: loss = 0.5363081097602844, acc = 0.841796875\n",
      "Batch 38: loss = 0.49639248847961426, acc = 0.853515625\n",
      "Batch 39: loss = 0.5936440229415894, acc = 0.8017578125\n",
      "Batch 40: loss = 0.5562412738800049, acc = 0.8193359375\n",
      "Batch 41: loss = 0.5737501382827759, acc = 0.8203125\n",
      "\n",
      "Epoch 58/100\n",
      "Batch 1: loss = 0.5199179649353027, acc = 0.857421875\n",
      "Batch 2: loss = 0.46129661798477173, acc = 0.8623046875\n",
      "Batch 3: loss = 0.46057116985321045, acc = 0.8671875\n",
      "Batch 4: loss = 0.438309907913208, acc = 0.873046875\n",
      "Batch 5: loss = 0.43147435784339905, acc = 0.8642578125\n",
      "Batch 6: loss = 0.4393109083175659, acc = 0.8564453125\n",
      "Batch 7: loss = 0.47467708587646484, acc = 0.8564453125\n",
      "Batch 8: loss = 0.47585391998291016, acc = 0.85546875\n",
      "Batch 9: loss = 0.5232308506965637, acc = 0.8544921875\n",
      "Batch 10: loss = 0.5144174098968506, acc = 0.8369140625\n",
      "Batch 11: loss = 0.556155800819397, acc = 0.8359375\n",
      "Batch 12: loss = 0.5227720737457275, acc = 0.828125\n",
      "Batch 13: loss = 0.5009950399398804, acc = 0.8525390625\n",
      "Batch 14: loss = 0.48956096172332764, acc = 0.8486328125\n",
      "Batch 15: loss = 0.49981558322906494, acc = 0.849609375\n",
      "Batch 16: loss = 0.48215335607528687, acc = 0.8408203125\n",
      "Batch 17: loss = 0.5114037990570068, acc = 0.841796875\n",
      "Batch 18: loss = 0.5227934718132019, acc = 0.8349609375\n",
      "Batch 19: loss = 0.5714882612228394, acc = 0.814453125\n",
      "Batch 20: loss = 0.5828630328178406, acc = 0.8232421875\n",
      "Batch 21: loss = 0.6008041501045227, acc = 0.8056640625\n",
      "Batch 22: loss = 0.5678616762161255, acc = 0.8349609375\n",
      "Batch 23: loss = 0.5509151220321655, acc = 0.8291015625\n",
      "Batch 24: loss = 0.5072221159934998, acc = 0.8388671875\n",
      "Batch 25: loss = 0.4897611439228058, acc = 0.857421875\n",
      "Batch 26: loss = 0.4505165219306946, acc = 0.857421875\n",
      "Batch 27: loss = 0.4134538769721985, acc = 0.8740234375\n",
      "Batch 28: loss = 0.4857076406478882, acc = 0.849609375\n",
      "Batch 29: loss = 0.5039559006690979, acc = 0.8447265625\n",
      "Batch 30: loss = 0.5189940929412842, acc = 0.83984375\n",
      "Batch 31: loss = 0.5136836767196655, acc = 0.857421875\n",
      "Batch 32: loss = 0.45214495062828064, acc = 0.8671875\n",
      "Batch 33: loss = 0.5583795309066772, acc = 0.82421875\n",
      "Batch 34: loss = 0.6137580275535583, acc = 0.806640625\n",
      "Batch 35: loss = 0.5199755430221558, acc = 0.8408203125\n",
      "Batch 36: loss = 0.46374958753585815, acc = 0.8623046875\n",
      "Batch 37: loss = 0.5064321160316467, acc = 0.84765625\n",
      "Batch 38: loss = 0.5063889026641846, acc = 0.841796875\n",
      "Batch 39: loss = 0.5037697553634644, acc = 0.849609375\n",
      "Batch 40: loss = 0.5724915266036987, acc = 0.8154296875\n",
      "Batch 41: loss = 0.5325397849082947, acc = 0.8359375\n",
      "\n",
      "Epoch 59/100\n",
      "Batch 1: loss = 0.5049852728843689, acc = 0.849609375\n",
      "Batch 2: loss = 0.4502287209033966, acc = 0.86328125\n",
      "Batch 3: loss = 0.4460292458534241, acc = 0.861328125\n",
      "Batch 4: loss = 0.44093456864356995, acc = 0.8662109375\n",
      "Batch 5: loss = 0.4157077372074127, acc = 0.8720703125\n",
      "Batch 6: loss = 0.43003860116004944, acc = 0.8701171875\n",
      "Batch 7: loss = 0.43969428539276123, acc = 0.859375\n",
      "Batch 8: loss = 0.4195440709590912, acc = 0.8701171875\n",
      "Batch 9: loss = 0.46556025743484497, acc = 0.86328125\n",
      "Batch 10: loss = 0.4511934518814087, acc = 0.8623046875\n",
      "Batch 11: loss = 0.5331664681434631, acc = 0.837890625\n",
      "Batch 12: loss = 0.5094320178031921, acc = 0.849609375\n",
      "Batch 13: loss = 0.4948710799217224, acc = 0.8525390625\n",
      "Batch 14: loss = 0.472548246383667, acc = 0.8623046875\n",
      "Batch 15: loss = 0.45483967661857605, acc = 0.8525390625\n",
      "Batch 16: loss = 0.4931578040122986, acc = 0.8515625\n",
      "Batch 17: loss = 0.5089060664176941, acc = 0.8369140625\n",
      "Batch 18: loss = 0.5080353021621704, acc = 0.845703125\n",
      "Batch 19: loss = 0.5124713182449341, acc = 0.84375\n",
      "Batch 20: loss = 0.5621733665466309, acc = 0.833984375\n",
      "Batch 21: loss = 0.575175940990448, acc = 0.8125\n",
      "Batch 22: loss = 0.5342134237289429, acc = 0.8408203125\n",
      "Batch 23: loss = 0.512920081615448, acc = 0.845703125\n",
      "Batch 24: loss = 0.4829311966896057, acc = 0.853515625\n",
      "Batch 25: loss = 0.4703626036643982, acc = 0.857421875\n",
      "Batch 26: loss = 0.437710165977478, acc = 0.8720703125\n",
      "Batch 27: loss = 0.3914884328842163, acc = 0.8876953125\n",
      "Batch 28: loss = 0.4530097544193268, acc = 0.8671875\n",
      "Batch 29: loss = 0.47222232818603516, acc = 0.8486328125\n",
      "Batch 30: loss = 0.4489406943321228, acc = 0.8642578125\n",
      "Batch 31: loss = 0.50248783826828, acc = 0.8515625\n",
      "Batch 32: loss = 0.4307595491409302, acc = 0.8798828125\n",
      "Batch 33: loss = 0.5654376149177551, acc = 0.81640625\n",
      "Batch 34: loss = 0.5658684372901917, acc = 0.8330078125\n",
      "Batch 35: loss = 0.4771186113357544, acc = 0.861328125\n",
      "Batch 36: loss = 0.4188939929008484, acc = 0.8740234375\n",
      "Batch 37: loss = 0.5162572264671326, acc = 0.8388671875\n",
      "Batch 38: loss = 0.46050938963890076, acc = 0.865234375\n",
      "Batch 39: loss = 0.5320179462432861, acc = 0.8349609375\n",
      "Batch 40: loss = 0.5340375900268555, acc = 0.84375\n",
      "Batch 41: loss = 0.538482666015625, acc = 0.8359375\n",
      "\n",
      "Epoch 60/100\n",
      "Batch 1: loss = 0.48206016421318054, acc = 0.8505859375\n",
      "Batch 2: loss = 0.4349632263183594, acc = 0.865234375\n",
      "Batch 3: loss = 0.4082637429237366, acc = 0.884765625\n",
      "Batch 4: loss = 0.44231587648391724, acc = 0.8662109375\n",
      "Batch 5: loss = 0.3539782464504242, acc = 0.8955078125\n",
      "Batch 6: loss = 0.4273519814014435, acc = 0.861328125\n",
      "Batch 7: loss = 0.42088058590888977, acc = 0.8740234375\n",
      "Batch 8: loss = 0.42768198251724243, acc = 0.8759765625\n",
      "Batch 9: loss = 0.419294536113739, acc = 0.8701171875\n",
      "Batch 10: loss = 0.4623398780822754, acc = 0.8642578125\n",
      "Batch 11: loss = 0.502853512763977, acc = 0.837890625\n",
      "Batch 12: loss = 0.5320205688476562, acc = 0.826171875\n",
      "Batch 13: loss = 0.5071964263916016, acc = 0.8515625\n",
      "Batch 14: loss = 0.4726402461528778, acc = 0.8544921875\n",
      "Batch 15: loss = 0.42264923453330994, acc = 0.880859375\n",
      "Batch 16: loss = 0.4752137064933777, acc = 0.849609375\n",
      "Batch 17: loss = 0.4625036120414734, acc = 0.8544921875\n",
      "Batch 18: loss = 0.5286650061607361, acc = 0.8349609375\n",
      "Batch 19: loss = 0.5079410076141357, acc = 0.8486328125\n",
      "Batch 20: loss = 0.5368491411209106, acc = 0.8251953125\n",
      "Batch 21: loss = 0.5510015487670898, acc = 0.8310546875\n",
      "Batch 22: loss = 0.4799351692199707, acc = 0.845703125\n",
      "Batch 23: loss = 0.503619372844696, acc = 0.8427734375\n",
      "Batch 24: loss = 0.4915698766708374, acc = 0.8525390625\n",
      "Batch 25: loss = 0.46169912815093994, acc = 0.861328125\n",
      "Batch 26: loss = 0.475400447845459, acc = 0.8544921875\n",
      "Batch 27: loss = 0.4402031898498535, acc = 0.859375\n",
      "Batch 28: loss = 0.4605702757835388, acc = 0.861328125\n",
      "Batch 29: loss = 0.49360954761505127, acc = 0.849609375\n",
      "Batch 30: loss = 0.4487048387527466, acc = 0.853515625\n",
      "Batch 31: loss = 0.49854058027267456, acc = 0.8564453125\n",
      "Batch 32: loss = 0.4337998032569885, acc = 0.8701171875\n",
      "Batch 33: loss = 0.5160372257232666, acc = 0.83203125\n",
      "Batch 34: loss = 0.5551947951316833, acc = 0.822265625\n",
      "Batch 35: loss = 0.5277854800224304, acc = 0.833984375\n",
      "Batch 36: loss = 0.4305489659309387, acc = 0.8671875\n",
      "Batch 37: loss = 0.4672926068305969, acc = 0.857421875\n",
      "Batch 38: loss = 0.4685561954975128, acc = 0.84765625\n",
      "Batch 39: loss = 0.5124455094337463, acc = 0.8505859375\n",
      "Batch 40: loss = 0.47303587198257446, acc = 0.8525390625\n",
      "Batch 41: loss = 0.5215096473693848, acc = 0.837890625\n",
      "Saved checkpoint to weights_eminem_input.txt.60.h5\n",
      "\n",
      "Epoch 61/100\n",
      "Batch 1: loss = 0.5030766725540161, acc = 0.8603515625\n",
      "Batch 2: loss = 0.42267298698425293, acc = 0.8740234375\n",
      "Batch 3: loss = 0.41234534978866577, acc = 0.876953125\n",
      "Batch 4: loss = 0.44177213311195374, acc = 0.865234375\n",
      "Batch 5: loss = 0.3669915795326233, acc = 0.8828125\n",
      "Batch 6: loss = 0.42856404185295105, acc = 0.8662109375\n",
      "Batch 7: loss = 0.43273475766181946, acc = 0.8564453125\n",
      "Batch 8: loss = 0.44520264863967896, acc = 0.859375\n",
      "Batch 9: loss = 0.4329008460044861, acc = 0.8642578125\n",
      "Batch 10: loss = 0.4525344967842102, acc = 0.853515625\n",
      "Batch 11: loss = 0.517420768737793, acc = 0.8271484375\n",
      "Batch 12: loss = 0.4724500775337219, acc = 0.8564453125\n",
      "Batch 13: loss = 0.5205013751983643, acc = 0.837890625\n",
      "Batch 14: loss = 0.4565683603286743, acc = 0.8662109375\n",
      "Batch 15: loss = 0.43872249126434326, acc = 0.869140625\n",
      "Batch 16: loss = 0.47398388385772705, acc = 0.84765625\n",
      "Batch 17: loss = 0.48155343532562256, acc = 0.8466796875\n",
      "Batch 18: loss = 0.49414241313934326, acc = 0.8466796875\n",
      "Batch 19: loss = 0.4395678639411926, acc = 0.8662109375\n",
      "Batch 20: loss = 0.4904617965221405, acc = 0.8505859375\n",
      "Batch 21: loss = 0.5123234987258911, acc = 0.83203125\n",
      "Batch 22: loss = 0.5102880001068115, acc = 0.84375\n",
      "Batch 23: loss = 0.4520096778869629, acc = 0.85546875\n",
      "Batch 24: loss = 0.45464032888412476, acc = 0.857421875\n",
      "Batch 25: loss = 0.42734235525131226, acc = 0.8681640625\n",
      "Batch 26: loss = 0.40906861424446106, acc = 0.8671875\n",
      "Batch 27: loss = 0.38548773527145386, acc = 0.88671875\n",
      "Batch 28: loss = 0.4324799180030823, acc = 0.869140625\n",
      "Batch 29: loss = 0.45410555601119995, acc = 0.8642578125\n",
      "Batch 30: loss = 0.4247026741504669, acc = 0.8671875\n",
      "Batch 31: loss = 0.4845362603664398, acc = 0.8583984375\n",
      "Batch 32: loss = 0.4123419523239136, acc = 0.87890625\n",
      "Batch 33: loss = 0.5045584440231323, acc = 0.8349609375\n",
      "Batch 34: loss = 0.5289173126220703, acc = 0.8369140625\n",
      "Batch 35: loss = 0.47546088695526123, acc = 0.8583984375\n",
      "Batch 36: loss = 0.43431222438812256, acc = 0.8662109375\n",
      "Batch 37: loss = 0.4613499641418457, acc = 0.8603515625\n",
      "Batch 38: loss = 0.43804657459259033, acc = 0.857421875\n",
      "Batch 39: loss = 0.4872494339942932, acc = 0.853515625\n",
      "Batch 40: loss = 0.4784523546695709, acc = 0.845703125\n",
      "Batch 41: loss = 0.5239760875701904, acc = 0.8349609375\n",
      "\n",
      "Epoch 62/100\n",
      "Batch 1: loss = 0.4682774543762207, acc = 0.8623046875\n",
      "Batch 2: loss = 0.38839131593704224, acc = 0.880859375\n",
      "Batch 3: loss = 0.4137183129787445, acc = 0.8681640625\n",
      "Batch 4: loss = 0.39076754450798035, acc = 0.8798828125\n",
      "Batch 5: loss = 0.4041561186313629, acc = 0.875\n",
      "Batch 6: loss = 0.38007378578186035, acc = 0.884765625\n",
      "Batch 7: loss = 0.41052231192588806, acc = 0.8798828125\n",
      "Batch 8: loss = 0.4092831015586853, acc = 0.87109375\n",
      "Batch 9: loss = 0.449825257062912, acc = 0.857421875\n",
      "Batch 10: loss = 0.438631534576416, acc = 0.8671875\n",
      "Batch 11: loss = 0.4702185392379761, acc = 0.8544921875\n",
      "Batch 12: loss = 0.4710391163825989, acc = 0.849609375\n",
      "Batch 13: loss = 0.4354362487792969, acc = 0.865234375\n",
      "Batch 14: loss = 0.4033662974834442, acc = 0.876953125\n",
      "Batch 15: loss = 0.4145762324333191, acc = 0.8779296875\n",
      "Batch 16: loss = 0.4132910370826721, acc = 0.8798828125\n",
      "Batch 17: loss = 0.4948381185531616, acc = 0.8427734375\n",
      "Batch 18: loss = 0.4704626500606537, acc = 0.8544921875\n",
      "Batch 19: loss = 0.4720144271850586, acc = 0.85546875\n",
      "Batch 20: loss = 0.48836222290992737, acc = 0.8515625\n",
      "Batch 21: loss = 0.4888644218444824, acc = 0.8564453125\n",
      "Batch 22: loss = 0.499502956867218, acc = 0.845703125\n",
      "Batch 23: loss = 0.502154529094696, acc = 0.84765625\n",
      "Batch 24: loss = 0.44256487488746643, acc = 0.8603515625\n",
      "Batch 25: loss = 0.41522645950317383, acc = 0.8740234375\n",
      "Batch 26: loss = 0.3973390460014343, acc = 0.8671875\n",
      "Batch 27: loss = 0.35940980911254883, acc = 0.8916015625\n",
      "Batch 28: loss = 0.4184912443161011, acc = 0.8603515625\n",
      "Batch 29: loss = 0.44665369391441345, acc = 0.8583984375\n",
      "Batch 30: loss = 0.4413240849971771, acc = 0.8623046875\n",
      "Batch 31: loss = 0.47234684228897095, acc = 0.8583984375\n",
      "Batch 32: loss = 0.35546594858169556, acc = 0.8974609375\n",
      "Batch 33: loss = 0.5161444544792175, acc = 0.8359375\n",
      "Batch 34: loss = 0.5026764869689941, acc = 0.8544921875\n",
      "Batch 35: loss = 0.4649973511695862, acc = 0.8564453125\n",
      "Batch 36: loss = 0.4115774631500244, acc = 0.8720703125\n",
      "Batch 37: loss = 0.45185357332229614, acc = 0.8662109375\n",
      "Batch 38: loss = 0.4019017517566681, acc = 0.8720703125\n",
      "Batch 39: loss = 0.49680203199386597, acc = 0.845703125\n",
      "Batch 40: loss = 0.4470437169075012, acc = 0.8623046875\n",
      "Batch 41: loss = 0.45469602942466736, acc = 0.8583984375\n",
      "\n",
      "Epoch 63/100\n",
      "Batch 1: loss = 0.4727326035499573, acc = 0.8662109375\n",
      "Batch 2: loss = 0.3844914436340332, acc = 0.880859375\n",
      "Batch 3: loss = 0.3682502508163452, acc = 0.8916015625\n",
      "Batch 4: loss = 0.40019452571868896, acc = 0.876953125\n",
      "Batch 5: loss = 0.39175885915756226, acc = 0.8779296875\n",
      "Batch 6: loss = 0.4057006537914276, acc = 0.8720703125\n",
      "Batch 7: loss = 0.41832616925239563, acc = 0.869140625\n",
      "Batch 8: loss = 0.43194451928138733, acc = 0.8681640625\n",
      "Batch 9: loss = 0.4271445870399475, acc = 0.86328125\n",
      "Batch 10: loss = 0.46068039536476135, acc = 0.8466796875\n",
      "Batch 11: loss = 0.46777641773223877, acc = 0.8466796875\n",
      "Batch 12: loss = 0.40891051292419434, acc = 0.8662109375\n",
      "Batch 13: loss = 0.44055911898612976, acc = 0.86328125\n",
      "Batch 14: loss = 0.4097842574119568, acc = 0.8740234375\n",
      "Batch 15: loss = 0.41303107142448425, acc = 0.8876953125\n",
      "Batch 16: loss = 0.4703233242034912, acc = 0.8515625\n",
      "Batch 17: loss = 0.46121934056282043, acc = 0.8583984375\n",
      "Batch 18: loss = 0.4817644953727722, acc = 0.85546875\n",
      "Batch 19: loss = 0.4746967554092407, acc = 0.845703125\n",
      "Batch 20: loss = 0.5000228881835938, acc = 0.8427734375\n",
      "Batch 21: loss = 0.48224198818206787, acc = 0.8525390625\n",
      "Batch 22: loss = 0.4938615560531616, acc = 0.85546875\n",
      "Batch 23: loss = 0.47090208530426025, acc = 0.8623046875\n",
      "Batch 24: loss = 0.43614569306373596, acc = 0.875\n",
      "Batch 25: loss = 0.4440057873725891, acc = 0.875\n",
      "Batch 26: loss = 0.4115545451641083, acc = 0.880859375\n",
      "Batch 27: loss = 0.359610915184021, acc = 0.884765625\n",
      "Batch 28: loss = 0.3939957022666931, acc = 0.888671875\n",
      "Batch 29: loss = 0.44308772683143616, acc = 0.857421875\n",
      "Batch 30: loss = 0.4214474558830261, acc = 0.869140625\n",
      "Batch 31: loss = 0.41063883900642395, acc = 0.8857421875\n",
      "Batch 32: loss = 0.3933773636817932, acc = 0.8828125\n",
      "Batch 33: loss = 0.48523199558258057, acc = 0.8544921875\n",
      "Batch 34: loss = 0.49335047602653503, acc = 0.8486328125\n",
      "Batch 35: loss = 0.4540831446647644, acc = 0.8642578125\n",
      "Batch 36: loss = 0.376157283782959, acc = 0.88671875\n",
      "Batch 37: loss = 0.4466556906700134, acc = 0.859375\n",
      "Batch 38: loss = 0.4617778956890106, acc = 0.861328125\n",
      "Batch 39: loss = 0.4487871825695038, acc = 0.8671875\n",
      "Batch 40: loss = 0.4901981055736542, acc = 0.8505859375\n",
      "Batch 41: loss = 0.45872044563293457, acc = 0.849609375\n",
      "\n",
      "Epoch 64/100\n",
      "Batch 1: loss = 0.44976839423179626, acc = 0.876953125\n",
      "Batch 2: loss = 0.40001213550567627, acc = 0.869140625\n",
      "Batch 3: loss = 0.3887067139148712, acc = 0.8916015625\n",
      "Batch 4: loss = 0.36963367462158203, acc = 0.896484375\n",
      "Batch 5: loss = 0.3720402419567108, acc = 0.8955078125\n",
      "Batch 6: loss = 0.37923362851142883, acc = 0.8798828125\n",
      "Batch 7: loss = 0.36859291791915894, acc = 0.896484375\n",
      "Batch 8: loss = 0.3953873813152313, acc = 0.8740234375\n",
      "Batch 9: loss = 0.43146204948425293, acc = 0.8681640625\n",
      "Batch 10: loss = 0.43175530433654785, acc = 0.8642578125\n",
      "Batch 11: loss = 0.46859151124954224, acc = 0.857421875\n",
      "Batch 12: loss = 0.3982856571674347, acc = 0.884765625\n",
      "Batch 13: loss = 0.43718773126602173, acc = 0.8681640625\n",
      "Batch 14: loss = 0.38421982526779175, acc = 0.8818359375\n",
      "Batch 15: loss = 0.4040490388870239, acc = 0.8759765625\n",
      "Batch 16: loss = 0.3978954553604126, acc = 0.8818359375\n",
      "Batch 17: loss = 0.43112778663635254, acc = 0.8671875\n",
      "Batch 18: loss = 0.46727317571640015, acc = 0.8564453125\n",
      "Batch 19: loss = 0.4424567222595215, acc = 0.8623046875\n",
      "Batch 20: loss = 0.46215611696243286, acc = 0.85546875\n",
      "Batch 21: loss = 0.4884369373321533, acc = 0.84765625\n",
      "Batch 22: loss = 0.4658028483390808, acc = 0.8466796875\n",
      "Batch 23: loss = 0.4256855249404907, acc = 0.875\n",
      "Batch 24: loss = 0.4157032370567322, acc = 0.8720703125\n",
      "Batch 25: loss = 0.3918754458427429, acc = 0.884765625\n",
      "Batch 26: loss = 0.3918730616569519, acc = 0.873046875\n",
      "Batch 27: loss = 0.34903839230537415, acc = 0.900390625\n",
      "Batch 28: loss = 0.4328746199607849, acc = 0.8740234375\n",
      "Batch 29: loss = 0.42387092113494873, acc = 0.86328125\n",
      "Batch 30: loss = 0.42986077070236206, acc = 0.8701171875\n",
      "Batch 31: loss = 0.4427100718021393, acc = 0.865234375\n",
      "Batch 32: loss = 0.397541344165802, acc = 0.8671875\n",
      "Batch 33: loss = 0.48093029856681824, acc = 0.8388671875\n",
      "Batch 34: loss = 0.5152127146720886, acc = 0.8564453125\n",
      "Batch 35: loss = 0.47482576966285706, acc = 0.8447265625\n",
      "Batch 36: loss = 0.3719222843647003, acc = 0.88671875\n",
      "Batch 37: loss = 0.40945175290107727, acc = 0.8857421875\n",
      "Batch 38: loss = 0.4232015311717987, acc = 0.8671875\n",
      "Batch 39: loss = 0.41905903816223145, acc = 0.8671875\n",
      "Batch 40: loss = 0.43543386459350586, acc = 0.873046875\n",
      "Batch 41: loss = 0.44363126158714294, acc = 0.8525390625\n",
      "\n",
      "Epoch 65/100\n",
      "Batch 1: loss = 0.41691306233406067, acc = 0.88671875\n",
      "Batch 2: loss = 0.41539689898490906, acc = 0.87109375\n",
      "Batch 3: loss = 0.3749004006385803, acc = 0.8916015625\n",
      "Batch 4: loss = 0.38174736499786377, acc = 0.892578125\n",
      "Batch 5: loss = 0.37598568201065063, acc = 0.8818359375\n",
      "Batch 6: loss = 0.34658458828926086, acc = 0.8916015625\n",
      "Batch 7: loss = 0.379072368144989, acc = 0.880859375\n",
      "Batch 8: loss = 0.3876681625843048, acc = 0.875\n",
      "Batch 9: loss = 0.41047003865242004, acc = 0.880859375\n",
      "Batch 10: loss = 0.4280164837837219, acc = 0.86328125\n",
      "Batch 11: loss = 0.4508321285247803, acc = 0.8515625\n",
      "Batch 12: loss = 0.44093725085258484, acc = 0.8642578125\n",
      "Batch 13: loss = 0.4748367667198181, acc = 0.8583984375\n",
      "Batch 14: loss = 0.3829003572463989, acc = 0.8828125\n",
      "Batch 15: loss = 0.4071035385131836, acc = 0.87109375\n",
      "Batch 16: loss = 0.4121043384075165, acc = 0.873046875\n",
      "Batch 17: loss = 0.39750874042510986, acc = 0.8818359375\n",
      "Batch 18: loss = 0.44687116146087646, acc = 0.85546875\n",
      "Batch 19: loss = 0.45042869448661804, acc = 0.861328125\n",
      "Batch 20: loss = 0.4970952272415161, acc = 0.8515625\n",
      "Batch 21: loss = 0.5230579376220703, acc = 0.8271484375\n",
      "Batch 22: loss = 0.4461744427680969, acc = 0.857421875\n",
      "Batch 23: loss = 0.451854407787323, acc = 0.8505859375\n",
      "Batch 24: loss = 0.39738285541534424, acc = 0.8701171875\n",
      "Batch 25: loss = 0.36962127685546875, acc = 0.8935546875\n",
      "Batch 26: loss = 0.35884201526641846, acc = 0.8857421875\n",
      "Batch 27: loss = 0.35310131311416626, acc = 0.8857421875\n",
      "Batch 28: loss = 0.41565942764282227, acc = 0.87890625\n",
      "Batch 29: loss = 0.4470823407173157, acc = 0.859375\n",
      "Batch 30: loss = 0.42894238233566284, acc = 0.8662109375\n",
      "Batch 31: loss = 0.43524694442749023, acc = 0.865234375\n",
      "Batch 32: loss = 0.3740805387496948, acc = 0.8818359375\n",
      "Batch 33: loss = 0.4446302056312561, acc = 0.85546875\n",
      "Batch 34: loss = 0.46704596281051636, acc = 0.859375\n",
      "Batch 35: loss = 0.4502142667770386, acc = 0.8583984375\n",
      "Batch 36: loss = 0.36192578077316284, acc = 0.884765625\n",
      "Batch 37: loss = 0.41494566202163696, acc = 0.8759765625\n",
      "Batch 38: loss = 0.41874316334724426, acc = 0.8671875\n",
      "Batch 39: loss = 0.418215274810791, acc = 0.8642578125\n",
      "Batch 40: loss = 0.4613882303237915, acc = 0.857421875\n",
      "Batch 41: loss = 0.4787243604660034, acc = 0.83984375\n",
      "\n",
      "Epoch 66/100\n",
      "Batch 1: loss = 0.39806199073791504, acc = 0.890625\n",
      "Batch 2: loss = 0.36226922273635864, acc = 0.8896484375\n",
      "Batch 3: loss = 0.35800105333328247, acc = 0.89453125\n",
      "Batch 4: loss = 0.38165411353111267, acc = 0.8837890625\n",
      "Batch 5: loss = 0.324209988117218, acc = 0.908203125\n",
      "Batch 6: loss = 0.3689500093460083, acc = 0.8828125\n",
      "Batch 7: loss = 0.38542699813842773, acc = 0.8837890625\n",
      "Batch 8: loss = 0.3953036665916443, acc = 0.8798828125\n",
      "Batch 9: loss = 0.41483497619628906, acc = 0.8603515625\n",
      "Batch 10: loss = 0.38727307319641113, acc = 0.888671875\n",
      "Batch 11: loss = 0.45119237899780273, acc = 0.8642578125\n",
      "Batch 12: loss = 0.41449040174484253, acc = 0.8740234375\n",
      "Batch 13: loss = 0.42444586753845215, acc = 0.873046875\n",
      "Batch 14: loss = 0.3665059208869934, acc = 0.884765625\n",
      "Batch 15: loss = 0.387926310300827, acc = 0.8896484375\n",
      "Batch 16: loss = 0.3782880902290344, acc = 0.89453125\n",
      "Batch 17: loss = 0.41163575649261475, acc = 0.865234375\n",
      "Batch 18: loss = 0.42875391244888306, acc = 0.873046875\n",
      "Batch 19: loss = 0.43286848068237305, acc = 0.869140625\n",
      "Batch 20: loss = 0.4084203243255615, acc = 0.8798828125\n",
      "Batch 21: loss = 0.43357762694358826, acc = 0.876953125\n",
      "Batch 22: loss = 0.4595038890838623, acc = 0.86328125\n",
      "Batch 23: loss = 0.46805328130722046, acc = 0.8583984375\n",
      "Batch 24: loss = 0.3922678530216217, acc = 0.875\n",
      "Batch 25: loss = 0.36419567465782166, acc = 0.89453125\n",
      "Batch 26: loss = 0.3630481958389282, acc = 0.890625\n",
      "Batch 27: loss = 0.33255472779273987, acc = 0.9033203125\n",
      "Batch 28: loss = 0.35772454738616943, acc = 0.8857421875\n",
      "Batch 29: loss = 0.40723228454589844, acc = 0.8798828125\n",
      "Batch 30: loss = 0.40988993644714355, acc = 0.8681640625\n",
      "Batch 31: loss = 0.41000980138778687, acc = 0.8779296875\n",
      "Batch 32: loss = 0.3639960289001465, acc = 0.880859375\n",
      "Batch 33: loss = 0.3925955295562744, acc = 0.8798828125\n",
      "Batch 34: loss = 0.495930016040802, acc = 0.8408203125\n",
      "Batch 35: loss = 0.4719136953353882, acc = 0.84375\n",
      "Batch 36: loss = 0.3841383457183838, acc = 0.8759765625\n",
      "Batch 37: loss = 0.41827937960624695, acc = 0.87890625\n",
      "Batch 38: loss = 0.42152053117752075, acc = 0.8662109375\n",
      "Batch 39: loss = 0.4285024404525757, acc = 0.8681640625\n",
      "Batch 40: loss = 0.47562143206596375, acc = 0.8486328125\n",
      "Batch 41: loss = 0.4175824224948883, acc = 0.873046875\n",
      "\n",
      "Epoch 67/100\n",
      "Batch 1: loss = 0.43248802423477173, acc = 0.87890625\n",
      "Batch 2: loss = 0.35172227025032043, acc = 0.900390625\n",
      "Batch 3: loss = 0.36198049783706665, acc = 0.890625\n",
      "Batch 4: loss = 0.3693917989730835, acc = 0.8740234375\n",
      "Batch 5: loss = 0.35082173347473145, acc = 0.8896484375\n",
      "Batch 6: loss = 0.35744741559028625, acc = 0.876953125\n",
      "Batch 7: loss = 0.3523826003074646, acc = 0.904296875\n",
      "Batch 8: loss = 0.3669631779193878, acc = 0.892578125\n",
      "Batch 9: loss = 0.3714902997016907, acc = 0.88671875\n",
      "Batch 10: loss = 0.4194173812866211, acc = 0.8681640625\n",
      "Batch 11: loss = 0.4357357323169708, acc = 0.8671875\n",
      "Batch 12: loss = 0.39178189635276794, acc = 0.880859375\n",
      "Batch 13: loss = 0.41550397872924805, acc = 0.8720703125\n",
      "Batch 14: loss = 0.3831583559513092, acc = 0.8896484375\n",
      "Batch 15: loss = 0.39897727966308594, acc = 0.8779296875\n",
      "Batch 16: loss = 0.39810603857040405, acc = 0.87109375\n",
      "Batch 17: loss = 0.42597272992134094, acc = 0.861328125\n",
      "Batch 18: loss = 0.4576607644557953, acc = 0.84765625\n",
      "Batch 19: loss = 0.42863449454307556, acc = 0.8740234375\n",
      "Batch 20: loss = 0.4504571557044983, acc = 0.8623046875\n",
      "Batch 21: loss = 0.45215848088264465, acc = 0.86328125\n",
      "Batch 22: loss = 0.43837040662765503, acc = 0.85546875\n",
      "Batch 23: loss = 0.45695754885673523, acc = 0.857421875\n",
      "Batch 24: loss = 0.3891597390174866, acc = 0.8798828125\n",
      "Batch 25: loss = 0.40673142671585083, acc = 0.8759765625\n",
      "Batch 26: loss = 0.36377274990081787, acc = 0.880859375\n",
      "Batch 27: loss = 0.33493149280548096, acc = 0.896484375\n",
      "Batch 28: loss = 0.3766400218009949, acc = 0.8916015625\n",
      "Batch 29: loss = 0.39865589141845703, acc = 0.87109375\n",
      "Batch 30: loss = 0.39786580204963684, acc = 0.8818359375\n",
      "Batch 31: loss = 0.4191321134567261, acc = 0.87890625\n",
      "Batch 32: loss = 0.3771362900733948, acc = 0.888671875\n",
      "Batch 33: loss = 0.4321295917034149, acc = 0.869140625\n",
      "Batch 34: loss = 0.44614627957344055, acc = 0.8701171875\n",
      "Batch 35: loss = 0.37119874358177185, acc = 0.8876953125\n",
      "Batch 36: loss = 0.3625558614730835, acc = 0.8916015625\n",
      "Batch 37: loss = 0.4166352152824402, acc = 0.8759765625\n",
      "Batch 38: loss = 0.38463300466537476, acc = 0.8876953125\n",
      "Batch 39: loss = 0.4384789764881134, acc = 0.865234375\n",
      "Batch 40: loss = 0.4422711730003357, acc = 0.865234375\n",
      "Batch 41: loss = 0.42275622487068176, acc = 0.8623046875\n",
      "\n",
      "Epoch 68/100\n",
      "Batch 1: loss = 0.40389856696128845, acc = 0.875\n",
      "Batch 2: loss = 0.34884464740753174, acc = 0.8916015625\n",
      "Batch 3: loss = 0.33596324920654297, acc = 0.890625\n",
      "Batch 4: loss = 0.33343011140823364, acc = 0.89453125\n",
      "Batch 5: loss = 0.3113688826560974, acc = 0.91015625\n",
      "Batch 6: loss = 0.33175352215766907, acc = 0.8916015625\n",
      "Batch 7: loss = 0.380588173866272, acc = 0.875\n",
      "Batch 8: loss = 0.37769001722335815, acc = 0.8876953125\n",
      "Batch 9: loss = 0.41812288761138916, acc = 0.88671875\n",
      "Batch 10: loss = 0.37859562039375305, acc = 0.884765625\n",
      "Batch 11: loss = 0.45117005705833435, acc = 0.853515625\n",
      "Batch 12: loss = 0.40310630202293396, acc = 0.8681640625\n",
      "Batch 13: loss = 0.3770373463630676, acc = 0.884765625\n",
      "Batch 14: loss = 0.3736060857772827, acc = 0.888671875\n",
      "Batch 15: loss = 0.3754621148109436, acc = 0.8896484375\n",
      "Batch 16: loss = 0.3674260675907135, acc = 0.880859375\n",
      "Batch 17: loss = 0.3870481252670288, acc = 0.8798828125\n",
      "Batch 18: loss = 0.3949079215526581, acc = 0.8798828125\n",
      "Batch 19: loss = 0.3877286911010742, acc = 0.888671875\n",
      "Batch 20: loss = 0.43545717000961304, acc = 0.8671875\n",
      "Batch 21: loss = 0.40409034490585327, acc = 0.873046875\n",
      "Batch 22: loss = 0.4252426028251648, acc = 0.8642578125\n",
      "Batch 23: loss = 0.3906278610229492, acc = 0.87109375\n",
      "Batch 24: loss = 0.39657285809516907, acc = 0.876953125\n",
      "Batch 25: loss = 0.37181976437568665, acc = 0.8828125\n",
      "Batch 26: loss = 0.3263566792011261, acc = 0.9072265625\n",
      "Batch 27: loss = 0.3288714289665222, acc = 0.9013671875\n",
      "Batch 28: loss = 0.3592889904975891, acc = 0.888671875\n",
      "Batch 29: loss = 0.4100499749183655, acc = 0.8642578125\n",
      "Batch 30: loss = 0.3660435676574707, acc = 0.8896484375\n",
      "Batch 31: loss = 0.42287516593933105, acc = 0.873046875\n",
      "Batch 32: loss = 0.35716331005096436, acc = 0.89453125\n",
      "Batch 33: loss = 0.43347644805908203, acc = 0.869140625\n",
      "Batch 34: loss = 0.4276737570762634, acc = 0.869140625\n",
      "Batch 35: loss = 0.3835427761077881, acc = 0.876953125\n",
      "Batch 36: loss = 0.34475094079971313, acc = 0.8955078125\n",
      "Batch 37: loss = 0.3923206329345703, acc = 0.8798828125\n",
      "Batch 38: loss = 0.37369540333747864, acc = 0.8857421875\n",
      "Batch 39: loss = 0.4124407172203064, acc = 0.861328125\n",
      "Batch 40: loss = 0.4339604079723358, acc = 0.8701171875\n",
      "Batch 41: loss = 0.43159690499305725, acc = 0.8740234375\n",
      "\n",
      "Epoch 69/100\n",
      "Batch 1: loss = 0.3883258104324341, acc = 0.8857421875\n",
      "Batch 2: loss = 0.3171716630458832, acc = 0.9130859375\n",
      "Batch 3: loss = 0.3356701135635376, acc = 0.8857421875\n",
      "Batch 4: loss = 0.33631718158721924, acc = 0.8994140625\n",
      "Batch 5: loss = 0.3317919373512268, acc = 0.900390625\n",
      "Batch 6: loss = 0.33013343811035156, acc = 0.9130859375\n",
      "Batch 7: loss = 0.3722759485244751, acc = 0.87890625\n",
      "Batch 8: loss = 0.3676987290382385, acc = 0.8876953125\n",
      "Batch 9: loss = 0.3820018172264099, acc = 0.869140625\n",
      "Batch 10: loss = 0.37621191143989563, acc = 0.888671875\n",
      "Batch 11: loss = 0.41691771149635315, acc = 0.880859375\n",
      "Batch 12: loss = 0.37739425897598267, acc = 0.87890625\n",
      "Batch 13: loss = 0.38112449645996094, acc = 0.8779296875\n",
      "Batch 14: loss = 0.36962890625, acc = 0.884765625\n",
      "Batch 15: loss = 0.3363158106803894, acc = 0.8935546875\n",
      "Batch 16: loss = 0.3705793023109436, acc = 0.8916015625\n",
      "Batch 17: loss = 0.3685905635356903, acc = 0.89453125\n",
      "Batch 18: loss = 0.44938480854034424, acc = 0.853515625\n",
      "Batch 19: loss = 0.3792824447154999, acc = 0.884765625\n",
      "Batch 20: loss = 0.44200825691223145, acc = 0.859375\n",
      "Batch 21: loss = 0.47025683522224426, acc = 0.8583984375\n",
      "Batch 22: loss = 0.41741496324539185, acc = 0.8720703125\n",
      "Batch 23: loss = 0.43571680784225464, acc = 0.8662109375\n",
      "Batch 24: loss = 0.3796839714050293, acc = 0.8818359375\n",
      "Batch 25: loss = 0.34751462936401367, acc = 0.8974609375\n",
      "Batch 26: loss = 0.3523257374763489, acc = 0.8916015625\n",
      "Batch 27: loss = 0.28265446424484253, acc = 0.904296875\n",
      "Batch 28: loss = 0.32395055890083313, acc = 0.90234375\n",
      "Batch 29: loss = 0.3856988549232483, acc = 0.8828125\n",
      "Batch 30: loss = 0.3534359931945801, acc = 0.8955078125\n",
      "Batch 31: loss = 0.35699498653411865, acc = 0.8896484375\n",
      "Batch 32: loss = 0.3485509157180786, acc = 0.890625\n",
      "Batch 33: loss = 0.42427143454551697, acc = 0.8603515625\n",
      "Batch 34: loss = 0.42442768812179565, acc = 0.86328125\n",
      "Batch 35: loss = 0.35391712188720703, acc = 0.8994140625\n",
      "Batch 36: loss = 0.36695289611816406, acc = 0.8740234375\n",
      "Batch 37: loss = 0.3645670413970947, acc = 0.8955078125\n",
      "Batch 38: loss = 0.3832314610481262, acc = 0.876953125\n",
      "Batch 39: loss = 0.3969740867614746, acc = 0.8701171875\n",
      "Batch 40: loss = 0.41202664375305176, acc = 0.86328125\n",
      "Batch 41: loss = 0.41771697998046875, acc = 0.8701171875\n",
      "\n",
      "Epoch 70/100\n",
      "Batch 1: loss = 0.42273980379104614, acc = 0.875\n",
      "Batch 2: loss = 0.3435373306274414, acc = 0.890625\n",
      "Batch 3: loss = 0.3601705729961395, acc = 0.890625\n",
      "Batch 4: loss = 0.34816697239875793, acc = 0.896484375\n",
      "Batch 5: loss = 0.3164149224758148, acc = 0.9072265625\n",
      "Batch 6: loss = 0.32218441367149353, acc = 0.892578125\n",
      "Batch 7: loss = 0.33661502599716187, acc = 0.8955078125\n",
      "Batch 8: loss = 0.3617861270904541, acc = 0.892578125\n",
      "Batch 9: loss = 0.35920006036758423, acc = 0.88671875\n",
      "Batch 10: loss = 0.36793094873428345, acc = 0.88671875\n",
      "Batch 11: loss = 0.39638757705688477, acc = 0.8701171875\n",
      "Batch 12: loss = 0.4060734510421753, acc = 0.8798828125\n",
      "Batch 13: loss = 0.37301889061927795, acc = 0.884765625\n",
      "Batch 14: loss = 0.32091325521469116, acc = 0.8994140625\n",
      "Batch 15: loss = 0.3465144634246826, acc = 0.9033203125\n",
      "Batch 16: loss = 0.3489704728126526, acc = 0.9052734375\n",
      "Batch 17: loss = 0.3466190695762634, acc = 0.890625\n",
      "Batch 18: loss = 0.4139386713504791, acc = 0.8701171875\n",
      "Batch 19: loss = 0.42901691794395447, acc = 0.8681640625\n",
      "Batch 20: loss = 0.4473474323749542, acc = 0.86328125\n",
      "Batch 21: loss = 0.45024776458740234, acc = 0.8583984375\n",
      "Batch 22: loss = 0.418867826461792, acc = 0.859375\n",
      "Batch 23: loss = 0.4000447392463684, acc = 0.87109375\n",
      "Batch 24: loss = 0.3621760308742523, acc = 0.8896484375\n",
      "Batch 25: loss = 0.34396302700042725, acc = 0.8896484375\n",
      "Batch 26: loss = 0.3329036831855774, acc = 0.896484375\n",
      "Batch 27: loss = 0.3208233714103699, acc = 0.900390625\n",
      "Batch 28: loss = 0.35758501291275024, acc = 0.8876953125\n",
      "Batch 29: loss = 0.3956491947174072, acc = 0.87890625\n",
      "Batch 30: loss = 0.3573155999183655, acc = 0.884765625\n",
      "Batch 31: loss = 0.3715023994445801, acc = 0.8896484375\n",
      "Batch 32: loss = 0.3299238085746765, acc = 0.900390625\n",
      "Batch 33: loss = 0.40170976519584656, acc = 0.8759765625\n",
      "Batch 34: loss = 0.43205583095550537, acc = 0.875\n",
      "Batch 35: loss = 0.3680756688117981, acc = 0.892578125\n",
      "Batch 36: loss = 0.3144643008708954, acc = 0.9033203125\n",
      "Batch 37: loss = 0.40025395154953003, acc = 0.876953125\n",
      "Batch 38: loss = 0.3585151731967926, acc = 0.8759765625\n",
      "Batch 39: loss = 0.4045049846172333, acc = 0.8798828125\n",
      "Batch 40: loss = 0.37979838252067566, acc = 0.8916015625\n",
      "Batch 41: loss = 0.37652868032455444, acc = 0.88671875\n",
      "Saved checkpoint to weights_eminem_input.txt.70.h5\n",
      "\n",
      "Epoch 71/100\n",
      "Batch 1: loss = 0.3569355010986328, acc = 0.8994140625\n",
      "Batch 2: loss = 0.33690762519836426, acc = 0.89453125\n",
      "Batch 3: loss = 0.33760401606559753, acc = 0.890625\n",
      "Batch 4: loss = 0.3480778932571411, acc = 0.8994140625\n",
      "Batch 5: loss = 0.32195979356765747, acc = 0.9111328125\n",
      "Batch 6: loss = 0.3383038640022278, acc = 0.896484375\n",
      "Batch 7: loss = 0.306535542011261, acc = 0.90625\n",
      "Batch 8: loss = 0.3558882474899292, acc = 0.8935546875\n",
      "Batch 9: loss = 0.3648985028266907, acc = 0.900390625\n",
      "Batch 10: loss = 0.3688662648200989, acc = 0.880859375\n",
      "Batch 11: loss = 0.4034944772720337, acc = 0.8720703125\n",
      "Batch 12: loss = 0.3544214367866516, acc = 0.892578125\n",
      "Batch 13: loss = 0.3820250630378723, acc = 0.87890625\n",
      "Batch 14: loss = 0.3883867561817169, acc = 0.87890625\n",
      "Batch 15: loss = 0.3526657819747925, acc = 0.8916015625\n",
      "Batch 16: loss = 0.3536967635154724, acc = 0.892578125\n",
      "Batch 17: loss = 0.34300968050956726, acc = 0.8837890625\n",
      "Batch 18: loss = 0.38456541299819946, acc = 0.88671875\n",
      "Batch 19: loss = 0.3878861665725708, acc = 0.8857421875\n",
      "Batch 20: loss = 0.39688438177108765, acc = 0.88671875\n",
      "Batch 21: loss = 0.4056854546070099, acc = 0.869140625\n",
      "Batch 22: loss = 0.3898196816444397, acc = 0.87109375\n",
      "Batch 23: loss = 0.3816281259059906, acc = 0.8837890625\n",
      "Batch 24: loss = 0.3798995018005371, acc = 0.873046875\n",
      "Batch 25: loss = 0.3383767604827881, acc = 0.8916015625\n",
      "Batch 26: loss = 0.34243422746658325, acc = 0.8916015625\n",
      "Batch 27: loss = 0.2910645008087158, acc = 0.9091796875\n",
      "Batch 28: loss = 0.3197634220123291, acc = 0.91015625\n",
      "Batch 29: loss = 0.3406677842140198, acc = 0.8955078125\n",
      "Batch 30: loss = 0.3570409417152405, acc = 0.8916015625\n",
      "Batch 31: loss = 0.3828204870223999, acc = 0.888671875\n",
      "Batch 32: loss = 0.3409201502799988, acc = 0.8876953125\n",
      "Batch 33: loss = 0.39097878336906433, acc = 0.8935546875\n",
      "Batch 34: loss = 0.4079316258430481, acc = 0.8837890625\n",
      "Batch 35: loss = 0.4018358886241913, acc = 0.8857421875\n",
      "Batch 36: loss = 0.3184264302253723, acc = 0.8916015625\n",
      "Batch 37: loss = 0.35996246337890625, acc = 0.87890625\n",
      "Batch 38: loss = 0.3291284441947937, acc = 0.8974609375\n",
      "Batch 39: loss = 0.4028632342815399, acc = 0.876953125\n",
      "Batch 40: loss = 0.39657139778137207, acc = 0.875\n",
      "Batch 41: loss = 0.3795344829559326, acc = 0.873046875\n",
      "\n",
      "Epoch 72/100\n",
      "Batch 1: loss = 0.3755309581756592, acc = 0.8896484375\n",
      "Batch 2: loss = 0.28468388319015503, acc = 0.9130859375\n",
      "Batch 3: loss = 0.3279954791069031, acc = 0.904296875\n",
      "Batch 4: loss = 0.33019495010375977, acc = 0.8994140625\n",
      "Batch 5: loss = 0.3012588918209076, acc = 0.9033203125\n",
      "Batch 6: loss = 0.31432634592056274, acc = 0.8984375\n",
      "Batch 7: loss = 0.33097440004348755, acc = 0.89453125\n",
      "Batch 8: loss = 0.34154894948005676, acc = 0.892578125\n",
      "Batch 9: loss = 0.3802717924118042, acc = 0.890625\n",
      "Batch 10: loss = 0.378068745136261, acc = 0.880859375\n",
      "Batch 11: loss = 0.38857555389404297, acc = 0.884765625\n",
      "Batch 12: loss = 0.3785395622253418, acc = 0.8759765625\n",
      "Batch 13: loss = 0.3888799846172333, acc = 0.888671875\n",
      "Batch 14: loss = 0.3372703194618225, acc = 0.8955078125\n",
      "Batch 15: loss = 0.34304946660995483, acc = 0.8984375\n",
      "Batch 16: loss = 0.3570517599582672, acc = 0.896484375\n",
      "Batch 17: loss = 0.35501861572265625, acc = 0.8955078125\n",
      "Batch 18: loss = 0.3803711235523224, acc = 0.8779296875\n",
      "Batch 19: loss = 0.38926100730895996, acc = 0.8818359375\n",
      "Batch 20: loss = 0.3664886951446533, acc = 0.896484375\n",
      "Batch 21: loss = 0.35036003589630127, acc = 0.8916015625\n",
      "Batch 22: loss = 0.38762781023979187, acc = 0.8896484375\n",
      "Batch 23: loss = 0.377410888671875, acc = 0.8720703125\n",
      "Batch 24: loss = 0.32956719398498535, acc = 0.892578125\n",
      "Batch 25: loss = 0.3269909918308258, acc = 0.9033203125\n",
      "Batch 26: loss = 0.31611889600753784, acc = 0.9033203125\n",
      "Batch 27: loss = 0.27135616540908813, acc = 0.921875\n",
      "Batch 28: loss = 0.35156115889549255, acc = 0.9013671875\n",
      "Batch 29: loss = 0.3734859824180603, acc = 0.8779296875\n",
      "Batch 30: loss = 0.3496156334877014, acc = 0.8935546875\n",
      "Batch 31: loss = 0.33051273226737976, acc = 0.908203125\n",
      "Batch 32: loss = 0.29350411891937256, acc = 0.9208984375\n",
      "Batch 33: loss = 0.3868088722229004, acc = 0.8798828125\n",
      "Batch 34: loss = 0.4207211136817932, acc = 0.8818359375\n",
      "Batch 35: loss = 0.3698411285877228, acc = 0.88671875\n",
      "Batch 36: loss = 0.2981393039226532, acc = 0.9189453125\n",
      "Batch 37: loss = 0.36142653226852417, acc = 0.890625\n",
      "Batch 38: loss = 0.327974796295166, acc = 0.896484375\n",
      "Batch 39: loss = 0.4164647161960602, acc = 0.8544921875\n",
      "Batch 40: loss = 0.3754204511642456, acc = 0.892578125\n",
      "Batch 41: loss = 0.39049461483955383, acc = 0.8720703125\n",
      "\n",
      "Epoch 73/100\n",
      "Batch 1: loss = 0.36820486187934875, acc = 0.8935546875\n",
      "Batch 2: loss = 0.30515265464782715, acc = 0.912109375\n",
      "Batch 3: loss = 0.31419837474823, acc = 0.904296875\n",
      "Batch 4: loss = 0.3144836127758026, acc = 0.90625\n",
      "Batch 5: loss = 0.3096150755882263, acc = 0.9140625\n",
      "Batch 6: loss = 0.33424708247184753, acc = 0.8896484375\n",
      "Batch 7: loss = 0.32254502177238464, acc = 0.9033203125\n",
      "Batch 8: loss = 0.3009108603000641, acc = 0.9111328125\n",
      "Batch 9: loss = 0.3414838910102844, acc = 0.9013671875\n",
      "Batch 10: loss = 0.36038297414779663, acc = 0.888671875\n",
      "Batch 11: loss = 0.4081961512565613, acc = 0.8701171875\n",
      "Batch 12: loss = 0.3606857359409332, acc = 0.892578125\n",
      "Batch 13: loss = 0.3829757571220398, acc = 0.87890625\n",
      "Batch 14: loss = 0.3504980802536011, acc = 0.892578125\n",
      "Batch 15: loss = 0.3184381127357483, acc = 0.9111328125\n",
      "Batch 16: loss = 0.3340776562690735, acc = 0.8935546875\n",
      "Batch 17: loss = 0.33718544244766235, acc = 0.9033203125\n",
      "Batch 18: loss = 0.3321799337863922, acc = 0.9072265625\n",
      "Batch 19: loss = 0.38597095012664795, acc = 0.8798828125\n",
      "Batch 20: loss = 0.3636796176433563, acc = 0.8876953125\n",
      "Batch 21: loss = 0.40537869930267334, acc = 0.865234375\n",
      "Batch 22: loss = 0.40428584814071655, acc = 0.8662109375\n",
      "Batch 23: loss = 0.38996729254722595, acc = 0.87109375\n",
      "Batch 24: loss = 0.33181852102279663, acc = 0.900390625\n",
      "Batch 25: loss = 0.32340872287750244, acc = 0.904296875\n",
      "Batch 26: loss = 0.30145299434661865, acc = 0.9091796875\n",
      "Batch 27: loss = 0.2720752954483032, acc = 0.9228515625\n",
      "Batch 28: loss = 0.3293772339820862, acc = 0.904296875\n",
      "Batch 29: loss = 0.3057332932949066, acc = 0.9052734375\n",
      "Batch 30: loss = 0.3284528851509094, acc = 0.89453125\n",
      "Batch 31: loss = 0.36200377345085144, acc = 0.8984375\n",
      "Batch 32: loss = 0.3186553418636322, acc = 0.9091796875\n",
      "Batch 33: loss = 0.35209083557128906, acc = 0.8876953125\n",
      "Batch 34: loss = 0.416954904794693, acc = 0.8642578125\n",
      "Batch 35: loss = 0.34662848711013794, acc = 0.8974609375\n",
      "Batch 36: loss = 0.2873218059539795, acc = 0.9052734375\n",
      "Batch 37: loss = 0.3527100682258606, acc = 0.880859375\n",
      "Batch 38: loss = 0.3300132155418396, acc = 0.904296875\n",
      "Batch 39: loss = 0.3409627676010132, acc = 0.8916015625\n",
      "Batch 40: loss = 0.3425486087799072, acc = 0.8955078125\n",
      "Batch 41: loss = 0.37314268946647644, acc = 0.87890625\n",
      "\n",
      "Epoch 74/100\n",
      "Batch 1: loss = 0.3377912640571594, acc = 0.9091796875\n",
      "Batch 2: loss = 0.32359254360198975, acc = 0.8984375\n",
      "Batch 3: loss = 0.3253997564315796, acc = 0.91015625\n",
      "Batch 4: loss = 0.3066103160381317, acc = 0.9052734375\n",
      "Batch 5: loss = 0.2704553008079529, acc = 0.9150390625\n",
      "Batch 6: loss = 0.3013511300086975, acc = 0.9033203125\n",
      "Batch 7: loss = 0.24845337867736816, acc = 0.9267578125\n",
      "Batch 8: loss = 0.305919885635376, acc = 0.912109375\n",
      "Batch 9: loss = 0.3713529109954834, acc = 0.8935546875\n",
      "Batch 10: loss = 0.3501468896865845, acc = 0.8974609375\n",
      "Batch 11: loss = 0.4037039279937744, acc = 0.8681640625\n",
      "Batch 12: loss = 0.36280888319015503, acc = 0.8857421875\n",
      "Batch 13: loss = 0.337104856967926, acc = 0.900390625\n",
      "Batch 14: loss = 0.3418624699115753, acc = 0.892578125\n",
      "Batch 15: loss = 0.3198884129524231, acc = 0.91015625\n",
      "Batch 16: loss = 0.3083820939064026, acc = 0.9130859375\n",
      "Batch 17: loss = 0.33249589800834656, acc = 0.8974609375\n",
      "Batch 18: loss = 0.32443785667419434, acc = 0.90625\n",
      "Batch 19: loss = 0.3662334680557251, acc = 0.8876953125\n",
      "Batch 20: loss = 0.3666028678417206, acc = 0.8876953125\n",
      "Batch 21: loss = 0.4027196168899536, acc = 0.8798828125\n",
      "Batch 22: loss = 0.36975976824760437, acc = 0.884765625\n",
      "Batch 23: loss = 0.31229400634765625, acc = 0.8984375\n",
      "Batch 24: loss = 0.3136019706726074, acc = 0.8955078125\n",
      "Batch 25: loss = 0.3297499418258667, acc = 0.90234375\n",
      "Batch 26: loss = 0.30853956937789917, acc = 0.904296875\n",
      "Batch 27: loss = 0.2621985673904419, acc = 0.9208984375\n",
      "Batch 28: loss = 0.333591103553772, acc = 0.8984375\n",
      "Batch 29: loss = 0.3413134515285492, acc = 0.8974609375\n",
      "Batch 30: loss = 0.333249568939209, acc = 0.8994140625\n",
      "Batch 31: loss = 0.33775848150253296, acc = 0.90625\n",
      "Batch 32: loss = 0.3063616156578064, acc = 0.9091796875\n",
      "Batch 33: loss = 0.35942980647087097, acc = 0.880859375\n",
      "Batch 34: loss = 0.38125327229499817, acc = 0.880859375\n",
      "Batch 35: loss = 0.3405829071998596, acc = 0.9052734375\n",
      "Batch 36: loss = 0.29251188039779663, acc = 0.9033203125\n",
      "Batch 37: loss = 0.3244989812374115, acc = 0.9052734375\n",
      "Batch 38: loss = 0.3029611110687256, acc = 0.9150390625\n",
      "Batch 39: loss = 0.3057001233100891, acc = 0.90625\n",
      "Batch 40: loss = 0.3721798360347748, acc = 0.88671875\n",
      "Batch 41: loss = 0.3794093728065491, acc = 0.8857421875\n",
      "\n",
      "Epoch 75/100\n",
      "Batch 1: loss = 0.3351723551750183, acc = 0.91015625\n",
      "Batch 2: loss = 0.28693363070487976, acc = 0.9208984375\n",
      "Batch 3: loss = 0.31049293279647827, acc = 0.921875\n",
      "Batch 4: loss = 0.2947179079055786, acc = 0.9140625\n",
      "Batch 5: loss = 0.28013700246810913, acc = 0.919921875\n",
      "Batch 6: loss = 0.26225462555885315, acc = 0.9296875\n",
      "Batch 7: loss = 0.2825177311897278, acc = 0.923828125\n",
      "Batch 8: loss = 0.29564112424850464, acc = 0.9169921875\n",
      "Batch 9: loss = 0.34772127866744995, acc = 0.8896484375\n",
      "Batch 10: loss = 0.35108208656311035, acc = 0.896484375\n",
      "Batch 11: loss = 0.36174869537353516, acc = 0.892578125\n",
      "Batch 12: loss = 0.35345789790153503, acc = 0.8857421875\n",
      "Batch 13: loss = 0.3311690092086792, acc = 0.888671875\n",
      "Batch 14: loss = 0.3311549127101898, acc = 0.904296875\n",
      "Batch 15: loss = 0.326524019241333, acc = 0.904296875\n",
      "Batch 16: loss = 0.31853049993515015, acc = 0.9052734375\n",
      "Batch 17: loss = 0.31575217843055725, acc = 0.904296875\n",
      "Batch 18: loss = 0.34158772230148315, acc = 0.888671875\n",
      "Batch 19: loss = 0.34842658042907715, acc = 0.884765625\n",
      "Batch 20: loss = 0.3356817066669464, acc = 0.9052734375\n",
      "Batch 21: loss = 0.37547269463539124, acc = 0.892578125\n",
      "Batch 22: loss = 0.3096035122871399, acc = 0.9072265625\n",
      "Batch 23: loss = 0.36659279465675354, acc = 0.8935546875\n",
      "Batch 24: loss = 0.2907053530216217, acc = 0.9140625\n",
      "Batch 25: loss = 0.31228363513946533, acc = 0.9013671875\n",
      "Batch 26: loss = 0.2864407002925873, acc = 0.9150390625\n",
      "Batch 27: loss = 0.25676998496055603, acc = 0.921875\n",
      "Batch 28: loss = 0.3030368387699127, acc = 0.9111328125\n",
      "Batch 29: loss = 0.3389264643192291, acc = 0.888671875\n",
      "Batch 30: loss = 0.3222624659538269, acc = 0.908203125\n",
      "Batch 31: loss = 0.36958998441696167, acc = 0.8828125\n",
      "Batch 32: loss = 0.2964484393596649, acc = 0.9052734375\n",
      "Batch 33: loss = 0.35040414333343506, acc = 0.892578125\n",
      "Batch 34: loss = 0.38205409049987793, acc = 0.8798828125\n",
      "Batch 35: loss = 0.354126513004303, acc = 0.8896484375\n",
      "Batch 36: loss = 0.31229281425476074, acc = 0.8984375\n",
      "Batch 37: loss = 0.3182472288608551, acc = 0.9052734375\n",
      "Batch 38: loss = 0.31657674908638, acc = 0.904296875\n",
      "Batch 39: loss = 0.33351847529411316, acc = 0.8896484375\n",
      "Batch 40: loss = 0.35023248195648193, acc = 0.8935546875\n",
      "Batch 41: loss = 0.37720224261283875, acc = 0.8759765625\n",
      "\n",
      "Epoch 76/100\n",
      "Batch 1: loss = 0.33901160955429077, acc = 0.896484375\n",
      "Batch 2: loss = 0.3102889657020569, acc = 0.90625\n",
      "Batch 3: loss = 0.2792888283729553, acc = 0.92578125\n",
      "Batch 4: loss = 0.2921609878540039, acc = 0.9189453125\n",
      "Batch 5: loss = 0.28079500794410706, acc = 0.919921875\n",
      "Batch 6: loss = 0.2968101501464844, acc = 0.9267578125\n",
      "Batch 7: loss = 0.29235708713531494, acc = 0.912109375\n",
      "Batch 8: loss = 0.29702630639076233, acc = 0.9228515625\n",
      "Batch 9: loss = 0.3343901038169861, acc = 0.892578125\n",
      "Batch 10: loss = 0.31339794397354126, acc = 0.912109375\n",
      "Batch 11: loss = 0.37828585505485535, acc = 0.87109375\n",
      "Batch 12: loss = 0.37160569429397583, acc = 0.8837890625\n",
      "Batch 13: loss = 0.32306838035583496, acc = 0.8955078125\n",
      "Batch 14: loss = 0.31079065799713135, acc = 0.90625\n",
      "Batch 15: loss = 0.2986694574356079, acc = 0.90234375\n",
      "Batch 16: loss = 0.27471280097961426, acc = 0.916015625\n",
      "Batch 17: loss = 0.2715720534324646, acc = 0.9072265625\n",
      "Batch 18: loss = 0.3495434820652008, acc = 0.890625\n",
      "Batch 19: loss = 0.3041638731956482, acc = 0.9033203125\n",
      "Batch 20: loss = 0.3676195442676544, acc = 0.8857421875\n",
      "Batch 21: loss = 0.37276196479797363, acc = 0.8837890625\n",
      "Batch 22: loss = 0.3453197777271271, acc = 0.884765625\n",
      "Batch 23: loss = 0.3545605540275574, acc = 0.884765625\n",
      "Batch 24: loss = 0.3216787874698639, acc = 0.9111328125\n",
      "Batch 25: loss = 0.2931618094444275, acc = 0.9130859375\n",
      "Batch 26: loss = 0.33404266834259033, acc = 0.89453125\n",
      "Batch 27: loss = 0.24721775949001312, acc = 0.9208984375\n",
      "Batch 28: loss = 0.2928556799888611, acc = 0.91015625\n",
      "Batch 29: loss = 0.2921730577945709, acc = 0.908203125\n",
      "Batch 30: loss = 0.3105103373527527, acc = 0.9091796875\n",
      "Batch 31: loss = 0.3434683084487915, acc = 0.9072265625\n",
      "Batch 32: loss = 0.31644976139068604, acc = 0.908203125\n",
      "Batch 33: loss = 0.3444451689720154, acc = 0.8935546875\n",
      "Batch 34: loss = 0.3678889572620392, acc = 0.8916015625\n",
      "Batch 35: loss = 0.34222325682640076, acc = 0.88671875\n",
      "Batch 36: loss = 0.26313626766204834, acc = 0.9150390625\n",
      "Batch 37: loss = 0.3486487865447998, acc = 0.8857421875\n",
      "Batch 38: loss = 0.3201600909233093, acc = 0.8984375\n",
      "Batch 39: loss = 0.3238651156425476, acc = 0.9052734375\n",
      "Batch 40: loss = 0.3901641368865967, acc = 0.8837890625\n",
      "Batch 41: loss = 0.3397383689880371, acc = 0.8974609375\n",
      "\n",
      "Epoch 77/100\n",
      "Batch 1: loss = 0.3485316038131714, acc = 0.89453125\n",
      "Batch 2: loss = 0.27388662099838257, acc = 0.9189453125\n",
      "Batch 3: loss = 0.26633530855178833, acc = 0.919921875\n",
      "Batch 4: loss = 0.29006463289260864, acc = 0.912109375\n",
      "Batch 5: loss = 0.3155131936073303, acc = 0.908203125\n",
      "Batch 6: loss = 0.24383190274238586, acc = 0.9267578125\n",
      "Batch 7: loss = 0.28318560123443604, acc = 0.9072265625\n",
      "Batch 8: loss = 0.28978395462036133, acc = 0.9033203125\n",
      "Batch 9: loss = 0.3090727925300598, acc = 0.9111328125\n",
      "Batch 10: loss = 0.3042528033256531, acc = 0.8994140625\n",
      "Batch 11: loss = 0.371843159198761, acc = 0.8916015625\n",
      "Batch 12: loss = 0.31837916374206543, acc = 0.9052734375\n",
      "Batch 13: loss = 0.32859453558921814, acc = 0.8916015625\n",
      "Batch 14: loss = 0.3031656742095947, acc = 0.912109375\n",
      "Batch 15: loss = 0.2855222225189209, acc = 0.9130859375\n",
      "Batch 16: loss = 0.33241885900497437, acc = 0.900390625\n",
      "Batch 17: loss = 0.2967257499694824, acc = 0.904296875\n",
      "Batch 18: loss = 0.3198208212852478, acc = 0.8974609375\n",
      "Batch 19: loss = 0.28902262449264526, acc = 0.9150390625\n",
      "Batch 20: loss = 0.353463351726532, acc = 0.896484375\n",
      "Batch 21: loss = 0.33579182624816895, acc = 0.89453125\n",
      "Batch 22: loss = 0.31509727239608765, acc = 0.9091796875\n",
      "Batch 23: loss = 0.3446497619152069, acc = 0.89453125\n",
      "Batch 24: loss = 0.3229500353336334, acc = 0.88671875\n",
      "Batch 25: loss = 0.2921043634414673, acc = 0.90234375\n",
      "Batch 26: loss = 0.3049834668636322, acc = 0.9013671875\n",
      "Batch 27: loss = 0.2340255081653595, acc = 0.9169921875\n",
      "Batch 28: loss = 0.3010910749435425, acc = 0.912109375\n",
      "Batch 29: loss = 0.29920926690101624, acc = 0.900390625\n",
      "Batch 30: loss = 0.2836243510246277, acc = 0.9130859375\n",
      "Batch 31: loss = 0.32523298263549805, acc = 0.904296875\n",
      "Batch 32: loss = 0.2914178967475891, acc = 0.91796875\n",
      "Batch 33: loss = 0.34187552332878113, acc = 0.904296875\n",
      "Batch 34: loss = 0.34297746419906616, acc = 0.8994140625\n",
      "Batch 35: loss = 0.3401339054107666, acc = 0.8935546875\n",
      "Batch 36: loss = 0.27625447511672974, acc = 0.9150390625\n",
      "Batch 37: loss = 0.3205205798149109, acc = 0.900390625\n",
      "Batch 38: loss = 0.30766093730926514, acc = 0.9150390625\n",
      "Batch 39: loss = 0.30426597595214844, acc = 0.8994140625\n",
      "Batch 40: loss = 0.3423500061035156, acc = 0.8916015625\n",
      "Batch 41: loss = 0.321322500705719, acc = 0.90234375\n",
      "\n",
      "Epoch 78/100\n",
      "Batch 1: loss = 0.28454285860061646, acc = 0.916015625\n",
      "Batch 2: loss = 0.27168020606040955, acc = 0.9169921875\n",
      "Batch 3: loss = 0.2694751024246216, acc = 0.9287109375\n",
      "Batch 4: loss = 0.2739329934120178, acc = 0.9130859375\n",
      "Batch 5: loss = 0.26945745944976807, acc = 0.9140625\n",
      "Batch 6: loss = 0.27504873275756836, acc = 0.91796875\n",
      "Batch 7: loss = 0.29546356201171875, acc = 0.9130859375\n",
      "Batch 8: loss = 0.28804588317871094, acc = 0.91796875\n",
      "Batch 9: loss = 0.3215397596359253, acc = 0.90625\n",
      "Batch 10: loss = 0.321492075920105, acc = 0.8994140625\n",
      "Batch 11: loss = 0.3476914167404175, acc = 0.8955078125\n",
      "Batch 12: loss = 0.31298667192459106, acc = 0.896484375\n",
      "Batch 13: loss = 0.30305466055870056, acc = 0.8994140625\n",
      "Batch 14: loss = 0.2849389910697937, acc = 0.921875\n",
      "Batch 15: loss = 0.3112892508506775, acc = 0.90625\n",
      "Batch 16: loss = 0.3014923632144928, acc = 0.908203125\n",
      "Batch 17: loss = 0.3482073247432709, acc = 0.875\n",
      "Batch 18: loss = 0.3305802643299103, acc = 0.9072265625\n",
      "Batch 19: loss = 0.33532246947288513, acc = 0.8955078125\n",
      "Batch 20: loss = 0.3776339292526245, acc = 0.884765625\n",
      "Batch 21: loss = 0.3824923634529114, acc = 0.888671875\n",
      "Batch 22: loss = 0.3260776996612549, acc = 0.9072265625\n",
      "Batch 23: loss = 0.33739417791366577, acc = 0.904296875\n",
      "Batch 24: loss = 0.33021020889282227, acc = 0.892578125\n",
      "Batch 25: loss = 0.28965044021606445, acc = 0.9111328125\n",
      "Batch 26: loss = 0.2790837287902832, acc = 0.9228515625\n",
      "Batch 27: loss = 0.22050347924232483, acc = 0.931640625\n",
      "Batch 28: loss = 0.29129064083099365, acc = 0.92578125\n",
      "Batch 29: loss = 0.2957179546356201, acc = 0.90625\n",
      "Batch 30: loss = 0.3140449821949005, acc = 0.9052734375\n",
      "Batch 31: loss = 0.294975221157074, acc = 0.92578125\n",
      "Batch 32: loss = 0.28719496726989746, acc = 0.9130859375\n",
      "Batch 33: loss = 0.2911376357078552, acc = 0.9150390625\n",
      "Batch 34: loss = 0.3496669828891754, acc = 0.892578125\n",
      "Batch 35: loss = 0.3435157537460327, acc = 0.896484375\n",
      "Batch 36: loss = 0.2579731047153473, acc = 0.9296875\n",
      "Batch 37: loss = 0.2991439402103424, acc = 0.9052734375\n",
      "Batch 38: loss = 0.276754766702652, acc = 0.9091796875\n",
      "Batch 39: loss = 0.3167402148246765, acc = 0.8974609375\n",
      "Batch 40: loss = 0.33791202306747437, acc = 0.8916015625\n",
      "Batch 41: loss = 0.3219207525253296, acc = 0.89453125\n",
      "\n",
      "Epoch 79/100\n",
      "Batch 1: loss = 0.31374743580818176, acc = 0.9150390625\n",
      "Batch 2: loss = 0.30750027298927307, acc = 0.91015625\n",
      "Batch 3: loss = 0.27477341890335083, acc = 0.9111328125\n",
      "Batch 4: loss = 0.2875823974609375, acc = 0.900390625\n",
      "Batch 5: loss = 0.2514537572860718, acc = 0.9306640625\n",
      "Batch 6: loss = 0.27220815420150757, acc = 0.9189453125\n",
      "Batch 7: loss = 0.3027416467666626, acc = 0.9072265625\n",
      "Batch 8: loss = 0.25357675552368164, acc = 0.9169921875\n",
      "Batch 9: loss = 0.2817123830318451, acc = 0.9228515625\n",
      "Batch 10: loss = 0.3012523055076599, acc = 0.9091796875\n",
      "Batch 11: loss = 0.3257761597633362, acc = 0.89453125\n",
      "Batch 12: loss = 0.3105635941028595, acc = 0.904296875\n",
      "Batch 13: loss = 0.3504541516304016, acc = 0.896484375\n",
      "Batch 14: loss = 0.30386239290237427, acc = 0.8994140625\n",
      "Batch 15: loss = 0.28658542037010193, acc = 0.9228515625\n",
      "Batch 16: loss = 0.2870328426361084, acc = 0.9228515625\n",
      "Batch 17: loss = 0.284514844417572, acc = 0.91015625\n",
      "Batch 18: loss = 0.31411102414131165, acc = 0.9033203125\n",
      "Batch 19: loss = 0.34221386909484863, acc = 0.8994140625\n",
      "Batch 20: loss = 0.3525329828262329, acc = 0.89453125\n",
      "Batch 21: loss = 0.376993864774704, acc = 0.888671875\n",
      "Batch 22: loss = 0.31848663091659546, acc = 0.896484375\n",
      "Batch 23: loss = 0.31235724687576294, acc = 0.8984375\n",
      "Batch 24: loss = 0.28123655915260315, acc = 0.90234375\n",
      "Batch 25: loss = 0.3050270974636078, acc = 0.8994140625\n",
      "Batch 26: loss = 0.27060800790786743, acc = 0.9208984375\n",
      "Batch 27: loss = 0.24726879596710205, acc = 0.9267578125\n",
      "Batch 28: loss = 0.28491824865341187, acc = 0.9130859375\n",
      "Batch 29: loss = 0.2930253744125366, acc = 0.900390625\n",
      "Batch 30: loss = 0.31197166442871094, acc = 0.9091796875\n",
      "Batch 31: loss = 0.3203965127468109, acc = 0.9111328125\n",
      "Batch 32: loss = 0.29518216848373413, acc = 0.9111328125\n",
      "Batch 33: loss = 0.3650727868080139, acc = 0.8876953125\n",
      "Batch 34: loss = 0.35322797298431396, acc = 0.9033203125\n",
      "Batch 35: loss = 0.30147087574005127, acc = 0.9072265625\n",
      "Batch 36: loss = 0.2382756918668747, acc = 0.9248046875\n",
      "Batch 37: loss = 0.28713998198509216, acc = 0.912109375\n",
      "Batch 38: loss = 0.2816768288612366, acc = 0.9189453125\n",
      "Batch 39: loss = 0.3086642622947693, acc = 0.9111328125\n",
      "Batch 40: loss = 0.3234947919845581, acc = 0.908203125\n",
      "Batch 41: loss = 0.3030962347984314, acc = 0.9072265625\n",
      "\n",
      "Epoch 80/100\n",
      "Batch 1: loss = 0.3028804659843445, acc = 0.9150390625\n",
      "Batch 2: loss = 0.28096193075180054, acc = 0.9228515625\n",
      "Batch 3: loss = 0.24181969463825226, acc = 0.939453125\n",
      "Batch 4: loss = 0.23784779012203217, acc = 0.931640625\n",
      "Batch 5: loss = 0.28490933775901794, acc = 0.9052734375\n",
      "Batch 6: loss = 0.2817133665084839, acc = 0.91015625\n",
      "Batch 7: loss = 0.2504972815513611, acc = 0.9248046875\n",
      "Batch 8: loss = 0.26655974984169006, acc = 0.9150390625\n",
      "Batch 9: loss = 0.28649574518203735, acc = 0.9130859375\n",
      "Batch 10: loss = 0.30218711495399475, acc = 0.90625\n",
      "Batch 11: loss = 0.30086928606033325, acc = 0.9111328125\n",
      "Batch 12: loss = 0.3184214234352112, acc = 0.904296875\n",
      "Batch 13: loss = 0.28041401505470276, acc = 0.919921875\n",
      "Batch 14: loss = 0.2898048162460327, acc = 0.908203125\n",
      "Batch 15: loss = 0.2676280736923218, acc = 0.9208984375\n",
      "Batch 16: loss = 0.25675612688064575, acc = 0.919921875\n",
      "Batch 17: loss = 0.3043312728404999, acc = 0.9052734375\n",
      "Batch 18: loss = 0.3009740114212036, acc = 0.9072265625\n",
      "Batch 19: loss = 0.3144717514514923, acc = 0.90625\n",
      "Batch 20: loss = 0.32299697399139404, acc = 0.8984375\n",
      "Batch 21: loss = 0.3243386745452881, acc = 0.89453125\n",
      "Batch 22: loss = 0.30339810252189636, acc = 0.90234375\n",
      "Batch 23: loss = 0.33950692415237427, acc = 0.890625\n",
      "Batch 24: loss = 0.28138309717178345, acc = 0.919921875\n",
      "Batch 25: loss = 0.27294179797172546, acc = 0.908203125\n",
      "Batch 26: loss = 0.2664572596549988, acc = 0.921875\n",
      "Batch 27: loss = 0.2576049566268921, acc = 0.9169921875\n",
      "Batch 28: loss = 0.2754896283149719, acc = 0.919921875\n",
      "Batch 29: loss = 0.25955381989479065, acc = 0.9140625\n",
      "Batch 30: loss = 0.2981601655483246, acc = 0.916015625\n",
      "Batch 31: loss = 0.34090790152549744, acc = 0.8955078125\n",
      "Batch 32: loss = 0.2957470715045929, acc = 0.91015625\n",
      "Batch 33: loss = 0.3820837736129761, acc = 0.8857421875\n",
      "Batch 34: loss = 0.3698039650917053, acc = 0.8876953125\n",
      "Batch 35: loss = 0.3542673587799072, acc = 0.892578125\n",
      "Batch 36: loss = 0.2502950429916382, acc = 0.9248046875\n",
      "Batch 37: loss = 0.3045506179332733, acc = 0.90234375\n",
      "Batch 38: loss = 0.28960520029067993, acc = 0.9130859375\n",
      "Batch 39: loss = 0.29637905955314636, acc = 0.9091796875\n",
      "Batch 40: loss = 0.3042694926261902, acc = 0.90625\n",
      "Batch 41: loss = 0.2842106819152832, acc = 0.931640625\n",
      "Saved checkpoint to weights_eminem_input.txt.80.h5\n",
      "\n",
      "Epoch 81/100\n",
      "Batch 1: loss = 0.30659565329551697, acc = 0.91015625\n",
      "Batch 2: loss = 0.2793375551700592, acc = 0.921875\n",
      "Batch 3: loss = 0.2539907693862915, acc = 0.9326171875\n",
      "Batch 4: loss = 0.2906895875930786, acc = 0.904296875\n",
      "Batch 5: loss = 0.2457091510295868, acc = 0.9296875\n",
      "Batch 6: loss = 0.24837899208068848, acc = 0.916015625\n",
      "Batch 7: loss = 0.3029889464378357, acc = 0.912109375\n",
      "Batch 8: loss = 0.2925848066806793, acc = 0.9091796875\n",
      "Batch 9: loss = 0.30960768461227417, acc = 0.9091796875\n",
      "Batch 10: loss = 0.30269670486450195, acc = 0.9091796875\n",
      "Batch 11: loss = 0.31693118810653687, acc = 0.9111328125\n",
      "Batch 12: loss = 0.2724798619747162, acc = 0.919921875\n",
      "Batch 13: loss = 0.3154327869415283, acc = 0.908203125\n",
      "Batch 14: loss = 0.29305750131607056, acc = 0.9150390625\n",
      "Batch 15: loss = 0.2756175696849823, acc = 0.912109375\n",
      "Batch 16: loss = 0.25502562522888184, acc = 0.923828125\n",
      "Batch 17: loss = 0.3191543221473694, acc = 0.90625\n",
      "Batch 18: loss = 0.2891618609428406, acc = 0.9111328125\n",
      "Batch 19: loss = 0.26968035101890564, acc = 0.9169921875\n",
      "Batch 20: loss = 0.28831976652145386, acc = 0.9208984375\n",
      "Batch 21: loss = 0.3224475085735321, acc = 0.9130859375\n",
      "Batch 22: loss = 0.3114304542541504, acc = 0.9130859375\n",
      "Batch 23: loss = 0.33424025774002075, acc = 0.8935546875\n",
      "Batch 24: loss = 0.2839982807636261, acc = 0.91015625\n",
      "Batch 25: loss = 0.2656405568122864, acc = 0.9228515625\n",
      "Batch 26: loss = 0.2623663544654846, acc = 0.919921875\n",
      "Batch 27: loss = 0.23015949130058289, acc = 0.921875\n",
      "Batch 28: loss = 0.27202850580215454, acc = 0.9248046875\n",
      "Batch 29: loss = 0.28419679403305054, acc = 0.912109375\n",
      "Batch 30: loss = 0.2830834984779358, acc = 0.9111328125\n",
      "Batch 31: loss = 0.30678993463516235, acc = 0.9033203125\n",
      "Batch 32: loss = 0.25329476594924927, acc = 0.923828125\n",
      "Batch 33: loss = 0.3937958776950836, acc = 0.8798828125\n",
      "Batch 34: loss = 0.34140968322753906, acc = 0.9033203125\n",
      "Batch 35: loss = 0.32505425810813904, acc = 0.8994140625\n",
      "Batch 36: loss = 0.2729477286338806, acc = 0.9140625\n",
      "Batch 37: loss = 0.2855844795703888, acc = 0.912109375\n",
      "Batch 38: loss = 0.29543057084083557, acc = 0.91015625\n",
      "Batch 39: loss = 0.28198862075805664, acc = 0.916015625\n",
      "Batch 40: loss = 0.30232787132263184, acc = 0.91015625\n",
      "Batch 41: loss = 0.2979673445224762, acc = 0.8984375\n",
      "\n",
      "Epoch 82/100\n",
      "Batch 1: loss = 0.296578049659729, acc = 0.9091796875\n",
      "Batch 2: loss = 0.2453908622264862, acc = 0.9296875\n",
      "Batch 3: loss = 0.24568068981170654, acc = 0.9306640625\n",
      "Batch 4: loss = 0.267448753118515, acc = 0.9169921875\n",
      "Batch 5: loss = 0.2785279154777527, acc = 0.9189453125\n",
      "Batch 6: loss = 0.24825401604175568, acc = 0.9296875\n",
      "Batch 7: loss = 0.2754673957824707, acc = 0.9169921875\n",
      "Batch 8: loss = 0.269401490688324, acc = 0.9130859375\n",
      "Batch 9: loss = 0.3070017099380493, acc = 0.908203125\n",
      "Batch 10: loss = 0.29477185010910034, acc = 0.9150390625\n",
      "Batch 11: loss = 0.3021174669265747, acc = 0.9111328125\n",
      "Batch 12: loss = 0.2905879318714142, acc = 0.904296875\n",
      "Batch 13: loss = 0.2970949709415436, acc = 0.916015625\n",
      "Batch 14: loss = 0.32097676396369934, acc = 0.8984375\n",
      "Batch 15: loss = 0.2524513900279999, acc = 0.9287109375\n",
      "Batch 16: loss = 0.2773214280605316, acc = 0.9130859375\n",
      "Batch 17: loss = 0.33101579546928406, acc = 0.88671875\n",
      "Batch 18: loss = 0.2940470576286316, acc = 0.9130859375\n",
      "Batch 19: loss = 0.3000168800354004, acc = 0.9111328125\n",
      "Batch 20: loss = 0.33596932888031006, acc = 0.8974609375\n",
      "Batch 21: loss = 0.30374032258987427, acc = 0.9033203125\n",
      "Batch 22: loss = 0.2615092992782593, acc = 0.9189453125\n",
      "Batch 23: loss = 0.27891474962234497, acc = 0.919921875\n",
      "Batch 24: loss = 0.257867693901062, acc = 0.9228515625\n",
      "Batch 25: loss = 0.2800045311450958, acc = 0.91015625\n",
      "Batch 26: loss = 0.23895813524723053, acc = 0.9306640625\n",
      "Batch 27: loss = 0.2591136693954468, acc = 0.9140625\n",
      "Batch 28: loss = 0.29187846183776855, acc = 0.908203125\n",
      "Batch 29: loss = 0.26134729385375977, acc = 0.9228515625\n",
      "Batch 30: loss = 0.26083189249038696, acc = 0.9228515625\n",
      "Batch 31: loss = 0.3102189302444458, acc = 0.9150390625\n",
      "Batch 32: loss = 0.2730898857116699, acc = 0.9150390625\n",
      "Batch 33: loss = 0.30224180221557617, acc = 0.9091796875\n",
      "Batch 34: loss = 0.3703410029411316, acc = 0.8896484375\n",
      "Batch 35: loss = 0.31010591983795166, acc = 0.9013671875\n",
      "Batch 36: loss = 0.2491883784532547, acc = 0.9208984375\n",
      "Batch 37: loss = 0.2802722454071045, acc = 0.9248046875\n",
      "Batch 38: loss = 0.2656221389770508, acc = 0.92578125\n",
      "Batch 39: loss = 0.27912312746047974, acc = 0.9140625\n",
      "Batch 40: loss = 0.3181362450122833, acc = 0.9033203125\n",
      "Batch 41: loss = 0.31643515825271606, acc = 0.9072265625\n",
      "\n",
      "Epoch 83/100\n",
      "Batch 1: loss = 0.301216721534729, acc = 0.908203125\n",
      "Batch 2: loss = 0.22389380633831024, acc = 0.935546875\n",
      "Batch 3: loss = 0.22520272433757782, acc = 0.93359375\n",
      "Batch 4: loss = 0.27105116844177246, acc = 0.9169921875\n",
      "Batch 5: loss = 0.2197066694498062, acc = 0.927734375\n",
      "Batch 6: loss = 0.2518237233161926, acc = 0.921875\n",
      "Batch 7: loss = 0.2651483416557312, acc = 0.912109375\n",
      "Batch 8: loss = 0.2485622763633728, acc = 0.9208984375\n",
      "Batch 9: loss = 0.2887730598449707, acc = 0.916015625\n",
      "Batch 10: loss = 0.3089969754219055, acc = 0.9111328125\n",
      "Batch 11: loss = 0.31331080198287964, acc = 0.9072265625\n",
      "Batch 12: loss = 0.28523632884025574, acc = 0.91015625\n",
      "Batch 13: loss = 0.2691511809825897, acc = 0.9248046875\n",
      "Batch 14: loss = 0.2677740156650543, acc = 0.9208984375\n",
      "Batch 15: loss = 0.2776825726032257, acc = 0.91796875\n",
      "Batch 16: loss = 0.2724366784095764, acc = 0.9208984375\n",
      "Batch 17: loss = 0.2786272168159485, acc = 0.9150390625\n",
      "Batch 18: loss = 0.26757848262786865, acc = 0.919921875\n",
      "Batch 19: loss = 0.29383185505867004, acc = 0.9072265625\n",
      "Batch 20: loss = 0.3311346471309662, acc = 0.896484375\n",
      "Batch 21: loss = 0.3170382082462311, acc = 0.8935546875\n",
      "Batch 22: loss = 0.2505017817020416, acc = 0.919921875\n",
      "Batch 23: loss = 0.3144226372241974, acc = 0.8935546875\n",
      "Batch 24: loss = 0.2622976303100586, acc = 0.9169921875\n",
      "Batch 25: loss = 0.24353311955928802, acc = 0.9365234375\n",
      "Batch 26: loss = 0.2383747398853302, acc = 0.9228515625\n",
      "Batch 27: loss = 0.23859721422195435, acc = 0.9248046875\n",
      "Batch 28: loss = 0.27120286226272583, acc = 0.9267578125\n",
      "Batch 29: loss = 0.2692719101905823, acc = 0.919921875\n",
      "Batch 30: loss = 0.3141590356826782, acc = 0.9072265625\n",
      "Batch 31: loss = 0.32857760787010193, acc = 0.9111328125\n",
      "Batch 32: loss = 0.26662391424179077, acc = 0.9248046875\n",
      "Batch 33: loss = 0.28606855869293213, acc = 0.9150390625\n",
      "Batch 34: loss = 0.32380181550979614, acc = 0.908203125\n",
      "Batch 35: loss = 0.28729864954948425, acc = 0.9111328125\n",
      "Batch 36: loss = 0.2682894468307495, acc = 0.916015625\n",
      "Batch 37: loss = 0.2916247844696045, acc = 0.90625\n",
      "Batch 38: loss = 0.2675333023071289, acc = 0.91015625\n",
      "Batch 39: loss = 0.2769864797592163, acc = 0.9189453125\n",
      "Batch 40: loss = 0.3032265305519104, acc = 0.91015625\n",
      "Batch 41: loss = 0.31300604343414307, acc = 0.900390625\n",
      "\n",
      "Epoch 84/100\n",
      "Batch 1: loss = 0.27471762895584106, acc = 0.921875\n",
      "Batch 2: loss = 0.24714866280555725, acc = 0.923828125\n",
      "Batch 3: loss = 0.2516598403453827, acc = 0.921875\n",
      "Batch 4: loss = 0.2452206164598465, acc = 0.9248046875\n",
      "Batch 5: loss = 0.248583123087883, acc = 0.9208984375\n",
      "Batch 6: loss = 0.23703227937221527, acc = 0.9267578125\n",
      "Batch 7: loss = 0.22507405281066895, acc = 0.9404296875\n",
      "Batch 8: loss = 0.2541247606277466, acc = 0.9267578125\n",
      "Batch 9: loss = 0.2698317766189575, acc = 0.923828125\n",
      "Batch 10: loss = 0.2789660692214966, acc = 0.912109375\n",
      "Batch 11: loss = 0.2953021228313446, acc = 0.9052734375\n",
      "Batch 12: loss = 0.2827875316143036, acc = 0.9140625\n",
      "Batch 13: loss = 0.2808990180492401, acc = 0.904296875\n",
      "Batch 14: loss = 0.28391605615615845, acc = 0.9189453125\n",
      "Batch 15: loss = 0.26340407133102417, acc = 0.923828125\n",
      "Batch 16: loss = 0.2566523551940918, acc = 0.931640625\n",
      "Batch 17: loss = 0.322238564491272, acc = 0.90625\n",
      "Batch 18: loss = 0.26347020268440247, acc = 0.9150390625\n",
      "Batch 19: loss = 0.26477810740470886, acc = 0.9228515625\n",
      "Batch 20: loss = 0.2993493676185608, acc = 0.9072265625\n",
      "Batch 21: loss = 0.29469767212867737, acc = 0.9150390625\n",
      "Batch 22: loss = 0.27205991744995117, acc = 0.9228515625\n",
      "Batch 23: loss = 0.2756602466106415, acc = 0.9228515625\n",
      "Batch 24: loss = 0.2659900188446045, acc = 0.9228515625\n",
      "Batch 25: loss = 0.2710329294204712, acc = 0.9130859375\n",
      "Batch 26: loss = 0.2552350163459778, acc = 0.931640625\n",
      "Batch 27: loss = 0.2117665410041809, acc = 0.9267578125\n",
      "Batch 28: loss = 0.24934473633766174, acc = 0.9248046875\n",
      "Batch 29: loss = 0.2451876401901245, acc = 0.921875\n",
      "Batch 30: loss = 0.29657483100891113, acc = 0.912109375\n",
      "Batch 31: loss = 0.28194302320480347, acc = 0.919921875\n",
      "Batch 32: loss = 0.23230013251304626, acc = 0.927734375\n",
      "Batch 33: loss = 0.3097628653049469, acc = 0.892578125\n",
      "Batch 34: loss = 0.30751901865005493, acc = 0.921875\n",
      "Batch 35: loss = 0.2656705975532532, acc = 0.9287109375\n",
      "Batch 36: loss = 0.27216774225234985, acc = 0.90625\n",
      "Batch 37: loss = 0.26956868171691895, acc = 0.916015625\n",
      "Batch 38: loss = 0.2838183641433716, acc = 0.91015625\n",
      "Batch 39: loss = 0.3249339461326599, acc = 0.892578125\n",
      "Batch 40: loss = 0.3197568356990814, acc = 0.9033203125\n",
      "Batch 41: loss = 0.2654935419559479, acc = 0.9150390625\n",
      "\n",
      "Epoch 85/100\n",
      "Batch 1: loss = 0.2833816409111023, acc = 0.9189453125\n",
      "Batch 2: loss = 0.2350115329027176, acc = 0.9326171875\n",
      "Batch 3: loss = 0.2681521475315094, acc = 0.9208984375\n",
      "Batch 4: loss = 0.22095179557800293, acc = 0.9287109375\n",
      "Batch 5: loss = 0.24107596278190613, acc = 0.9326171875\n",
      "Batch 6: loss = 0.24157927930355072, acc = 0.93359375\n",
      "Batch 7: loss = 0.24336934089660645, acc = 0.931640625\n",
      "Batch 8: loss = 0.2599335312843323, acc = 0.9287109375\n",
      "Batch 9: loss = 0.26533186435699463, acc = 0.927734375\n",
      "Batch 10: loss = 0.29496559500694275, acc = 0.9111328125\n",
      "Batch 11: loss = 0.2610131800174713, acc = 0.9189453125\n",
      "Batch 12: loss = 0.2994251847267151, acc = 0.91796875\n",
      "Batch 13: loss = 0.29561445116996765, acc = 0.9052734375\n",
      "Batch 14: loss = 0.2890707850456238, acc = 0.9169921875\n",
      "Batch 15: loss = 0.23745693266391754, acc = 0.9375\n",
      "Batch 16: loss = 0.2597205638885498, acc = 0.921875\n",
      "Batch 17: loss = 0.2766757607460022, acc = 0.9140625\n",
      "Batch 18: loss = 0.28354477882385254, acc = 0.912109375\n",
      "Batch 19: loss = 0.27422451972961426, acc = 0.9169921875\n",
      "Batch 20: loss = 0.31578508019447327, acc = 0.91796875\n",
      "Batch 21: loss = 0.3193144202232361, acc = 0.9111328125\n",
      "Batch 22: loss = 0.30113115906715393, acc = 0.896484375\n",
      "Batch 23: loss = 0.2958952784538269, acc = 0.89453125\n",
      "Batch 24: loss = 0.2442714422941208, acc = 0.9228515625\n",
      "Batch 25: loss = 0.2331286519765854, acc = 0.9345703125\n",
      "Batch 26: loss = 0.24454030394554138, acc = 0.923828125\n",
      "Batch 27: loss = 0.21907849609851837, acc = 0.921875\n",
      "Batch 28: loss = 0.2599582076072693, acc = 0.9169921875\n",
      "Batch 29: loss = 0.2774676978588104, acc = 0.9248046875\n",
      "Batch 30: loss = 0.26388517022132874, acc = 0.921875\n",
      "Batch 31: loss = 0.2700192928314209, acc = 0.931640625\n",
      "Batch 32: loss = 0.2596442997455597, acc = 0.91796875\n",
      "Batch 33: loss = 0.2683562636375427, acc = 0.9287109375\n",
      "Batch 34: loss = 0.288657546043396, acc = 0.9111328125\n",
      "Batch 35: loss = 0.3211667537689209, acc = 0.904296875\n",
      "Batch 36: loss = 0.24635639786720276, acc = 0.921875\n",
      "Batch 37: loss = 0.28351348638534546, acc = 0.9169921875\n",
      "Batch 38: loss = 0.26986268162727356, acc = 0.921875\n",
      "Batch 39: loss = 0.2868677079677582, acc = 0.9033203125\n",
      "Batch 40: loss = 0.31285586953163147, acc = 0.9013671875\n",
      "Batch 41: loss = 0.3014488220214844, acc = 0.904296875\n",
      "\n",
      "Epoch 86/100\n",
      "Batch 1: loss = 0.29990482330322266, acc = 0.90625\n",
      "Batch 2: loss = 0.23215779662132263, acc = 0.931640625\n",
      "Batch 3: loss = 0.2217678725719452, acc = 0.9345703125\n",
      "Batch 4: loss = 0.22889916598796844, acc = 0.9287109375\n",
      "Batch 5: loss = 0.21438217163085938, acc = 0.939453125\n",
      "Batch 6: loss = 0.2158629298210144, acc = 0.9306640625\n",
      "Batch 7: loss = 0.24702134728431702, acc = 0.923828125\n",
      "Batch 8: loss = 0.23581472039222717, acc = 0.927734375\n",
      "Batch 9: loss = 0.26574915647506714, acc = 0.9169921875\n",
      "Batch 10: loss = 0.27775824069976807, acc = 0.9169921875\n",
      "Batch 11: loss = 0.29277437925338745, acc = 0.9111328125\n",
      "Batch 12: loss = 0.2609679698944092, acc = 0.9189453125\n",
      "Batch 13: loss = 0.2941582202911377, acc = 0.9130859375\n",
      "Batch 14: loss = 0.22223210334777832, acc = 0.927734375\n",
      "Batch 15: loss = 0.2745819389820099, acc = 0.9228515625\n",
      "Batch 16: loss = 0.23249632120132446, acc = 0.921875\n",
      "Batch 17: loss = 0.25739288330078125, acc = 0.9296875\n",
      "Batch 18: loss = 0.27591514587402344, acc = 0.91015625\n",
      "Batch 19: loss = 0.2804887294769287, acc = 0.916015625\n",
      "Batch 20: loss = 0.26187413930892944, acc = 0.9248046875\n",
      "Batch 21: loss = 0.29181230068206787, acc = 0.9033203125\n",
      "Batch 22: loss = 0.2590259909629822, acc = 0.931640625\n",
      "Batch 23: loss = 0.264140248298645, acc = 0.9208984375\n",
      "Batch 24: loss = 0.25409674644470215, acc = 0.9287109375\n",
      "Batch 25: loss = 0.2640492022037506, acc = 0.9248046875\n",
      "Batch 26: loss = 0.2537848949432373, acc = 0.9208984375\n",
      "Batch 27: loss = 0.19878612458705902, acc = 0.9365234375\n",
      "Batch 28: loss = 0.25810521841049194, acc = 0.9208984375\n",
      "Batch 29: loss = 0.25476542115211487, acc = 0.9189453125\n",
      "Batch 30: loss = 0.28039515018463135, acc = 0.904296875\n",
      "Batch 31: loss = 0.24464577436447144, acc = 0.931640625\n",
      "Batch 32: loss = 0.24015162885189056, acc = 0.935546875\n",
      "Batch 33: loss = 0.2558249831199646, acc = 0.9208984375\n",
      "Batch 34: loss = 0.3140721321105957, acc = 0.916015625\n",
      "Batch 35: loss = 0.28028935194015503, acc = 0.9140625\n",
      "Batch 36: loss = 0.2175101339817047, acc = 0.939453125\n",
      "Batch 37: loss = 0.2598903179168701, acc = 0.9296875\n",
      "Batch 38: loss = 0.2538504898548126, acc = 0.91796875\n",
      "Batch 39: loss = 0.2614131569862366, acc = 0.919921875\n",
      "Batch 40: loss = 0.3048593997955322, acc = 0.900390625\n",
      "Batch 41: loss = 0.30219411849975586, acc = 0.8994140625\n",
      "\n",
      "Epoch 87/100\n",
      "Batch 1: loss = 0.29267027974128723, acc = 0.921875\n",
      "Batch 2: loss = 0.2245556265115738, acc = 0.927734375\n",
      "Batch 3: loss = 0.22013510763645172, acc = 0.9453125\n",
      "Batch 4: loss = 0.24479904770851135, acc = 0.9306640625\n",
      "Batch 5: loss = 0.22427639365196228, acc = 0.935546875\n",
      "Batch 6: loss = 0.2410634607076645, acc = 0.9208984375\n",
      "Batch 7: loss = 0.23896481096744537, acc = 0.9296875\n",
      "Batch 8: loss = 0.2422378659248352, acc = 0.931640625\n",
      "Batch 9: loss = 0.24735897779464722, acc = 0.9287109375\n",
      "Batch 10: loss = 0.269561231136322, acc = 0.9140625\n",
      "Batch 11: loss = 0.2607434391975403, acc = 0.9189453125\n",
      "Batch 12: loss = 0.29645729064941406, acc = 0.912109375\n",
      "Batch 13: loss = 0.27022963762283325, acc = 0.916015625\n",
      "Batch 14: loss = 0.2456849366426468, acc = 0.916015625\n",
      "Batch 15: loss = 0.22192582488059998, acc = 0.9404296875\n",
      "Batch 16: loss = 0.2605249881744385, acc = 0.921875\n",
      "Batch 17: loss = 0.264135479927063, acc = 0.9228515625\n",
      "Batch 18: loss = 0.26955485343933105, acc = 0.9130859375\n",
      "Batch 19: loss = 0.3138546347618103, acc = 0.9111328125\n",
      "Batch 20: loss = 0.26520127058029175, acc = 0.9267578125\n",
      "Batch 21: loss = 0.2738688290119171, acc = 0.916015625\n",
      "Batch 22: loss = 0.2743489742279053, acc = 0.9169921875\n",
      "Batch 23: loss = 0.2537294030189514, acc = 0.92578125\n",
      "Batch 24: loss = 0.2615988850593567, acc = 0.912109375\n",
      "Batch 25: loss = 0.24641908705234528, acc = 0.92578125\n",
      "Batch 26: loss = 0.2422610968351364, acc = 0.9296875\n",
      "Batch 27: loss = 0.22419802844524384, acc = 0.9287109375\n",
      "Batch 28: loss = 0.265144020318985, acc = 0.921875\n",
      "Batch 29: loss = 0.27659809589385986, acc = 0.9091796875\n",
      "Batch 30: loss = 0.2547624111175537, acc = 0.9248046875\n",
      "Batch 31: loss = 0.2734141945838928, acc = 0.919921875\n",
      "Batch 32: loss = 0.2534772753715515, acc = 0.92578125\n",
      "Batch 33: loss = 0.29667454957962036, acc = 0.90625\n",
      "Batch 34: loss = 0.31380152702331543, acc = 0.9013671875\n",
      "Batch 35: loss = 0.23872840404510498, acc = 0.9267578125\n",
      "Batch 36: loss = 0.23128943145275116, acc = 0.9267578125\n",
      "Batch 37: loss = 0.28096920251846313, acc = 0.912109375\n",
      "Batch 38: loss = 0.2362058460712433, acc = 0.919921875\n",
      "Batch 39: loss = 0.2916380763053894, acc = 0.9091796875\n",
      "Batch 40: loss = 0.3065490126609802, acc = 0.9033203125\n",
      "Batch 41: loss = 0.28998568654060364, acc = 0.9091796875\n",
      "\n",
      "Epoch 88/100\n",
      "Batch 1: loss = 0.28920280933380127, acc = 0.912109375\n",
      "Batch 2: loss = 0.28760138154029846, acc = 0.908203125\n",
      "Batch 3: loss = 0.24159519374370575, acc = 0.93359375\n",
      "Batch 4: loss = 0.23065787553787231, acc = 0.9296875\n",
      "Batch 5: loss = 0.22914782166481018, acc = 0.931640625\n",
      "Batch 6: loss = 0.24085786938667297, acc = 0.9306640625\n",
      "Batch 7: loss = 0.23411494493484497, acc = 0.927734375\n",
      "Batch 8: loss = 0.23409458994865417, acc = 0.92578125\n",
      "Batch 9: loss = 0.23977868258953094, acc = 0.927734375\n",
      "Batch 10: loss = 0.2828618288040161, acc = 0.908203125\n",
      "Batch 11: loss = 0.28874123096466064, acc = 0.908203125\n",
      "Batch 12: loss = 0.2454124093055725, acc = 0.9248046875\n",
      "Batch 13: loss = 0.2617300748825073, acc = 0.9169921875\n",
      "Batch 14: loss = 0.29834944009780884, acc = 0.91015625\n",
      "Batch 15: loss = 0.24057699739933014, acc = 0.9326171875\n",
      "Batch 16: loss = 0.23279884457588196, acc = 0.94140625\n",
      "Batch 17: loss = 0.25096070766448975, acc = 0.9130859375\n",
      "Batch 18: loss = 0.2355247437953949, acc = 0.9267578125\n",
      "Batch 19: loss = 0.28146892786026, acc = 0.904296875\n",
      "Batch 20: loss = 0.2944903075695038, acc = 0.9150390625\n",
      "Batch 21: loss = 0.27506890892982483, acc = 0.9140625\n",
      "Batch 22: loss = 0.25729644298553467, acc = 0.9140625\n",
      "Batch 23: loss = 0.25362804532051086, acc = 0.927734375\n",
      "Batch 24: loss = 0.2508993446826935, acc = 0.9248046875\n",
      "Batch 25: loss = 0.23603568971157074, acc = 0.9296875\n",
      "Batch 26: loss = 0.25252407789230347, acc = 0.92578125\n",
      "Batch 27: loss = 0.20104557275772095, acc = 0.94140625\n",
      "Batch 28: loss = 0.2543015480041504, acc = 0.919921875\n",
      "Batch 29: loss = 0.2481822371482849, acc = 0.916015625\n",
      "Batch 30: loss = 0.27358996868133545, acc = 0.9208984375\n",
      "Batch 31: loss = 0.2852975130081177, acc = 0.9130859375\n",
      "Batch 32: loss = 0.2475738525390625, acc = 0.919921875\n",
      "Batch 33: loss = 0.29231423139572144, acc = 0.919921875\n",
      "Batch 34: loss = 0.312139093875885, acc = 0.916015625\n",
      "Batch 35: loss = 0.29671138525009155, acc = 0.904296875\n",
      "Batch 36: loss = 0.23211443424224854, acc = 0.9306640625\n",
      "Batch 37: loss = 0.2472173273563385, acc = 0.92578125\n",
      "Batch 38: loss = 0.22786861658096313, acc = 0.93359375\n",
      "Batch 39: loss = 0.2604603171348572, acc = 0.912109375\n",
      "Batch 40: loss = 0.3160575330257416, acc = 0.896484375\n",
      "Batch 41: loss = 0.26821550726890564, acc = 0.923828125\n",
      "\n",
      "Epoch 89/100\n",
      "Batch 1: loss = 0.25730106234550476, acc = 0.923828125\n",
      "Batch 2: loss = 0.23201768100261688, acc = 0.9326171875\n",
      "Batch 3: loss = 0.22187012434005737, acc = 0.94140625\n",
      "Batch 4: loss = 0.2134789377450943, acc = 0.9384765625\n",
      "Batch 5: loss = 0.23030918836593628, acc = 0.9326171875\n",
      "Batch 6: loss = 0.22286555171012878, acc = 0.9267578125\n",
      "Batch 7: loss = 0.24015596508979797, acc = 0.9296875\n",
      "Batch 8: loss = 0.22251158952713013, acc = 0.9267578125\n",
      "Batch 9: loss = 0.2809998393058777, acc = 0.9150390625\n",
      "Batch 10: loss = 0.24100668728351593, acc = 0.9287109375\n",
      "Batch 11: loss = 0.27743884921073914, acc = 0.908203125\n",
      "Batch 12: loss = 0.24086201190948486, acc = 0.9287109375\n",
      "Batch 13: loss = 0.23599159717559814, acc = 0.9345703125\n",
      "Batch 14: loss = 0.22301535308361053, acc = 0.9248046875\n",
      "Batch 15: loss = 0.21914412081241608, acc = 0.9365234375\n",
      "Batch 16: loss = 0.21803021430969238, acc = 0.927734375\n",
      "Batch 17: loss = 0.23970229923725128, acc = 0.935546875\n",
      "Batch 18: loss = 0.252006858587265, acc = 0.9287109375\n",
      "Batch 19: loss = 0.2681688070297241, acc = 0.9208984375\n",
      "Batch 20: loss = 0.2589317560195923, acc = 0.9287109375\n",
      "Batch 21: loss = 0.2847077548503876, acc = 0.919921875\n",
      "Batch 22: loss = 0.2545744478702545, acc = 0.9208984375\n",
      "Batch 23: loss = 0.25025874376296997, acc = 0.91796875\n",
      "Batch 24: loss = 0.26720115542411804, acc = 0.919921875\n",
      "Batch 25: loss = 0.23259273171424866, acc = 0.9248046875\n",
      "Batch 26: loss = 0.22653216123580933, acc = 0.9326171875\n",
      "Batch 27: loss = 0.20757240056991577, acc = 0.9345703125\n",
      "Batch 28: loss = 0.2436530441045761, acc = 0.9306640625\n",
      "Batch 29: loss = 0.25172775983810425, acc = 0.9267578125\n",
      "Batch 30: loss = 0.25691989064216614, acc = 0.92578125\n",
      "Batch 31: loss = 0.26125994324684143, acc = 0.9208984375\n",
      "Batch 32: loss = 0.2461208701133728, acc = 0.9267578125\n",
      "Batch 33: loss = 0.2806222438812256, acc = 0.9091796875\n",
      "Batch 34: loss = 0.29759180545806885, acc = 0.9140625\n",
      "Batch 35: loss = 0.24781948328018188, acc = 0.9248046875\n",
      "Batch 36: loss = 0.2076312005519867, acc = 0.9326171875\n",
      "Batch 37: loss = 0.24720756709575653, acc = 0.921875\n",
      "Batch 38: loss = 0.2696651518344879, acc = 0.9140625\n",
      "Batch 39: loss = 0.276687890291214, acc = 0.91015625\n",
      "Batch 40: loss = 0.2687162756919861, acc = 0.9130859375\n",
      "Batch 41: loss = 0.29424282908439636, acc = 0.91015625\n",
      "\n",
      "Epoch 90/100\n",
      "Batch 1: loss = 0.29007014632225037, acc = 0.919921875\n",
      "Batch 2: loss = 0.19183364510536194, acc = 0.9482421875\n",
      "Batch 3: loss = 0.2000836730003357, acc = 0.9462890625\n",
      "Batch 4: loss = 0.22519807517528534, acc = 0.9375\n",
      "Batch 5: loss = 0.2295617163181305, acc = 0.9248046875\n",
      "Batch 6: loss = 0.20703476667404175, acc = 0.9375\n",
      "Batch 7: loss = 0.24889083206653595, acc = 0.92578125\n",
      "Batch 8: loss = 0.2122185230255127, acc = 0.9345703125\n",
      "Batch 9: loss = 0.23136380314826965, acc = 0.9345703125\n",
      "Batch 10: loss = 0.25075048208236694, acc = 0.935546875\n",
      "Batch 11: loss = 0.2722882032394409, acc = 0.916015625\n",
      "Batch 12: loss = 0.25732892751693726, acc = 0.9208984375\n",
      "Batch 13: loss = 0.2728866934776306, acc = 0.9169921875\n",
      "Batch 14: loss = 0.22812119126319885, acc = 0.9306640625\n",
      "Batch 15: loss = 0.25040867924690247, acc = 0.923828125\n",
      "Batch 16: loss = 0.24022908508777618, acc = 0.919921875\n",
      "Batch 17: loss = 0.25457334518432617, acc = 0.923828125\n",
      "Batch 18: loss = 0.24908484518527985, acc = 0.93359375\n",
      "Batch 19: loss = 0.25455960631370544, acc = 0.923828125\n",
      "Batch 20: loss = 0.30010122060775757, acc = 0.904296875\n",
      "Batch 21: loss = 0.3036784827709198, acc = 0.8994140625\n",
      "Batch 22: loss = 0.2622509300708771, acc = 0.923828125\n",
      "Batch 23: loss = 0.29852384328842163, acc = 0.912109375\n",
      "Batch 24: loss = 0.27395835518836975, acc = 0.921875\n",
      "Batch 25: loss = 0.2129298895597458, acc = 0.9423828125\n",
      "Batch 26: loss = 0.21012407541275024, acc = 0.9345703125\n",
      "Batch 27: loss = 0.2180294692516327, acc = 0.93359375\n",
      "Batch 28: loss = 0.2372918725013733, acc = 0.9345703125\n",
      "Batch 29: loss = 0.23398447036743164, acc = 0.9248046875\n",
      "Batch 30: loss = 0.2996525764465332, acc = 0.912109375\n",
      "Batch 31: loss = 0.2786203622817993, acc = 0.9140625\n",
      "Batch 32: loss = 0.22324901819229126, acc = 0.9375\n",
      "Batch 33: loss = 0.29719245433807373, acc = 0.90625\n",
      "Batch 34: loss = 0.2867596745491028, acc = 0.9189453125\n",
      "Batch 35: loss = 0.2750205397605896, acc = 0.912109375\n",
      "Batch 36: loss = 0.22480197250843048, acc = 0.9267578125\n",
      "Batch 37: loss = 0.2527439296245575, acc = 0.912109375\n",
      "Batch 38: loss = 0.22462359070777893, acc = 0.9306640625\n",
      "Batch 39: loss = 0.2483592927455902, acc = 0.9326171875\n",
      "Batch 40: loss = 0.2920893132686615, acc = 0.904296875\n",
      "Batch 41: loss = 0.2784091830253601, acc = 0.9130859375\n",
      "Saved checkpoint to weights_eminem_input.txt.90.h5\n",
      "\n",
      "Epoch 91/100\n",
      "Batch 1: loss = 0.23661477863788605, acc = 0.935546875\n",
      "Batch 2: loss = 0.2051287442445755, acc = 0.9453125\n",
      "Batch 3: loss = 0.22555656731128693, acc = 0.927734375\n",
      "Batch 4: loss = 0.2122754454612732, acc = 0.9384765625\n",
      "Batch 5: loss = 0.21082305908203125, acc = 0.9384765625\n",
      "Batch 6: loss = 0.197666198015213, acc = 0.9345703125\n",
      "Batch 7: loss = 0.2088889330625534, acc = 0.94140625\n",
      "Batch 8: loss = 0.2192612588405609, acc = 0.935546875\n",
      "Batch 9: loss = 0.2471373975276947, acc = 0.927734375\n",
      "Batch 10: loss = 0.23268964886665344, acc = 0.9296875\n",
      "Batch 11: loss = 0.2655675411224365, acc = 0.9287109375\n",
      "Batch 12: loss = 0.25194692611694336, acc = 0.9208984375\n",
      "Batch 13: loss = 0.2755684554576874, acc = 0.9140625\n",
      "Batch 14: loss = 0.26412150263786316, acc = 0.9208984375\n",
      "Batch 15: loss = 0.2196800410747528, acc = 0.9423828125\n",
      "Batch 16: loss = 0.21188807487487793, acc = 0.9404296875\n",
      "Batch 17: loss = 0.23410865664482117, acc = 0.931640625\n",
      "Batch 18: loss = 0.2585682272911072, acc = 0.9248046875\n",
      "Batch 19: loss = 0.2550547420978546, acc = 0.923828125\n",
      "Batch 20: loss = 0.29711204767227173, acc = 0.9208984375\n",
      "Batch 21: loss = 0.2749381959438324, acc = 0.916015625\n",
      "Batch 22: loss = 0.2603037357330322, acc = 0.91796875\n",
      "Batch 23: loss = 0.2531149685382843, acc = 0.9169921875\n",
      "Batch 24: loss = 0.25130677223205566, acc = 0.923828125\n",
      "Batch 25: loss = 0.23105379939079285, acc = 0.927734375\n",
      "Batch 26: loss = 0.23489220440387726, acc = 0.927734375\n",
      "Batch 27: loss = 0.20402413606643677, acc = 0.939453125\n",
      "Batch 28: loss = 0.22867119312286377, acc = 0.927734375\n",
      "Batch 29: loss = 0.24568551778793335, acc = 0.9267578125\n",
      "Batch 30: loss = 0.24050530791282654, acc = 0.9296875\n",
      "Batch 31: loss = 0.2380964159965515, acc = 0.9326171875\n",
      "Batch 32: loss = 0.2379993498325348, acc = 0.921875\n",
      "Batch 33: loss = 0.262422114610672, acc = 0.9208984375\n",
      "Batch 34: loss = 0.27169352769851685, acc = 0.9208984375\n",
      "Batch 35: loss = 0.24944011867046356, acc = 0.919921875\n",
      "Batch 36: loss = 0.2044021338224411, acc = 0.93359375\n",
      "Batch 37: loss = 0.2527565360069275, acc = 0.9267578125\n",
      "Batch 38: loss = 0.24216513335704803, acc = 0.9267578125\n",
      "Batch 39: loss = 0.2414824366569519, acc = 0.9169921875\n",
      "Batch 40: loss = 0.24866706132888794, acc = 0.9287109375\n",
      "Batch 41: loss = 0.23398730158805847, acc = 0.9228515625\n",
      "\n",
      "Epoch 92/100\n",
      "Batch 1: loss = 0.2725316286087036, acc = 0.9267578125\n",
      "Batch 2: loss = 0.2297246754169464, acc = 0.9404296875\n",
      "Batch 3: loss = 0.2359941303730011, acc = 0.9296875\n",
      "Batch 4: loss = 0.19170568883419037, acc = 0.9404296875\n",
      "Batch 5: loss = 0.241974875330925, acc = 0.9296875\n",
      "Batch 6: loss = 0.26608824729919434, acc = 0.912109375\n",
      "Batch 7: loss = 0.23684561252593994, acc = 0.9287109375\n",
      "Batch 8: loss = 0.22641800343990326, acc = 0.9404296875\n",
      "Batch 9: loss = 0.2512451410293579, acc = 0.92578125\n",
      "Batch 10: loss = 0.23160231113433838, acc = 0.931640625\n",
      "Batch 11: loss = 0.26483458280563354, acc = 0.91015625\n",
      "Batch 12: loss = 0.2168884128332138, acc = 0.9384765625\n",
      "Batch 13: loss = 0.23329180479049683, acc = 0.9345703125\n",
      "Batch 14: loss = 0.24029883742332458, acc = 0.91796875\n",
      "Batch 15: loss = 0.24149131774902344, acc = 0.9248046875\n",
      "Batch 16: loss = 0.2297465205192566, acc = 0.931640625\n",
      "Batch 17: loss = 0.2574213743209839, acc = 0.92578125\n",
      "Batch 18: loss = 0.2790146768093109, acc = 0.91015625\n",
      "Batch 19: loss = 0.2829740047454834, acc = 0.9052734375\n",
      "Batch 20: loss = 0.24554619193077087, acc = 0.9287109375\n",
      "Batch 21: loss = 0.25667333602905273, acc = 0.9248046875\n",
      "Batch 22: loss = 0.25915563106536865, acc = 0.9208984375\n",
      "Batch 23: loss = 0.22409306466579437, acc = 0.9287109375\n",
      "Batch 24: loss = 0.2290138602256775, acc = 0.931640625\n",
      "Batch 25: loss = 0.2300558239221573, acc = 0.9443359375\n",
      "Batch 26: loss = 0.22553694248199463, acc = 0.9306640625\n",
      "Batch 27: loss = 0.18367642164230347, acc = 0.939453125\n",
      "Batch 28: loss = 0.24048349261283875, acc = 0.9345703125\n",
      "Batch 29: loss = 0.22774823009967804, acc = 0.923828125\n",
      "Batch 30: loss = 0.23707816004753113, acc = 0.92578125\n",
      "Batch 31: loss = 0.258029580116272, acc = 0.92578125\n",
      "Batch 32: loss = 0.2486903965473175, acc = 0.923828125\n",
      "Batch 33: loss = 0.27256691455841064, acc = 0.919921875\n",
      "Batch 34: loss = 0.2659730315208435, acc = 0.9248046875\n",
      "Batch 35: loss = 0.2600761353969574, acc = 0.92578125\n",
      "Batch 36: loss = 0.23206456005573273, acc = 0.9267578125\n",
      "Batch 37: loss = 0.22201129794120789, acc = 0.9296875\n",
      "Batch 38: loss = 0.232453852891922, acc = 0.9326171875\n",
      "Batch 39: loss = 0.22798779606819153, acc = 0.9267578125\n",
      "Batch 40: loss = 0.25729408860206604, acc = 0.9189453125\n",
      "Batch 41: loss = 0.23623625934123993, acc = 0.92578125\n",
      "\n",
      "Epoch 93/100\n",
      "Batch 1: loss = 0.24963374435901642, acc = 0.92578125\n",
      "Batch 2: loss = 0.17882665991783142, acc = 0.947265625\n",
      "Batch 3: loss = 0.22270768880844116, acc = 0.9375\n",
      "Batch 4: loss = 0.20015715062618256, acc = 0.94140625\n",
      "Batch 5: loss = 0.20119482278823853, acc = 0.9326171875\n",
      "Batch 6: loss = 0.21675413846969604, acc = 0.931640625\n",
      "Batch 7: loss = 0.23685741424560547, acc = 0.923828125\n",
      "Batch 8: loss = 0.1845478117465973, acc = 0.9501953125\n",
      "Batch 9: loss = 0.23338741064071655, acc = 0.9306640625\n",
      "Batch 10: loss = 0.21933536231517792, acc = 0.9384765625\n",
      "Batch 11: loss = 0.24651427567005157, acc = 0.9208984375\n",
      "Batch 12: loss = 0.20970916748046875, acc = 0.935546875\n",
      "Batch 13: loss = 0.23044027388095856, acc = 0.9345703125\n",
      "Batch 14: loss = 0.20532813668251038, acc = 0.935546875\n",
      "Batch 15: loss = 0.21087810397148132, acc = 0.935546875\n",
      "Batch 16: loss = 0.23373743891716003, acc = 0.939453125\n",
      "Batch 17: loss = 0.2280980944633484, acc = 0.9296875\n",
      "Batch 18: loss = 0.22601136565208435, acc = 0.9345703125\n",
      "Batch 19: loss = 0.23779833316802979, acc = 0.9326171875\n",
      "Batch 20: loss = 0.2614779472351074, acc = 0.92578125\n",
      "Batch 21: loss = 0.2509283423423767, acc = 0.9267578125\n",
      "Batch 22: loss = 0.23151980340480804, acc = 0.9267578125\n",
      "Batch 23: loss = 0.21019048988819122, acc = 0.9423828125\n",
      "Batch 24: loss = 0.23237022757530212, acc = 0.92578125\n",
      "Batch 25: loss = 0.22068440914154053, acc = 0.9365234375\n",
      "Batch 26: loss = 0.20142731070518494, acc = 0.9375\n",
      "Batch 27: loss = 0.14503377676010132, acc = 0.962890625\n",
      "Batch 28: loss = 0.21485558152198792, acc = 0.93359375\n",
      "Batch 29: loss = 0.22781890630722046, acc = 0.927734375\n",
      "Batch 30: loss = 0.24098670482635498, acc = 0.9345703125\n",
      "Batch 31: loss = 0.2483930140733719, acc = 0.931640625\n",
      "Batch 32: loss = 0.2343102991580963, acc = 0.931640625\n",
      "Batch 33: loss = 0.2895793616771698, acc = 0.919921875\n",
      "Batch 34: loss = 0.26983559131622314, acc = 0.908203125\n",
      "Batch 35: loss = 0.2237936556339264, acc = 0.9326171875\n",
      "Batch 36: loss = 0.2240920513868332, acc = 0.9296875\n",
      "Batch 37: loss = 0.22197982668876648, acc = 0.9306640625\n",
      "Batch 38: loss = 0.21880534291267395, acc = 0.9326171875\n",
      "Batch 39: loss = 0.24066022038459778, acc = 0.9150390625\n",
      "Batch 40: loss = 0.24435703456401825, acc = 0.9189453125\n",
      "Batch 41: loss = 0.2606300115585327, acc = 0.916015625\n",
      "\n",
      "Epoch 94/100\n",
      "Batch 1: loss = 0.26859918236732483, acc = 0.9150390625\n",
      "Batch 2: loss = 0.23219867050647736, acc = 0.92578125\n",
      "Batch 3: loss = 0.20143923163414001, acc = 0.9443359375\n",
      "Batch 4: loss = 0.1843568980693817, acc = 0.943359375\n",
      "Batch 5: loss = 0.21824532747268677, acc = 0.9375\n",
      "Batch 6: loss = 0.1793660819530487, acc = 0.947265625\n",
      "Batch 7: loss = 0.22344118356704712, acc = 0.9326171875\n",
      "Batch 8: loss = 0.22544372081756592, acc = 0.935546875\n",
      "Batch 9: loss = 0.2274005115032196, acc = 0.935546875\n",
      "Batch 10: loss = 0.2474556565284729, acc = 0.9228515625\n",
      "Batch 11: loss = 0.27899444103240967, acc = 0.904296875\n",
      "Batch 12: loss = 0.22621312737464905, acc = 0.9287109375\n",
      "Batch 13: loss = 0.21269167959690094, acc = 0.9375\n",
      "Batch 14: loss = 0.22933992743492126, acc = 0.9306640625\n",
      "Batch 15: loss = 0.21541009843349457, acc = 0.9365234375\n",
      "Batch 16: loss = 0.22973598539829254, acc = 0.9345703125\n",
      "Batch 17: loss = 0.2201043665409088, acc = 0.931640625\n",
      "Batch 18: loss = 0.2556386888027191, acc = 0.9267578125\n",
      "Batch 19: loss = 0.24116738140583038, acc = 0.9306640625\n",
      "Batch 20: loss = 0.2465568333864212, acc = 0.9375\n",
      "Batch 21: loss = 0.2476775348186493, acc = 0.92578125\n",
      "Batch 22: loss = 0.2846320569515228, acc = 0.9130859375\n",
      "Batch 23: loss = 0.24261122941970825, acc = 0.9296875\n",
      "Batch 24: loss = 0.24513518810272217, acc = 0.9306640625\n",
      "Batch 25: loss = 0.27137821912765503, acc = 0.9150390625\n",
      "Batch 26: loss = 0.2154446244239807, acc = 0.939453125\n",
      "Batch 27: loss = 0.19114097952842712, acc = 0.9453125\n",
      "Batch 28: loss = 0.2590148448944092, acc = 0.9208984375\n",
      "Batch 29: loss = 0.22760988771915436, acc = 0.9306640625\n",
      "Batch 30: loss = 0.21954292058944702, acc = 0.9423828125\n",
      "Batch 31: loss = 0.26221030950546265, acc = 0.9296875\n",
      "Batch 32: loss = 0.18477082252502441, acc = 0.9453125\n",
      "Batch 33: loss = 0.2572669982910156, acc = 0.921875\n",
      "Batch 34: loss = 0.2645084261894226, acc = 0.9228515625\n",
      "Batch 35: loss = 0.21723672747612, acc = 0.9326171875\n",
      "Batch 36: loss = 0.21285194158554077, acc = 0.931640625\n",
      "Batch 37: loss = 0.2146323323249817, acc = 0.9375\n",
      "Batch 38: loss = 0.20331767201423645, acc = 0.9375\n",
      "Batch 39: loss = 0.23596403002738953, acc = 0.923828125\n",
      "Batch 40: loss = 0.2383478432893753, acc = 0.9296875\n",
      "Batch 41: loss = 0.2462168037891388, acc = 0.91796875\n",
      "\n",
      "Epoch 95/100\n",
      "Batch 1: loss = 0.26179414987564087, acc = 0.9326171875\n",
      "Batch 2: loss = 0.20206567645072937, acc = 0.935546875\n",
      "Batch 3: loss = 0.19961829483509064, acc = 0.94921875\n",
      "Batch 4: loss = 0.21372786164283752, acc = 0.9326171875\n",
      "Batch 5: loss = 0.19240060448646545, acc = 0.9453125\n",
      "Batch 6: loss = 0.20409272611141205, acc = 0.93359375\n",
      "Batch 7: loss = 0.2018275409936905, acc = 0.9345703125\n",
      "Batch 8: loss = 0.20193526148796082, acc = 0.9423828125\n",
      "Batch 9: loss = 0.23417304456233978, acc = 0.9384765625\n",
      "Batch 10: loss = 0.2405109405517578, acc = 0.9248046875\n",
      "Batch 11: loss = 0.2399507462978363, acc = 0.9189453125\n",
      "Batch 12: loss = 0.24884377419948578, acc = 0.9267578125\n",
      "Batch 13: loss = 0.2525234818458557, acc = 0.935546875\n",
      "Batch 14: loss = 0.19337818026542664, acc = 0.94140625\n",
      "Batch 15: loss = 0.20266389846801758, acc = 0.9462890625\n",
      "Batch 16: loss = 0.20235130190849304, acc = 0.9345703125\n",
      "Batch 17: loss = 0.21662576496601105, acc = 0.9296875\n",
      "Batch 18: loss = 0.22807885706424713, acc = 0.9326171875\n",
      "Batch 19: loss = 0.2504850924015045, acc = 0.9306640625\n",
      "Batch 20: loss = 0.22566689550876617, acc = 0.93359375\n",
      "Batch 21: loss = 0.25394999980926514, acc = 0.9208984375\n",
      "Batch 22: loss = 0.24053910374641418, acc = 0.921875\n",
      "Batch 23: loss = 0.2576369047164917, acc = 0.919921875\n",
      "Batch 24: loss = 0.2207552045583725, acc = 0.935546875\n",
      "Batch 25: loss = 0.20393384993076324, acc = 0.9375\n",
      "Batch 26: loss = 0.17840084433555603, acc = 0.9482421875\n",
      "Batch 27: loss = 0.1627250760793686, acc = 0.943359375\n",
      "Batch 28: loss = 0.21313822269439697, acc = 0.9375\n",
      "Batch 29: loss = 0.20214149355888367, acc = 0.939453125\n",
      "Batch 30: loss = 0.24323511123657227, acc = 0.927734375\n",
      "Batch 31: loss = 0.2308959662914276, acc = 0.939453125\n",
      "Batch 32: loss = 0.22729532420635223, acc = 0.93359375\n",
      "Batch 33: loss = 0.23014527559280396, acc = 0.9326171875\n",
      "Batch 34: loss = 0.25578397512435913, acc = 0.923828125\n",
      "Batch 35: loss = 0.284214049577713, acc = 0.912109375\n",
      "Batch 36: loss = 0.1972086876630783, acc = 0.9404296875\n",
      "Batch 37: loss = 0.23581841588020325, acc = 0.9365234375\n",
      "Batch 38: loss = 0.2242300808429718, acc = 0.935546875\n",
      "Batch 39: loss = 0.24524393677711487, acc = 0.9228515625\n",
      "Batch 40: loss = 0.24784865975379944, acc = 0.9228515625\n",
      "Batch 41: loss = 0.2900163531303406, acc = 0.91796875\n",
      "\n",
      "Epoch 96/100\n",
      "Batch 1: loss = 0.2217562198638916, acc = 0.9365234375\n",
      "Batch 2: loss = 0.21043214201927185, acc = 0.939453125\n",
      "Batch 3: loss = 0.20086166262626648, acc = 0.9384765625\n",
      "Batch 4: loss = 0.17482587695121765, acc = 0.9453125\n",
      "Batch 5: loss = 0.19568398594856262, acc = 0.9423828125\n",
      "Batch 6: loss = 0.20925506949424744, acc = 0.9365234375\n",
      "Batch 7: loss = 0.22257910668849945, acc = 0.9326171875\n",
      "Batch 8: loss = 0.21741461753845215, acc = 0.9326171875\n",
      "Batch 9: loss = 0.23065295815467834, acc = 0.927734375\n",
      "Batch 10: loss = 0.25117653608322144, acc = 0.9306640625\n",
      "Batch 11: loss = 0.264358252286911, acc = 0.9150390625\n",
      "Batch 12: loss = 0.21325796842575073, acc = 0.9375\n",
      "Batch 13: loss = 0.2133638560771942, acc = 0.9296875\n",
      "Batch 14: loss = 0.229079008102417, acc = 0.92578125\n",
      "Batch 15: loss = 0.20450511574745178, acc = 0.939453125\n",
      "Batch 16: loss = 0.20750415325164795, acc = 0.94140625\n",
      "Batch 17: loss = 0.2140793651342392, acc = 0.9345703125\n",
      "Batch 18: loss = 0.21270805597305298, acc = 0.9375\n",
      "Batch 19: loss = 0.21707496047019958, acc = 0.93359375\n",
      "Batch 20: loss = 0.2631046772003174, acc = 0.916015625\n",
      "Batch 21: loss = 0.26589930057525635, acc = 0.91796875\n",
      "Batch 22: loss = 0.2310394048690796, acc = 0.9228515625\n",
      "Batch 23: loss = 0.22295677661895752, acc = 0.93359375\n",
      "Batch 24: loss = 0.21109697222709656, acc = 0.9345703125\n",
      "Batch 25: loss = 0.21713563799858093, acc = 0.9384765625\n",
      "Batch 26: loss = 0.20657286047935486, acc = 0.9384765625\n",
      "Batch 27: loss = 0.17655380070209503, acc = 0.9462890625\n",
      "Batch 28: loss = 0.20571354031562805, acc = 0.939453125\n",
      "Batch 29: loss = 0.20459860563278198, acc = 0.9462890625\n",
      "Batch 30: loss = 0.22837339341640472, acc = 0.9287109375\n",
      "Batch 31: loss = 0.23760849237442017, acc = 0.9296875\n",
      "Batch 32: loss = 0.20300716161727905, acc = 0.935546875\n",
      "Batch 33: loss = 0.21013686060905457, acc = 0.9482421875\n",
      "Batch 34: loss = 0.2516966164112091, acc = 0.9228515625\n",
      "Batch 35: loss = 0.24319913983345032, acc = 0.9365234375\n",
      "Batch 36: loss = 0.21568156778812408, acc = 0.927734375\n",
      "Batch 37: loss = 0.22993923723697662, acc = 0.9326171875\n",
      "Batch 38: loss = 0.2134101390838623, acc = 0.9306640625\n",
      "Batch 39: loss = 0.2619120180606842, acc = 0.9150390625\n",
      "Batch 40: loss = 0.25636035203933716, acc = 0.9169921875\n",
      "Batch 41: loss = 0.2299666702747345, acc = 0.9267578125\n",
      "\n",
      "Epoch 97/100\n",
      "Batch 1: loss = 0.24814537167549133, acc = 0.9326171875\n",
      "Batch 2: loss = 0.2205466330051422, acc = 0.93359375\n",
      "Batch 3: loss = 0.22974446415901184, acc = 0.9423828125\n",
      "Batch 4: loss = 0.22097815573215485, acc = 0.9267578125\n",
      "Batch 5: loss = 0.18831461668014526, acc = 0.947265625\n",
      "Batch 6: loss = 0.17074620723724365, acc = 0.9501953125\n",
      "Batch 7: loss = 0.21287429332733154, acc = 0.9384765625\n",
      "Batch 8: loss = 0.17190858721733093, acc = 0.94921875\n",
      "Batch 9: loss = 0.2102140486240387, acc = 0.9404296875\n",
      "Batch 10: loss = 0.2257585972547531, acc = 0.9296875\n",
      "Batch 11: loss = 0.2516922056674957, acc = 0.9248046875\n",
      "Batch 12: loss = 0.22987918555736542, acc = 0.931640625\n",
      "Batch 13: loss = 0.24787072837352753, acc = 0.9208984375\n",
      "Batch 14: loss = 0.2342642843723297, acc = 0.927734375\n",
      "Batch 15: loss = 0.2070387750864029, acc = 0.9423828125\n",
      "Batch 16: loss = 0.20510712265968323, acc = 0.9384765625\n",
      "Batch 17: loss = 0.20428326725959778, acc = 0.9384765625\n",
      "Batch 18: loss = 0.23168188333511353, acc = 0.931640625\n",
      "Batch 19: loss = 0.23313741385936737, acc = 0.923828125\n",
      "Batch 20: loss = 0.2413024604320526, acc = 0.9384765625\n",
      "Batch 21: loss = 0.22674424946308136, acc = 0.9384765625\n",
      "Batch 22: loss = 0.20184889435768127, acc = 0.9443359375\n",
      "Batch 23: loss = 0.20702379941940308, acc = 0.9306640625\n",
      "Batch 24: loss = 0.2049674689769745, acc = 0.931640625\n",
      "Batch 25: loss = 0.21358367800712585, acc = 0.9384765625\n",
      "Batch 26: loss = 0.1958312690258026, acc = 0.9443359375\n",
      "Batch 27: loss = 0.17924389243125916, acc = 0.9384765625\n",
      "Batch 28: loss = 0.22102057933807373, acc = 0.9365234375\n",
      "Batch 29: loss = 0.21132886409759521, acc = 0.9404296875\n",
      "Batch 30: loss = 0.24621623754501343, acc = 0.923828125\n",
      "Batch 31: loss = 0.24235403537750244, acc = 0.931640625\n",
      "Batch 32: loss = 0.2146950364112854, acc = 0.939453125\n",
      "Batch 33: loss = 0.23599354922771454, acc = 0.9287109375\n",
      "Batch 34: loss = 0.29700395464897156, acc = 0.90625\n",
      "Batch 35: loss = 0.25635695457458496, acc = 0.9287109375\n",
      "Batch 36: loss = 0.20763686299324036, acc = 0.935546875\n",
      "Batch 37: loss = 0.19399341940879822, acc = 0.939453125\n",
      "Batch 38: loss = 0.19343812763690948, acc = 0.9453125\n",
      "Batch 39: loss = 0.23339030146598816, acc = 0.919921875\n",
      "Batch 40: loss = 0.24018433690071106, acc = 0.9326171875\n",
      "Batch 41: loss = 0.2706718146800995, acc = 0.923828125\n",
      "\n",
      "Epoch 98/100\n",
      "Batch 1: loss = 0.21807517111301422, acc = 0.9404296875\n",
      "Batch 2: loss = 0.2158830761909485, acc = 0.9345703125\n",
      "Batch 3: loss = 0.20943951606750488, acc = 0.9453125\n",
      "Batch 4: loss = 0.20844191312789917, acc = 0.9345703125\n",
      "Batch 5: loss = 0.2073771059513092, acc = 0.927734375\n",
      "Batch 6: loss = 0.18200096487998962, acc = 0.94921875\n",
      "Batch 7: loss = 0.19069944322109222, acc = 0.9443359375\n",
      "Batch 8: loss = 0.1939198523759842, acc = 0.943359375\n",
      "Batch 9: loss = 0.23940536379814148, acc = 0.9267578125\n",
      "Batch 10: loss = 0.23540380597114563, acc = 0.9326171875\n",
      "Batch 11: loss = 0.24968087673187256, acc = 0.9208984375\n",
      "Batch 12: loss = 0.24434086680412292, acc = 0.9228515625\n",
      "Batch 13: loss = 0.2237803041934967, acc = 0.9365234375\n",
      "Batch 14: loss = 0.22121699154376984, acc = 0.9375\n",
      "Batch 15: loss = 0.19295164942741394, acc = 0.943359375\n",
      "Batch 16: loss = 0.20290397107601166, acc = 0.9423828125\n",
      "Batch 17: loss = 0.22651919722557068, acc = 0.9208984375\n",
      "Batch 18: loss = 0.22206544876098633, acc = 0.939453125\n",
      "Batch 19: loss = 0.24306970834732056, acc = 0.921875\n",
      "Batch 20: loss = 0.2359922230243683, acc = 0.9326171875\n",
      "Batch 21: loss = 0.257255882024765, acc = 0.9228515625\n",
      "Batch 22: loss = 0.22262680530548096, acc = 0.9384765625\n",
      "Batch 23: loss = 0.2637011408805847, acc = 0.9130859375\n",
      "Batch 24: loss = 0.20850776135921478, acc = 0.9375\n",
      "Batch 25: loss = 0.19671165943145752, acc = 0.9404296875\n",
      "Batch 26: loss = 0.1918773502111435, acc = 0.9423828125\n",
      "Batch 27: loss = 0.1961384415626526, acc = 0.951171875\n",
      "Batch 28: loss = 0.17770279943943024, acc = 0.9501953125\n",
      "Batch 29: loss = 0.2207353115081787, acc = 0.9296875\n",
      "Batch 30: loss = 0.23463773727416992, acc = 0.9267578125\n",
      "Batch 31: loss = 0.21170954406261444, acc = 0.939453125\n",
      "Batch 32: loss = 0.19693677127361298, acc = 0.9404296875\n",
      "Batch 33: loss = 0.24563062191009521, acc = 0.9306640625\n",
      "Batch 34: loss = 0.25403738021850586, acc = 0.9248046875\n",
      "Batch 35: loss = 0.20792627334594727, acc = 0.9423828125\n",
      "Batch 36: loss = 0.20971834659576416, acc = 0.935546875\n",
      "Batch 37: loss = 0.20831641554832458, acc = 0.9365234375\n",
      "Batch 38: loss = 0.16847451031208038, acc = 0.9443359375\n",
      "Batch 39: loss = 0.22960981726646423, acc = 0.9326171875\n",
      "Batch 40: loss = 0.19758592545986176, acc = 0.943359375\n",
      "Batch 41: loss = 0.24630500376224518, acc = 0.9228515625\n",
      "\n",
      "Epoch 99/100\n",
      "Batch 1: loss = 0.24581541121006012, acc = 0.9267578125\n",
      "Batch 2: loss = 0.1889583319425583, acc = 0.939453125\n",
      "Batch 3: loss = 0.20501364767551422, acc = 0.935546875\n",
      "Batch 4: loss = 0.21544863283634186, acc = 0.9306640625\n",
      "Batch 5: loss = 0.20314814150333405, acc = 0.9287109375\n",
      "Batch 6: loss = 0.17794190347194672, acc = 0.94140625\n",
      "Batch 7: loss = 0.1953887939453125, acc = 0.93359375\n",
      "Batch 8: loss = 0.19424402713775635, acc = 0.939453125\n",
      "Batch 9: loss = 0.2211550772190094, acc = 0.9375\n",
      "Batch 10: loss = 0.2223178744316101, acc = 0.9345703125\n",
      "Batch 11: loss = 0.208522230386734, acc = 0.9326171875\n",
      "Batch 12: loss = 0.22266265749931335, acc = 0.93359375\n",
      "Batch 13: loss = 0.2267579883337021, acc = 0.9375\n",
      "Batch 14: loss = 0.1944693922996521, acc = 0.939453125\n",
      "Batch 15: loss = 0.18626336753368378, acc = 0.9423828125\n",
      "Batch 16: loss = 0.21013422310352325, acc = 0.9384765625\n",
      "Batch 17: loss = 0.20573976635932922, acc = 0.9375\n",
      "Batch 18: loss = 0.21147480607032776, acc = 0.9375\n",
      "Batch 19: loss = 0.20770800113677979, acc = 0.9306640625\n",
      "Batch 20: loss = 0.21401695907115936, acc = 0.94140625\n",
      "Batch 21: loss = 0.21695908904075623, acc = 0.931640625\n",
      "Batch 22: loss = 0.23019136488437653, acc = 0.919921875\n",
      "Batch 23: loss = 0.21034671366214752, acc = 0.9326171875\n",
      "Batch 24: loss = 0.21890810132026672, acc = 0.9306640625\n",
      "Batch 25: loss = 0.18202859163284302, acc = 0.9423828125\n",
      "Batch 26: loss = 0.17986483871936798, acc = 0.9541015625\n",
      "Batch 27: loss = 0.15548700094223022, acc = 0.9609375\n",
      "Batch 28: loss = 0.2113862931728363, acc = 0.9453125\n",
      "Batch 29: loss = 0.19338205456733704, acc = 0.94140625\n",
      "Batch 30: loss = 0.20650769770145416, acc = 0.94140625\n",
      "Batch 31: loss = 0.21494774520397186, acc = 0.93359375\n",
      "Batch 32: loss = 0.1998874545097351, acc = 0.9375\n",
      "Batch 33: loss = 0.2459433674812317, acc = 0.931640625\n",
      "Batch 34: loss = 0.25782936811447144, acc = 0.923828125\n",
      "Batch 35: loss = 0.23244637250900269, acc = 0.931640625\n",
      "Batch 36: loss = 0.17412973940372467, acc = 0.9443359375\n",
      "Batch 37: loss = 0.2271151840686798, acc = 0.923828125\n",
      "Batch 38: loss = 0.21693381667137146, acc = 0.931640625\n",
      "Batch 39: loss = 0.19057394564151764, acc = 0.9501953125\n",
      "Batch 40: loss = 0.24125447869300842, acc = 0.9326171875\n",
      "Batch 41: loss = 0.24116288125514984, acc = 0.9208984375\n",
      "\n",
      "Epoch 100/100\n",
      "Batch 1: loss = 0.18870016932487488, acc = 0.9462890625\n",
      "Batch 2: loss = 0.19037114083766937, acc = 0.94140625\n",
      "Batch 3: loss = 0.18406042456626892, acc = 0.9453125\n",
      "Batch 4: loss = 0.1835082322359085, acc = 0.9541015625\n",
      "Batch 5: loss = 0.17852133512496948, acc = 0.9453125\n",
      "Batch 6: loss = 0.16388878226280212, acc = 0.9482421875\n",
      "Batch 7: loss = 0.1764044165611267, acc = 0.939453125\n",
      "Batch 8: loss = 0.19523131847381592, acc = 0.94140625\n",
      "Batch 9: loss = 0.22696800529956818, acc = 0.9365234375\n",
      "Batch 10: loss = 0.20393067598342896, acc = 0.9443359375\n",
      "Batch 11: loss = 0.23696619272232056, acc = 0.921875\n",
      "Batch 12: loss = 0.2021399587392807, acc = 0.9462890625\n",
      "Batch 13: loss = 0.20040234923362732, acc = 0.9423828125\n",
      "Batch 14: loss = 0.1936587244272232, acc = 0.9375\n",
      "Batch 15: loss = 0.20186816155910492, acc = 0.939453125\n",
      "Batch 16: loss = 0.19883650541305542, acc = 0.939453125\n",
      "Batch 17: loss = 0.23140037059783936, acc = 0.9345703125\n",
      "Batch 18: loss = 0.22134914994239807, acc = 0.9345703125\n",
      "Batch 19: loss = 0.2071346640586853, acc = 0.9423828125\n",
      "Batch 20: loss = 0.23991170525550842, acc = 0.92578125\n",
      "Batch 21: loss = 0.22507011890411377, acc = 0.9326171875\n",
      "Batch 22: loss = 0.23651784658432007, acc = 0.9326171875\n",
      "Batch 23: loss = 0.20902712643146515, acc = 0.935546875\n",
      "Batch 24: loss = 0.18585655093193054, acc = 0.9453125\n",
      "Batch 25: loss = 0.19486618041992188, acc = 0.94140625\n",
      "Batch 26: loss = 0.1543508917093277, acc = 0.9521484375\n",
      "Batch 27: loss = 0.15604844689369202, acc = 0.955078125\n",
      "Batch 28: loss = 0.1839899718761444, acc = 0.9462890625\n",
      "Batch 29: loss = 0.15938089787960052, acc = 0.95703125\n",
      "Batch 30: loss = 0.21163593232631683, acc = 0.9404296875\n",
      "Batch 31: loss = 0.21181797981262207, acc = 0.9443359375\n",
      "Batch 32: loss = 0.2160370647907257, acc = 0.93359375\n",
      "Batch 33: loss = 0.22339656949043274, acc = 0.9365234375\n",
      "Batch 34: loss = 0.2833596467971802, acc = 0.9072265625\n",
      "Batch 35: loss = 0.2135816514492035, acc = 0.9375\n",
      "Batch 36: loss = 0.17982734739780426, acc = 0.947265625\n",
      "Batch 37: loss = 0.25836870074272156, acc = 0.921875\n",
      "Batch 38: loss = 0.18249735236167908, acc = 0.9462890625\n",
      "Batch 39: loss = 0.21978403627872467, acc = 0.935546875\n",
      "Batch 40: loss = 0.219618558883667, acc = 0.931640625\n",
      "Batch 41: loss = 0.20375759899616241, acc = 0.9423828125\n",
      "Saved checkpoint to weights_eminem_input.txt.100.h5\n"
     ]
    }
   ],
   "source": [
    "train('eminem_input.txt',file_name('eminem_input.txt'), epochs=100, save_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "AsvCQxmidhq8",
    "outputId": "d31e2991-179b-4fab-807d-5fd7965a2295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "9\n",
      "feek in the wrong feels right, i'm getin' for you\n",
      "so escapin' me is ampice\n",
      "mander asgard\n",
      "\n",
      "[chorus]\n",
      "im not afraid (im not afraid)\n",
      "to take a stand (to take a stand)\n",
      "everybody (everybody)\n",
      "come take my hand (come take my hand)\n",
      "well walk this road together, through the storm\n",
      "whatever weather, cold or warm\n",
      "just lettin' you know that youre not alone\n",
      "holla if you feel like youve been down the same road\n",
      "\n",
      "[dintro]\n",
      "yeah, it's a figa\n",
      "and i just bought a when i wasn't, then who was there and you better never let it go\n",
      "you only get one shot, do not miss your chance to blow\n",
      "this opportunity comes once in a lifetime, yo\n",
      "you better\n",
      "\n",
      "[verse 2]\n",
      "his soul's escaping the mover, the whole crowd goes so loud\n",
      "he opens his mouth, but the words won't cook\" who show the fuck can him\n",
      "but it's my hand (come take my hand)\n",
      "well walk this road together, through the storm\n",
      "whatever weather, cold or nam!\n",
      "well, that's all right because i love the way you lie\n",
      "i love the way you lie\n",
      "\n",
      "[verse 1: eminem]\n",
      "i can't tell \n"
     ]
    }
   ],
   "source": [
    "#for text\n",
    "def build_sample_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(1, 1)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences=(i != 2), stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "    \n",
    "def sample( header, num_chars,name):\n",
    "    with open('char_to_idx_{}.json'.format(name)) as f:\n",
    "        char_to_idx = json.load(f)\n",
    "    idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "    vocab_size = len(char_to_idx)\n",
    "\n",
    "    model = build_sample_model(vocab_size)\n",
    "    load_weights(100, model,name)\n",
    "    model.save(os.path.join(MODEL_DIR, 'model_{}.{}.h5'.format(name,100)))\n",
    "\n",
    "    sampled = [char_to_idx[c] for c in header]\n",
    "    print(sampled)\n",
    "    \n",
    "\n",
    "    for i in range(num_chars):\n",
    "        batch = np.zeros((1, 1))\n",
    "        if sampled:\n",
    "            batch[0, 0] = sampled[-1]\n",
    "        else:\n",
    "            batch[0, 0] = np.random.randint(vocab_size)\n",
    "        result = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(vocab_size), p=result)\n",
    "        sampled.append(sample)\n",
    "\n",
    "    return ''.join(idx_to_char[c] for c in sampled)\n",
    "\n",
    "\n",
    "print(sample( '', 1000,'eminem_input.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "suYD-029sHkK",
    "outputId": "9a811934-35f4-4f35-8ffd-1a5ebd0a6e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "/8\n",
      "[=d/4z/8] [b/4z/8] [b/8z/8] [b/8z/8] [^d/8^D,7/8] z/8 [=G,/4G/8] z/8\n",
      "[b3/4^D,3/4=D/8] z/4 [^D,/4^G,/4^A,/8^D/8] z/4 [^D,/8^G,/8^A,/8] z/8 [^G/8^g/8]\n",
      "[^D,/8^G/8^g/8] [^G,/8^D,/8] [^A,/8^G,/8] z/8 [=G,/8^D,5/4^D5/4^A5/4] z/8\n",
      "[^G,3/8^D,/2z3/8] [c/8^d/8] z/4 [^A,/8^D,/8F,/8] [^A,/4=D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^d/8 z/4 [c'/8^D,/4] z/8 [^A,/4^D,/4] z/8 [^a5/8^A,5/8] z/4\n",
      "[^d/8c/8C/8^D,5/8] z5/8 [^D,/2^G,/2^A,/2z/2] c/4 z/8 [^a5/8z/8]\n",
      "[c'/2z/8] [^D,/4^G,/4^C,/4] z/8 [^D,/8^G,/8^A,/8] z/8 [^d/8^D,/4F,/4^A,/4^D/4] z/8 [^D,/8^G,/8^A,/8^D/8] z/8 [^D,/8^G,/8^A,/8^D/8] [^A,/4^G,/4^D,/4^D/4]\n",
      "z/8 [f9/8^A,/4=D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "[^a3/8^A,23/8F,3/8D3/8] z/4 [^A,/4D,/4F,/4^A,/4D/8] z/8 [^A,/4D,/4] z/8 ^D/4 z/8 c'/8 [F,/8f/8] z/4 [=A,/8=D,/8] \n",
      "X: 1\n",
      "T: DragonBallZ (3:49)\n",
      "Z: Transcribed using LotRO MIDI Player: http://lotro.acasylum.com/midi\n",
      "%  Original file: StarTre/2Nik..4_widBid\n",
      "%  Transpose: -11\n",
      "L: 1/4\n",
      "Q: 120\n",
      "K: C\n",
      "z5/4 [D13z11/4] [^F/4B,/4] B,/4 [G/4B,/8] z/8 [^F/4B,/8] z/8 [^F/4B,/8] z/8 [^F/4B,/8] z/8 [^F3/4B,/4] B,/4 [G/4B,/8]\n",
      "z/8 [^F/4B,/8] z/8 [^F/4B,/8] z/8 [E3/4A,/4A2] A,/4\n",
      "[=F/4A,/8] z/8 [E/4A,/8] z/8 [E/2A,/8] z/8 [F/4A,/4A6] [E/4A,/4]\n",
      "[E/2A,/8] z/8 [E/4A,/8] z/8 [^F/4B,/4] B,/4 [G/4B,/8] z/8 [^F/4B,/8]\n",
      "z/8 [^F/4B,/8] z/8 [^F/4B,/8] z/8 [E/4A,/4] A,/4\n",
      "[=F/4A,/8]\n",
      "z/8 [E/4A,/8] z/8 [E/2A,/8] z/8 [F/4A,/4A6] [E/4A,/4] [E/4A,/8] z/8 [E/2A,/8] z/8 [^D/4A,/8] z/8\n",
      "[E/2A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E3/4A,/4] A,/4 [F/4A,/8] z/8 [E/2A,/8] z/8 [F/4A,/4] [E/4A,/4] [E/4A,/8] z/8 [E/2A,/8] z/8 [^D/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/2A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8]\n",
      "z/8 [E/4A,/8] z/8 [E/4A,/8] z/8\n",
      "[E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8]\n",
      "z/8 [E/4A,/4] A,/4 [F/4A,/8]\n",
      "z/8 [E/4A,/8] z/8 [E3/4A,/4] A,/4 [F/4A,/8]\n",
      "z/8 [E/4A,/8] z/8 [E/4A,/4] A,/4 [F/4A,/8] z/8 [E/4A,/8] z/8 [E3/4A,/4] A,/4 [F/4A,/8]\n",
      "z/8 [E/4A,/8] z/8 [E/4A,/4] A,/4 [F/4A,/8] z/8\n",
      "[E/2A,/8] z/8 [^D/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [B3/4^F3/4B,/4] B,/4 [f/4^f/4G/4B,/8] z/8 [^F/4B,/8]\n",
      "z/8 [=F/4B,/8] z/8 [^F/4B,/8]\n",
      "z/8 [^F/4B,/8] z/8 [^F/4B,/8] z/8 [^F3/4B,/4] B,/4 [G/4B,/8] z/8 [^F/2B,/8] z/8 [G/4B,/4]\n",
      "[^F/4B,/4] [^F/4B,/8] z/8 [^F/2B,/8] z/8 [=F/4B,/8] z/8 [^F/4B,/8] z/8 [^F3/4B,/4] B,/4 [G/4B,/8]\n",
      "z/8\n",
      "[^F/2B,/8] z/8 [^F/4B,/8] z/8\n",
      "[B3/4^F3/4B,/4] B,/4 [b/4^f/4G/4B,/8] z/8 [^fB/4^F/4B,/8] z/8 [^F/4B,/8] z/8 [^F/4B,/4] B,/4 [G/4B,/8] z/8\n",
      "[^F/4B,/8] z/8 [^F/4B,/4] B,/4 [G/4B,/8] z/8 [^F/4B,/8]\n",
      "z/8 [=F/4B,/8] z/8 [^F/4B,/8]\n",
      "z/8 [^F/4B,/8] z/8 [^F/4B,/8] z/8 [^F/4B,/4] B,/4 [G/4B,/8] z/8\n",
      "[^F/4B,/8] z/8 [^F/4B,/8] z/8 [E/4A,/4] A,/4\n",
      "[=F/4A,/8] z/8 [E/4A,/8] z/8 [E/2A,/8] z/8 [F/4A,/4A6] [E/4A,/4] [E/4A,/8] z/8 [E/2A,/8] z/8 [a/4A,/4] A,/4 [F/4A,/8] z/8 [E/4A,/8] z/8 [E3/4A,/4] A,/4 [F/4A,/8]\n",
      "z/8 [E/4A,/8] z/8\n",
      "[E3/4A,/4] A,/4 [F/4A,/8] z/8 [E/4A,/8] z/8 [E3/4A,/4] A,/4 [F/4A,/8] z/8 [E/2A,/8] z/8 [F/4A,/4] [E/4A,/4] [E/4A,/8] z/8 [E/2A,/8] z/8 [^D4A,/8A,/8] z/8\n",
      "[E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8]\n",
      "z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8 [E/4A,/8] z/8\n",
      "[E/4A,/8] z/8 [E/4A,/8] z/8\n",
      "[E/4A,/8]\n",
      "z/8 [E/4A,/8] z/8\n",
      "[B3/4^F3/4B,/4] B,/4 [=c/4G/4B,/8]\n",
      "z/8\n",
      "[B/4^g/4B,/4] z/8 [b/4^f/4^F,/4^A/4] z/8 [^A,/4f/4^D,/8^A,/8] z/8 [^A,/4^a/4] z/8 [^A,/8=d/8] z/4\n",
      "[^A,/8^d/8] z/8 [^A,/4^a/4] z/8 [^A,/8^a] z/4 [G,/8^a/4] z/8 [G,/4=a/4] z/8 [F,/8d/4] z/8 [G,/8g] z/8 G,/4 z/8 G,/8 z/4 [G,/8^a/4] z/8 [G,/4=a/4]\n",
      "z/8 [G,/8f/8] z/4 [G,/8gc'] z/8 G,/4 z/8 G,/8 z/4 [G,/8f]\n",
      "\n",
      "X: 1\n",
      "T: CaptainPlanet (1:03)\n",
      "Z: Transcribed using LotRO MIDI Player: http://lotro.acasylum.com/midi\n",
      "%  Original file: Halloween (made by Ratissia of snowbourne (1:21)\n",
      "%  Transpose: -14\n",
      "L: 1/4\n",
      "Q: 120\n",
      "K: C\n",
      "z4 [g16z16z] [a16z4] [f16z4] [a4A8] [g10G7G,5/4] z/4 C/2 [F17/8z2]\n",
      "[A6Az/2] [E^Gz/2] [Az/2] [C3/8^G] z/8 [A,/2A] [D/2^G] [=G11/4Az/2] [^Gz/2] [Az/2] [^Gz/2] [Az/2] [^Gz/2] [Az/2] ^G z7/2 B, z/2 E/4 A2\n",
      "z/4 [A,/2c] z/4 [^Az/4] z/8 [^D,3/4^D,5/8] z/8 [A,5/8z/2] [=D,3/4] z/4 [E,e5/8] z/4\n",
      "[=D,5/8=d/2] z/8 [E,e3/4] z/4 [^D,5/8 ^d/8] [E,5/8z/4] [^a3/8z/4] [^D,5/8z/2] [=g/4=[E,/8d3/8] e/4 [E,e3/4] z/4 [B,e39/8] z/8 [E,e5/8]\n",
      "z3/8 [E,e5/8] z3/8 [E,e5/8]\n",
      "z3/8 [^D,5/8^d/2] z/8 [=D,5/8] [^d368z/8] [A,e3/4] z/8 [E,e3/4] z/4\n",
      "[=D,5/8=a3/8] z/8 [=D,5/8] z/8 [=D,5/8]\n",
      "z/8 [=D,5/8=d3/8] z/4 [^D,5/8] z/8 [=D,5/8] [^D,5/8^a5/8] z/8 [=D,5/8] z/8 [E,e3/4] z/4 [=D,5/8=d/2] z/8 [E,e3/4] z/4 [E,e7/8] z/8\n",
      "[=D,5/8] z/8 [=D,5/8] z/8 [=D,5/8]\n",
      "z/4 [=D,5/8] z/8 [=D,5/8] [=D,5/8] z/8 [=D,5/8]\n",
      "[^a3/8E,37/8] [b15/8z/2] b/8 [=a7/8z/8]\n",
      "[=c'5/8c'5/8] [=a3/8z/4] [g/8c'/2] e/8 [=A9/8=A,9/8] [A,/2e/4] [a/8a3/8] z/8 [=d/8c/4] [e3/8^a/4] [c'/4G/4]\n",
      "[E3/8E3/8] [f/4F/4] [e/8E/8] [f/2F/2] [c5/8C5/8] [^f/2^A/2] [g/8=A3/8] [^d/2^A/2] [g/8=d/8] [c'/8C/8] [E/8e/8] [^A,/4z/8] [^A/8^a/8] [^A15/8^G17/8^A,7/8^D7/8] [^d/4^D,/4] [^D/4z/8]\n",
      "[^A9/8^a9/8^A,9/8D7/8] z/8 [f/4^A,/4^D,/4z/8] [^D3/8=d/8g/8] [D,/2E,/2] [G/4z/8] [f/4F3/8] [f/4G/4] [[g/8E/8] [^A3/8^A,3/8]\n",
      "[^d/8A/8c'/8] [c'/8C/8] [e/8^A,/8] [^A,/8C/8^a/8] [^a/8 [c3/8z/4] [^A,17/8z/8] [^a/8c/8] [=A/8^a/8] [^A,/8^a/8^A,/8] [^D/8c/8]\n",
      "[^A,/8D,/8F,/8F7/4=a/8] z3/8 [E,/8F,/8] [F,/8^A,/8^D/8] [=A,/8D,/8]\n",
      "[F/4f/8] [E/8e/8] [^A,/4z/8] [F/8f/8] [E/8e/8] [^D/4^A,5/8^D,7/8^A,7/8=G,f^d/4] z/8 [=D/8^d/8] [E/8^a/8] [=D/8=d/8] [^G/8^g/8]\n",
      "[=D/8d/8] [F/8f/8] [^A,/8D/8F,/8F,/8] [C/8^A,/8]\n",
      "[^D,13/8^A/8^a/8] [=D/8d/8=A,/8] [^A,/8^a/8^A,/8] [^D,/4^A,/4^D/4z/8] [^D,/8=G,/8D,/8^A,/8] z/8 [^D,/8=G,/8^A,/8^D,/4F,/4] ^a/8 ^a/8 [B,/8F,/4F,/4^D,/4^A,/4] z/8 [^A,/4=D,/4F,/4^A,/4D/4] z/8\n",
      "[^D,/8^A,/8^D,/8F,/8] [^A,3/8^D,/2E,/2^D,/2] z/4 [G,/8^D,/8^a3/8^A,3/8D3/8] z/4 [F,/8^D,/8=g/8] z/8 [^A,/8=g/8=G,/8] [B/8^d/8^D,/8] [^D,/8F,/8] z/8\n",
      "[^A,/8D,/8F,/8] [F,3/8^A,/2D,3/8] z/4 ^A,7/8 [^D,5/8F,/2^A/2] z/4 [c/4^G/8] z/8 ^D,/8 [^D,5/8F,/2z/4]\n",
      "^c/8 [^A,5/8^D,/2^A15/8]\n",
      "[^A,3/8=D,3/8] [=D,/4^A,/4] [^D/8^d/8] [D/8=G/8\n",
      "[^D/2^A,/2^D/4G,/4] [^A,/8E,/8] [F,/8^A3/8] [^A,/8^a/8]\n",
      "[^D,/8=G,/8^A,/8^D,/8] [d3/8^D,3/8^A,/2] [^A,/8=D,/8F,/8] z/8\n",
      "[^A,/8D,/8F,/8] [F,3/8^A,/2D,3/8] z/4 [^A,3/8^D,3/8^G,3/8] z/8 ^d/4\n",
      "[^D,3/8^A,/2^D/8] z/4 [^A,3/8^D,3/8^G,3/8] z/8 ^d/4\n",
      "[^D,3/8^A,/2^A,3/8^D,3/8] z/4 [^D,/4^C,/4^G,/4^D/4] z/8 [^D,/8^G,3/8^A,/4^D,7/8] z/8 [^D,/8G,/8^A,/8^D,/8F] =A/8] [F,/8^A,/8^D/8] z/8 [F,/4^A,/4^D/4] z/8 [F,/4=F/4] [^A,/4^D,/4F,/4] [C/4^F,/4^D/4] z/8\n",
      "[^D,/8^G,/8^A,/8] z/8 [F,/8^G,/4^D/4] z/8\n",
      "[F,/4^D,/4^A,/4] z3/8 [F,/8^D,/8^A,/8] [F,/8^D,/8^A,/8] z/8 [F,/8^D,/8^A,/8] [F,/8^D,/8^A,/8] z/8 [F,/8^D,/8^A,/8] [F,/8^D,/8^A,/8] z/8 [F,/8^D,/8^A,/8] z5/8 [F,/8^D,/8^A,3/4] z3/8 [F,/8^A,/8] [C/8^A/8]\n",
      "[F,/8^D,/8^A,3/8] z3/8 [F,/8B,/8^a11/8^D,3/8^A,3/8] z/4 [B,/8^f3/8^a3/8^A,3/8F,3/8] z/4 [F,/8B,/8^c/4] [f/8^A,/8F,/8]\n",
      "[F,/4B,/8^f/4^a/4^A,/4] z/2 [F,/8B,/8] z/8\n",
      "[G,/8^D,/8F,/8F,3/8] z3/8 [G,/8^D,3/8^A3/8^d3/8^F,3/8] z/4 [^F3/8^c3/8^d3/8^f3/8^F,3/8]\n",
      "[^F3/8^c3/8=F,/8B,/8^F,3/8^C,/4] z3/8 [^G,/8^D,3/8] [f5/8^F,3/8] [^G,/8^D,/8]\n",
      "[c'/8^G,/8] [^G,/8^D,/8] [C/8^G,/8] z/8 [^G,/8^D,3/8] [F,/8^D,/8^A3/4] z/8\n",
      "[^D,/8^G,/8^A,/8] z3/8 [^A3/8F,/8^A,/8] z/8 [=G,/8^D,/8]\n",
      "[F3/8^A3/8f3/8F,3/8^A,3/8z/4] [F3/8^A3/8z/8] [G,/8^D,/8^A3=c3^d2^G,27/8]\n",
      "z3/4 ^c3/8 f3/8 z/8 [^a5/8z3/8] F,/8 z/4 [=G,/8B,/8^g3/4] z3/4 [^D,/8^d/4] z/8\n",
      "[F,/8f/8] z7/4 [F,/8^A2/8^c/2=f/2=f/2^A,/4] z/2 [F,/8B,/8^f/8^a/8^A,/8] z7/4\n",
      "[G,/8^D,/8^A,3/4] z3/4 [F,/8^A,/8^D/8] [F,/8^A,/8^D,/8F,/8] z/8 [F,/8^G,/4^D/4] z/8 [F,/8^A,/4^D/8] z/8 [F,/4=D/4] [^A,/4^A/4^G,/8] z/8\n",
      "[F,/8=D,/8^A,/8^A,/8] z/8\n",
      "[f/8^D,/8] z/8 [^G,/4^G/4] [^D,/4^A/4z/8] [F,/8^A,/4^D/8G/8=d/8] z/4 [^A,/8^D,/8F,/8] [^A,/8^D,/8F,/8] z/8 [^A,/8^D,/8F,/8] [^A,/4^D,/4F,/4] z/8\n",
      "[^A,/8D,/8F,/8] z/4 [^A,/8^D,/8F,/8] [^A,/4^D,/4F,/4] z/8\n",
      "[^A,/8D,/8F,/8] z/8 [^A,/8D,/8F,/8] [^A,/8D,/8F,/8] z/8\n",
      "[f/8^D,/4F,/4] [^A,/4D,/4F,/4] z/8\n",
      "[C,/8F,/4F,/4^D/8] z/4 [^A,/8^D,/8F,/8] [^A,/8^D,/8F,/8] z/8 [^A,/8^D,/8F,/8]\n",
      "[F,3/8^A,3/8^D,/2^A17/8] z/4 [^A,/8^D,/8F,/8] [^A,/8^D,/8F,/8] z/8\n",
      "[^A,/8^D,/8F,/8] [^A,/4D,/4F,/4] z/8 [^A,/8D,/8F,/8] z/8\n",
      "[^A,/8D,/8F,/8] [F,3/8^A,/2D,3/8] z/4 [^A,3/8^D,3/8^G,3/8] z/8 ^d/4\n",
      "[^D,3/8^A,/2^D,3/8] z3/8 ^D,/4 [^D,5/8z/8]\n",
      "^c/8 [^d/8^D,/2F,/2] z/8 [^A,/4^D,/4F,/4] z/8\n",
      "[^d5/4^F,3/8^D,3/8F,3/8] z/4 ^A,/8 z/8 [=D,/4F,/4^A,/4^D/4] z/8\n",
      "[^D,/8^G,/8^A,/8^D/8] [^D,/8^G,/8^A,/8^D/8] z/8 [^A,/4^G,/4^D,/4^D/4]\n",
      "z/8 [f5/8^A,3/8=D,3/8] z/4\n",
      "[^D,/4^C,/4^G,/8^G,/8] z/8 [f/8^D,/8] [^D,/4^G,/4^D,/4^A,/4] z/8\n",
      "[^A,/8^D,/8F,/8] z/4 [^D,/8^D,/8F,/8] z/8 [^A,/8^D,/8F,/8] [^A,/4=D,/4F,/4] z/8 [^G,/4^D,/4F,/4] z/8 [^D,/8^G,/8^A,/8] z/8 [^A,/8^D,/8F,/8] [^A,/4=D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^D/8 z/4 =D/8 F,/8 [C3/8F,3/8z/8] ^D/8 z/4 [G/8C5/8] =A/4 ^A/8\n",
      "[F,/8^A/8] =A/8 [F,/8^A5/8^C,/8^A,37/8] ^A/4 [F,/8^A/8] [=A,/8^A,/8]\n",
      "=a/8 [F,/8^D,/8^A,3/4^C3/4] [F/8^A/8^f/8] z/8 [^A,5/8^D/8] [=G/8^g/8^G,/8] z/8 [=G/8^g/8^G,7/8] [^G/8^g/8^G,/8] z/8 [=G/8^g/8^G,/8] z/8 [=G/8^D,/8=G,/8]\n",
      "[^G/8^g/8^G,/8] z/8 [=G/8^D,/8=G,/8]\n",
      "[^G/8^D,/8F,/8] [^G/8^g/8^G,/8] [^G/8^g/8^G,/8] [^G/4^D,/4^G,/4] [^D/8^d/8] [E/8^A,/8^D,/8] [C3/8^G3/8G,/8C,/8^A,/8] z/8 [^A,/8^A,/8] [^D,5/8^A/8]\n",
      "[^A/8d/8f/8F,/8] [C/8^A/8] z/8\n",
      "[^A,11/8/C/8^A/8] [^A/4F/8f/8] z/8 [F/8f/8] [F/8f/8] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/8f/8] [F/8f/4]\n",
      "[F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8\n",
      "[F/4f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4F/4] [F/8f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/4 [F/4f/4] [F/8f/4] F/8\n",
      "[F/8f/4] [F/4f/4] [F,/8=F/8] z/8\n",
      "[F,/8F/8] [f/8F/4] [F,/8F/8] [d/8F/8]\n",
      "[F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8]\n",
      "[F/4f/4] [F/4f/4] [F/8f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8]\n",
      "[F/4f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4]\n",
      "[F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4]\n",
      "[F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/8] F/8 [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4^A,/4f/8^D27/8=G,7/8=A,7/8=C,7/8] [F/4f/4] [E/8e/8]\n",
      "[F/4f/8] [F/4f/4] [F/8f/8] [F/8f/8]\n",
      "[F/8f/8] [F/4f/4F,/4^A,/4C/4] z/8 [f/4^A,/4z/8]\n",
      "[F3/8f/8] [E/8e/8] [F/4f/4] [^A/8^g/8]\n",
      "[F/2f/4] z5/8 [f/4F,/4] [F,/8f3/8] z/8 [C/8f/8] z/8\n",
      "[F/8f/8] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8\n",
      "[F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4F/4] z/8\n",
      "[F/4f/4] [^D/4^d/4] [F/2f/4] z/8 [F/4f/4] z/8 [F/4f/4^a/4] z/8 [F/8g/8] [E/8e/8] [^A/4^D,7/4^C,5/4^G,7/4e/8e/8] [=d/4B,/4] [F,/8B/8f/8] z/8 [^A,11/8^A/8] [=G/8g/8] [F/8=d/8]\n",
      "[^D/8^d/8] [^D/8^d/8]\n",
      "[^D/8^d/8] [C/8=d/8]\n",
      "[^D/8^d/8] [^D/8^d/8] [^D/8^A/8] [^A,/8c3/8^G,3/8C3/8^G3/8^A3/8] [^D/8^d/8]\n",
      "[^D/8^d/8] [^D/8^d/8] [^D/8^d/8]\n",
      "[^D/8^d/8] [^A/8F/8] z/8 [=G,3/8^G/8^D,3/8] [^d/8^D/8] [^A/8^a/8]\n",
      "[^A/8F/8d/8^A,3/8] [^A,11/8^D/8] [^D/8^d/8] [^D/8^d/8] [^G/8^g/8] [=F/8d/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/8f/8] [F/8f/8] [F/8f/8] [F/4f/4] z/8 [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4]\n",
      "[F/8f/4] F/8 [F/4f/4] [F/8g/4] [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4]\n",
      "[F/8f/8] [F/4C,/4F,/4^A,/4F,/4] z/8 [^A/4f/4f/4F,/4^A,/4D/4] z/8\n",
      "[^A/4d/4f/4F,/4^A,/4=D/4] [^A/4d/4f/4F/4F,/4^A,/4] z/8\n",
      "[^A5/4f5/4f5/4F5/4F,5/4F,5/4] z3/8 [^d/4^A,/4z/8] [^A/4z/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4^A,/2f/8C3/8^A3/8] z/8 [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8]\n",
      "[F/8f/8] [F/4^A,/4f/8^D,3/8] z/8 [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] [F/8f/4] [F/4f/4] [F/8f/4]\n",
      "[F/8f/8] [F/4f/4] [F/8f/4]\n",
      "F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [^D/4c/4] [F/8f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4^A7/4^D,7/4f/8=A7/4c7/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/8f/8] [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/8f/4] F/8 [F/4f/4] [F/4f/4] [F/8f/8] [F/4f/4] [F/8f/8] [F/4f/4] [F/8d/8] [F/4f/4F/4F,/4^A,/4] z/8\n",
      "[^A/8d/8f/8F,/8B,/8^A,/8] z/8 [^A,/4^A/4^d/4^D,/4F,/4] z/8 [^A/8=d/8=f/8F,/8^A,/8=D/8] z/8\n",
      "[^A/8d/8f/8F,/8^A,/8=D/8] [^A/8d/8f/8F,/8^A,/8D/8] z/8\n",
      "[^A/8d/8f/8F,/8^A,/8D/8] z/8 [^A/8d/8f/8F,/8^A,/8D/8] z/8\n",
      "[^A/8d/8f/8F,/8^A,/8D/8] z/8 [^A/8d/8f/8F,/8^A,/8D/8] z/8\n",
      "[^A/8d/8f/4F/4^A,/4D/4] z/8 [^A/4d/4f/4F,/4^A,/4D/4] z/8\n",
      "[^A/4d/4f/4F,/4^A,/4D/4] [^A/4d/4f/4F,/4^A,/4D/8] z/8\n",
      "[^A/4d/4f/4D/4F,/4^A,/4] [^A/4d/4D,/4F,/4^A,/4] z/8\n",
      "[^A/8d/8f/8F,/8^A,/8D/8] [f/8^A=/4d/8F,/8^A,/8] z/8\n",
      "[^A9/4^d5/8] z/8 [F,/8f/8]\n",
      "[F,3/8^D,3/8^A/8^A/8] [^D/8^d/8] z/8 [=d/8=D/8] [c/8c'/8C/4] [^A/8^a/8^A,3/8] [^G/8^g/8] [=D/8=d/8] [^D/8^d/8] [^G/8^g/8^G,5/8] z/8 [=G/8=g/8^G,/8] z/8 [=G/8=g/8=G,/8] [c/8c'/8c'/8]\n",
      "[^A/8a/8f/8F,/8^A,/8] [C/8^A/8] [^A,7/8z/8]\n",
      "[^c/8^d/8^A,5/8] z/8 [^A/8^c/4] E,/8 z/8 [F,/2^D,5/8^D/2z/8] [^A/8^a/8] [^D/8=d/8^A,/8] z/8\n",
      "[^D/8^d/8^D,/8]\n",
      "[^G/8^g/8^G,/8] z/8 [=G/8^g/8=G,/8] [^G/8^g/8] [c'/8c'/8] [^d/8=D,/8] [C/8c'/8] [^D5/8^A/8] [^A/8^d/8^D,/8] z/8\n",
      "[=D/8=d/8=D,/8] [C/8c/8] z/8 [^C,3/8^G/8^g3/8] z/8 [^G,5/4^D,5/4^g/8] z3/8 [^A,/8^a/8]\n",
      "[F,3/8^A,3/4^a/8^A/4] z/8 [F/8f/8] [E/8e/8] [F/4f/4] [E/8e/8] [F/4f/4] [E/8e/8]\n",
      "[F/4A,/8^D,3/8^A,f/4F,7/8] z3/8 [C/8^D,/8F,/8] [C/8^C,/8F,/8] z/8 [=G/4^A/4^D,/4F,/4]\n",
      "[C/4^d/4^D/4] z/8 [=A/8=d/4f/8^D,/8^A,/8=A,/8] z3/8 [F,/8^D,/8^A,3/4] z[4 [F,/4F/8^A/8] z/8 [F,/4^d/4^G,/4] z/8 [F,/4=D/4^A,/4] z/8 [F,/8=F,/8^A,/8^D/2G/2^A/2g/2] z/4\n",
      "[F,/8^d/8] z7/4 [G,/8^D,/8^A,3/4^C,3/4F,3/4] z3/8 [F,/8B,/8^A3/2^c5/4^f5/8^a3/8]\n",
      "[^f/8^F,/4^C,/4] z/8\n",
      "[^A,/8^D,/8^A,/8] z/8 [^A,/8^D,/8] [C,/8^D,/8] [^D,/8F,/8^A,/8^D,/8] z/8 [^A,/8^D,/8F,/8] [^A,3/8^D,/2F,3/8] z/4 [^A,/8^D,/8F,/8] [^A,/8^D,/8F,/8] z/8\n",
      "[^A,/8^D,/8F,/8] [^A,/4^D,/4F,/4] z/8 [^A,/8D,/8F,/8] z/8\n",
      "[^A,/8D,/8F,/8] [F,3/8^A,/2D,3/8] z/4 [^A,3/8^D,3/8^G,3/8] z/8 [^A,/4^D,/4^A,/4C,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^D/8 z/4 =D/8 F,/8 [C3/8F,3/8z/8] ^D/8 z/4 [G/8C5/8 =A,3/4 F,/8 ^A,/8 [^A/8^A,/4] [^D/8^A/8] z/8 [=G,/8^D,/8=c/8]\n",
      "[c/8^G/8^G,/8^D,/8F,3/8] z/4 [F,/4c/4] z/8 [c5/4=g5/4=G,5/4E,/4C,/4] z/8\n",
      "[^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "[^c5/4^F5/4^D5/4F,5/4^A,5/4] z/4 [^A,/4D,/4F,/4] z/8 [^A,3/8D,3/8F,3/8]\n",
      "[c3/8^d3/8^D,3/8F,3/8] [G,9/8^A,3/8D,3/8F,3/8] z/4 [^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^D/8 z/8 =D/8 [F,/2^C,/2^A/2c/2^A,/2D/2] z/4 ^D,/8 [^D/4^d/4^G,/4^D,/4G,/4] z/8 [B/4^d/4^A,/4^D/4^G,/4^D/4] z/8\n",
      "[f9/4^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8 [^A,3/8D,3/8F,3/8]\n",
      "[c3/8^d3/8^G,3/8C3/8^D3/8] [B3/8=d3/8=G,3/8=D3/8B,3/8]\n",
      "[c3/8^d3/8^G,3/8=D3/8] [^A15/8=A,3/8=D3/8^A,3/8] [^A3/8^D3/8=d3/8^C,3/8] [^D3/8^A3/8=d3/8^F,3/8] [^D3/8^A3/8=d3/8^C,3/8^F,3/8^A,3/8] [c3/8^G3/8F,/8^d3/8^D,3/8] z/8 [^A,/8^F,/8^G,/8^D,/8]\n",
      "[F3/8^A,3/8^D,/2G,3/8] [c^A,3/8F,3/8]\n",
      "[^D,3/8=G,3/8C/8D3/8] z/8 [^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^D/8 z/4 =D/8 F,/8 [C3/8F,3/8z/8] ^D/8 z/4 [G/8c/8] z/4 [c/8C/2c'/2^G,/2D/4] z/8 [f/4^a/4^d/4=C,/4] z/8 [g/4G,/4G/4] z/8 [f/8^a/8^A,3/4] [f/8^a/8] z/8 [^a5/8E,5/8]\n",
      "[^a/8^A,/4] [^D/8^d/8] [^D/8G/8] [^A15/4^A9/4^A,5/4F,5/4F5/8f5/8] [G,z/8] [^A5/8F5/8] z/8 [f/4F5/8]\n",
      "z/8 [^d5/8=D3/4F,5/8^A,9/8^D/4] G,/8 [A15/8^A5/8=a5/8F,5/8C5/8] z/4\n",
      "[^A/8^a/8^A,/2] [^D,/4G,/4^A,/4^D/4z/8] [^a3/8z/8] [=a3/8z/4] [^A,/4z/8]\n",
      "[^a13/8^A,3/8C3/8F,3/8^A,3/8] [c/4^A,/4] [F,/8B,/8f/4^A,/4D,/4] z/8 [^A,/8D,/8F,/8] [^A,3/8D,/8F,/8] [^A,/8G,/8D,/8] z/8\n",
      "[^A,/8D,/8F,/8] [F,3/8^A,/2D,3/8] z/4 [^A,3/8^D,3/8^G,3/8] z/8 ^d/4\n",
      "[^D,3/8^A,/2^D,3/8] z/4 ^D,/4 z/4 [^D,3/8^A,3/8^D,3/8] z/4 [F,/8^D,/8] z/8 [F,5/4^D,5/4^D,5/4^A,5/4] z3/4 [^D,/4^G,/4] z/8 [^D,/4^G,/4^A,/8^D/8] z/8\n",
      "[^D,/8^G,/8^A,/8^D/8] z/8\n",
      "[^D,/8^G,/8^A,/8^D/8] z/8 [^A,/4^G,/4^D,/4^D/4]\n",
      "z/8 [f7/8^A,/4=D,/4F,/4] z/8 [f7/8^A,/4] z/8\n",
      "[^A5/8=g/4f/4F,/4F,/4] z/8 [B,/4^f/4^D/4^D,/4F,/4] z/8 [^A,/4=D,/4F,/4^A,/4D/4] z/8\n",
      "[^A,/4^D,/4^G,/4z/8] [^D/8^d/8] z/8 [^D,/4^G,/4^D,/4^G,/4^D,/4^A,/4] z3/8 [^D/8^d/8^G,5/8] z/8 [=d/8=D/8] [c'/8^a/8\n",
      "[^A,9/8^A/4^a/8^A,3/8] z/4 [^G/8^g/8] [B/4^d/4^f/4^F,/4B,/4^D/8] z/8 [=G/8=g/8=F,/8] [c'/4=G/4] [^A/8^d/8^a/8] [^D/8^d/8^D,/8] [^G/8^g/8^G,/8] z/8 [=G/8^g/8^G,/8] z/8 [=G/8^g/8^G,/8] [^G/8^g/8]\n",
      "[=G/8=g/8=G,/8] [c/4c'/4c'/4] z/8\n",
      "[^d/8^D/8] z/8 [=d/8=D/8] [c'/8C/8] [^A/8^a/8]\n",
      "[=c/8^a/8=A/8] [^D/8^d/8^D,/8] [^G/8^g/8] [=G,/8=D,/8] [C/8c'/8] [^C/4^d/4] [^D/8^d/8] [^D/8^d/8] [=D/8d/8] [F/4f/4] [E/8e/8] [F/2f/4] z/8 [^A/4^d/4=g/4] z/8 [g3/8=F5/8] z/8 [^A/4z/8] [c'3/8c'/4C/4F3/8c'/4] [e/8E/8]\n",
      "[f/4F/4] [e/8E/8] [f/4F/4] [^g/8^G/8] [=g/4=G/4] [^g/4^G/4] [^g/8c/8]\n",
      "[b/4B/4] [e/8E/8] z/8 [E,3/8C3/8=G,3/8^G,3/8b/8^G,5/8C/8]\n",
      "z/4 [^G,5/8B,5/8c/8^G/8^g/8] z/8\n",
      "[^A,5/8^D,5/8] z/8 [^d/8^D,/2=D,3/8] z/4 [^d/4^F,3/8^D,3/8F,3/8^A,3/8] z/4 [^A,5/8^D,/2z3/8] [c/8^d/8] E,/8 [^D,5/8^A/8^D,5/8] z/4 [^A,5/8^D,5/8^a/8] z/4 [^d/8c/4] z/4 [^A,5/8^D,5/8^A,9/8^G/8] z/8 ^a/8 [^a/2^G,/2E,/2F,/2] z3/8 [^d/2^G,/2F,3/8=A,3/8] z3/8 [^a5/8F,3/8] z/4 [^D,3/8^C/23/8]\n",
      "z/4 [^d3/8^F,3/8] z/4 [^D,5/8^C/4] z/8 [^D,/4^G,/4^A,/4^D/4z/8] z/8 [^D,/4^G,/4^A,/8^D/8] z/8 [^D,/8^G,/8^A,/8^D/8] [^D,/8^G,/8^A,/8^D/8] z/8 [^A,/4^G,/4^D,/4^D/4]\n",
      "z/8 [f3/8^A,/4D,/4F,/4] z/8\n",
      "[^A,3/4E,/4^A,/4^D15/8] z/8\n",
      "[^d3/8^F,3/8^A,3/8^D,3/8] z/4 [F,/8^D,/8^a3/8^A,3/8C3/8] z/4\n",
      "[^A,/8^D,/8F,/8] [^A,/8^D,/8F,/8] z/8 [^A,/8^D,/8F,/8]\n",
      "[^A,/8^D,/8F,/8] z/8 [^A,/8^D,/8F,/8] [^A,/4^D,/4F,/4] z/8\n",
      "[^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^D,/8 z/4 [^d/8^D,/8F,/8] [^d/8^D,/8F,/8] z/8 [^A,/8^D,/8F,/8] [^A,/4^D,/4F,/4] z/8\n",
      "[^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "^A,/8 [^D,5/8F,/2z/2] [c/4^d/8^D,/4] [^D,/4^G,/4^A,/4^D/4] z/8\n",
      "[^D,/8^G,/8^A,/8^D/8] z/8 [^A,/4^G,/4^D,/4^D/4]\n",
      "z/8 [^A,/4=D,/4F,/4^A,/4D/4] z/8 [^D,/4^G,/4^A,/4^D/4^a/4] z/8\n",
      "[B,/8^d/8^A,/8^D,/8] [B,/8^d/4^D,/4] [^A,/4D,/4F,/4] z/8 [^A,/4D,/4F,/4] z/8\n",
      "[^A,/8D,/8F,/8] z/8\n",
      "[^A,/8D,/8F,/8] [F,3/8^A,/2D,3/8] z/4 [^A,3/8^D,3/8^G,3/8] z/8 ^d/4\n",
      "[^D,3/8^A,/2^D,3/8] z/4 ^A,/8 [^D\n"
     ]
    }
   ],
   "source": [
    "# for music\n",
    "print(sample( '', 20000,'TV_Movie_abc_input.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WCDZHRhhUaX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
